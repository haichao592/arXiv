{
  "sources": [
    {
      "title": "cs.CL updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.CL",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2105.03075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Steven Y. Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1\">Varun Gangal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jason Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1\">Soroush Vosoughi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitamura_T/0/1/0/all/0/1\">Teruko Mitamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>",
          "description": "Data augmentation has recently seen increased interest in NLP due to more\nwork in low-resource domains, new tasks, and the popularity of large-scale\nneural networks that require large amounts of training data. Despite this\nrecent upsurge, this area is still relatively underexplored, perhaps due to the\nchallenges posed by the discrete nature of language data. In this paper, we\npresent a comprehensive and unifying survey of data augmentation for NLP by\nsummarizing the literature in a structured manner. We first introduce and\nmotivate data augmentation for NLP, and then discuss major methodologically\nrepresentative approaches. Next, we highlight techniques that are used for\npopular NLP applications and tasks. We conclude by outlining current challenges\nand directions for future research. Overall, our paper aims to clarify the\nlandscape of existing literature in data augmentation for NLP and motivate\nadditional work in this area. We also present a GitHub repository with a paper\nlist that will be continuously updated at\nhttps://github.com/styfeng/DataAug4NLP",
          "link": "http://arxiv.org/abs/2105.03075",
          "publishedOn": "2021-05-24T07:23:03.393Z",
          "wordCount": 634,
          "title": "A Survey of Data Augmentation Approaches for NLP. (arXiv:2105.03075v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.12248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jialin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiasen Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mottaghi_R/0/1/0/all/0/1\">Roozbeh Mottaghi</a>",
          "description": "The problem of knowledge-based visual question answering involves answering\nquestions that require external knowledge in addition to the content of the\nimage. Such knowledge typically comes in a variety of forms, including visual,\ntextual, and commonsense knowledge. The use of more knowledge sources, however,\nalso increases the chance of retrieving more irrelevant or noisy facts, making\nit difficult to comprehend the facts and find the answer. To address this\nchallenge, we propose Multi-modal Answer Validation using External knowledge\n(MAVEx), where the idea is to validate a set of promising answer candidates\nbased on answer-specific knowledge retrieval. This is in contrast to existing\napproaches that search for the answer in a vast collection of often irrelevant\nfacts. Our approach aims to learn which knowledge source should be trusted for\neach answer candidate and how to validate the candidate using that source. We\nconsider a multi-modal setting, relying on both textual and visual knowledge\nresources, including images searched using Google, sentences from Wikipedia\narticles, and concepts from ConceptNet. Our experiments with OK-VQA, a\nchallenging knowledge-based VQA dataset, demonstrate that MAVEx achieves new\nstate-of-the-art results.",
          "link": "http://arxiv.org/abs/2103.12248",
          "publishedOn": "2021-05-24T07:23:03.307Z",
          "wordCount": 642,
          "title": "Multi-Modal Answer Validation for Knowledge-Based VQA. (arXiv:2103.12248v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06977",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1\">Kayo Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandes_P/0/1/0/all/0/1\">Patrick Fernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pruthi_D/0/1/0/all/0/1\">Danish Pruthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1\">Aditi Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>",
          "description": "Context-aware machine translation models are designed to leverage contextual\ninformation, but often fail to do so. As a result, they inaccurately\ndisambiguate pronouns and polysemous words that require context for resolution.\nIn this paper, we ask several questions: What contexts do human translators use\nto resolve ambiguous words? Are models paying large amounts of attention to the\nsame context? What if we explicitly train them to do so? To answer these\nquestions, we introduce SCAT (Supporting Context for Ambiguous Translations), a\nnew English-French dataset comprising supporting context words for 14K\ntranslations that professional translators found useful for pronoun\ndisambiguation. Using SCAT, we perform an in-depth analysis of the context used\nto disambiguate, examining positional and lexical characteristics of the\nsupporting words. Furthermore, we measure the degree of alignment between the\nmodel's attention scores and the supporting context from SCAT, and apply a\nguided attention strategy to encourage agreement between the two.",
          "link": "http://arxiv.org/abs/2105.06977",
          "publishedOn": "2021-05-24T07:23:03.253Z",
          "wordCount": 613,
          "title": "Do Context-Aware Translation Models Pay the Right Attention?. (arXiv:2105.06977v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09050",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jia-Chen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhen-Hua Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Quan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhigang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>",
          "description": "Persona can function as the prior knowledge for maintaining the consistency\nof dialogue systems. Most of previous studies adopted the self persona in\ndialogue whose response was about to be selected from a set of candidates or\ndirectly generated, but few have noticed the role of partner in dialogue. This\npaper makes an attempt to thoroughly explore the impact of utilizing personas\nthat describe either self or partner speakers on the task of response selection\nin retrieval-based chatbots. Four persona fusion strategies are designed, which\nassume personas interact with contexts or responses in different ways. These\nstrategies are implemented into three representative models for response\nselection, which are based on the Hierarchical Recurrent Encoder (HRE),\nInteractive Matching Network (IMN) and Bidirectional Encoder Representations\nfrom Transformers (BERT) respectively. Empirical studies on the Persona-Chat\ndataset show that the partner personas neglected in previous studies can\nimprove the accuracy of response selection in the IMN- and BERT-based models.\nBesides, our BERT-based model implemented with the context-response-aware\npersona fusion strategy outperforms previous methods by margins larger than\n2.7% on original personas and 4.6% on revised personas in terms of hits@1\n(top-1 accuracy), achieving a new state-of-the-art performance on the\nPersona-Chat dataset.",
          "link": "http://arxiv.org/abs/2105.09050",
          "publishedOn": "2021-05-24T07:23:03.103Z",
          "wordCount": 663,
          "title": "Partner Matters! An Empirical Study on Fusing Personas for Personalized Response Selection in Retrieval-Based Chatbots. (arXiv:2105.09050v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaopeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tiancheng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyusong Lee</a>",
          "description": "Text-to-image retrieval is an essential task in cross-modal information\nretrieval, i.e., retrieving relevant images from a large and unlabelled dataset\ngiven textual queries. In this paper, we propose VisualSparta, a novel\n(Visual-text Sparse Transformer Matching) model that shows significant\nimprovement in terms of both accuracy and efficiency. VisualSparta is capable\nof outperforming previous state-of-the-art scalable methods in MSCOCO and\nFlickr30K. We also show that it achieves substantial retrieving speed\nadvantages, i.e., for a 1 million image index, VisualSparta using CPU gets\n~391X speedup compared to CPU vector search and ~5.4X speedup compared to\nvector search with GPU acceleration. Experiments show that this speed advantage\neven gets bigger for larger datasets because VisualSparta can be efficiently\nimplemented as an inverted index. To the best of our knowledge, VisualSparta is\nthe first transformer-based text-to-image retrieval model that can achieve\nreal-time searching for large-scale datasets, with significant accuracy\nimprovement compared to previous state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2101.00265",
          "publishedOn": "2021-05-24T07:23:03.096Z",
          "wordCount": 629,
          "title": "VisualSparta: An Embarrassingly Simple Approach to Large-scale Text-to-Image Search with Weighted Bag-of-words. (arXiv:2101.00265v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09226",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_D/0/1/0/all/0/1\">Divyansh Singh</a>",
          "description": "In recent times, we have seen an increased use of text chat for communication\non social networks and smartphones. This particularly involves the use of\nHindi-English code-mixed text which contains words which are not recognized in\nEnglish vocabulary. We have worked on detecting emotions in these mixed data\nand classify the sentences in human emotions which are angry, fear, happy or\nsad. We have used state of the art natural language processing models and\ncompared their performance on the dataset comprising sentences in this mixed\ndata. The dataset was collected and annotated from sources and then used to\ntrain the models.",
          "link": "http://arxiv.org/abs/2105.09226",
          "publishedOn": "2021-05-24T07:23:03.076Z",
          "wordCount": 538,
          "title": "Detection of Emotions in Hindi-English Code Mixed Text Data. (arXiv:2105.09226v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.05617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tufano_M/0/1/0/all/0/1\">Michele Tufano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1\">Dawn Drain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svyatkovskiy_A/0/1/0/all/0/1\">Alexey Svyatkovskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shao Kun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1\">Neel Sundaresan</a>",
          "description": "Automated unit test case generation tools facilitate test-driven development\nand support developers by suggesting tests intended to identify flaws in their\ncode. Existing approaches are usually guided by the test coverage criteria,\ngenerating synthetic test cases that are often difficult for developers to read\nor understand. In this paper we propose AthenaTest, an approach that aims to\ngenerate unit test cases by learning from real-world focal methods and\ndeveloper-written testcases. We formulate unit test case generation as a\nsequence-to-sequence learning task, adopting a two-step training procedure\nconsisting of denoising pretraining on a large unsupervised Java corpus, and\nsupervised finetuning for a downstream translation task of generating unit\ntests. We investigate the impact of natural language and source code\npretraining, as well as the focal context information surrounding the focal\nmethod. Both techniques provide improvements in terms of validation loss, with\npretraining yielding 25% relative improvement and focal context providing\nadditional 11.1% improvement. We also introduce Methods2Test, the largest\npublicly available supervised parallel corpus of unit test case methods and\ncorresponding focal methods in Java, which comprises 780K test cases mined from\n91K open-source repositories from GitHub. We evaluate AthenaTest on five\ndefects4j projects, generating 25K passing test cases covering 43.7% of the\nfocal methods with only 30 attempts. We execute the test cases, collect test\ncoverage information, and compare them with test cases generated by EvoSuite\nand GPT-3, finding that our approach outperforms GPT-3 and has comparable\ncoverage w.r.t. EvoSuite. Finally, we survey professional developers on their\npreference in terms of readability, understandability, and testing\neffectiveness of the generated tests, showing overwhelmingly preference towards\nAthenaTest.",
          "link": "http://arxiv.org/abs/2009.05617",
          "publishedOn": "2021-05-24T07:23:02.857Z",
          "wordCount": 731,
          "title": "Unit Test Case Generation with Transformers and Focal Context. (arXiv:2009.05617v2 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.01542",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luu_S/0/1/0/all/0/1\">Son T. Luu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_M/0/1/0/all/0/1\">Mao Nguyen Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Loi Duc Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_K/0/1/0/all/0/1\">Khiem Vinh Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngan Luu-Thuy Nguyen</a>",
          "description": "Machine reading comprehension (MRC) is a sub-field in natural language\nprocessing that aims to help computers understand unstructured texts and then\nanswer questions related to them. In practice, conversation is an essential way\nto communicate and transfer information. To help machines understand\nconversation texts, we present UIT-ViCoQA - a new corpus for conversational\nmachine reading comprehension in the Vietnamese language. This corpus consists\nof 10,000 questions with answers to over 2,000 conversations about health news\narticles. Then, we evaluate several baseline approaches for conversational\nmachine comprehension on the UIT-ViCoQA corpus. The best model obtains an F1\nscore of 45.27%, which is 30.91 points behind human performance (76.18%),\nindicating that there is ample room for improvement.",
          "link": "http://arxiv.org/abs/2105.01542",
          "publishedOn": "2021-05-24T07:23:02.847Z",
          "wordCount": 586,
          "title": "Conversational Machine Reading Comprehension for Vietnamese Healthcare Texts. (arXiv:2105.01542v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10396",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Walter_M/0/1/0/all/0/1\">Matthew R. Walter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patki_S/0/1/0/all/0/1\">Siddharth Patki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daniele_A/0/1/0/all/0/1\">Andrea F. Daniele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fahnestock_E/0/1/0/all/0/1\">Ethan Fahnestock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duvallet_F/0/1/0/all/0/1\">Felix Duvallet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hemachandra_S/0/1/0/all/0/1\">Sachithra Hemachandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Jean Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stentz_A/0/1/0/all/0/1\">Anthony Stentz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_N/0/1/0/all/0/1\">Nicholas Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howard_T/0/1/0/all/0/1\">Thomas M. Howard</a>",
          "description": "Contemporary approaches to perception, planning, estimation, and control have\nallowed robots to operate robustly as our remote surrogates in uncertain,\nunstructured environments. There is now an opportunity for robots to operate\nnot only in isolation, but also with and alongside humans in our complex\nenvironments. Natural language provides an efficient and flexible medium\nthrough which humans can communicate with collaborative robots. Through\nsignificant progress in statistical methods for natural language understanding,\nrobots are now able to interpret a diverse array of free-form navigation,\nmanipulation, and mobile manipulation commands. However, most contemporary\napproaches require a detailed prior spatial-semantic map of the robot's\nenvironment that models the space of possible referents of the utterance.\nConsequently, these methods fail when robots are deployed in new, previously\nunknown, or partially observed environments, particularly when mental models of\nthe environment differ between the human operator and the robot. This paper\nprovides a comprehensive description of a novel learning framework that allows\nfield and service robots to interpret and correctly execute natural language\ninstructions in a priori unknown, unstructured environments. Integral to our\napproach is its use of language as a \"sensor\" -- inferring spatial,\ntopological, and semantic information implicit in natural language utterances\nand then exploiting this information to learn a distribution over a latent\nenvironment model. We incorporate this distribution in a probabilistic language\ngrounding model and infer a distribution over a symbolic representation of the\nrobot's action space. We use imitation learning to identify a belief space\npolicy that reasons over the environment and behavior distributions. We\nevaluate our framework through a variety of different navigation and mobile\nmanipulation experiments.",
          "link": "http://arxiv.org/abs/2105.10396",
          "publishedOn": "2021-05-24T07:23:02.771Z",
          "wordCount": 722,
          "title": "Language Understanding for Field and Service Robots in a Priori Unknown Environments. (arXiv:2105.10396v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10419",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kvapilikova_I/0/1/0/all/0/1\">Ivana Kvapil&#x131;kova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labaka_G/0/1/0/all/0/1\">Gorka Labaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1\">Eneko Agirre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bojar_O/0/1/0/all/0/1\">Ond&#x159;ej Bojar</a>",
          "description": "Existing models of multilingual sentence embeddings require large parallel\ndata resources which are not available for low-resource languages. We propose a\nnovel unsupervised method to derive multilingual sentence embeddings relying\nonly on monolingual data. We first produce a synthetic parallel corpus using\nunsupervised machine translation, and use it to fine-tune a pretrained\ncross-lingual masked language model (XLM) to derive the multilingual sentence\nrepresentations. The quality of the representations is evaluated on two\nparallel corpus mining tasks with improvements of up to 22 F1 points over\nvanilla XLM. In addition, we observe that a single synthetic bilingual corpus\nis able to improve results for other language pairs.",
          "link": "http://arxiv.org/abs/2105.10419",
          "publishedOn": "2021-05-24T07:23:02.763Z",
          "wordCount": 565,
          "title": "Unsupervised Multilingual Sentence Embeddings for Parallel Corpus Mining. (arXiv:2105.10419v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.12919",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1\">Reid Pryzant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Card_D/0/1/0/all/0/1\">Dallas Card</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veitch_V/0/1/0/all/0/1\">Victor Veitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_D/0/1/0/all/0/1\">Dhanya Sridhar</a>",
          "description": "We consider the problem of using observational data to estimate the causal\neffects of linguistic properties. For example, does writing a complaint\npolitely lead to a faster response time? How much will a positive product\nreview increase sales? This paper addresses two technical challenges related to\nthe problem before developing a practical method. First, we formalize the\ncausal quantity of interest as the effect of a writer's intent, and establish\nthe assumptions necessary to identify this from observational data. Second, in\npractice, we only have access to noisy proxies for the linguistic properties of\ninterest -- e.g., predictions from classifiers and lexicons. We propose an\nestimator for this setting and prove that its bias is bounded when we perform\nan adjustment for the text. Based on these results, we introduce TextCause, an\nalgorithm for estimating causal effects of linguistic properties. The method\nleverages (1) distant supervision to improve the quality of noisy proxies, and\n(2) a pre-trained language model (BERT) to adjust for the text. We show that\nthe proposed method outperforms related approaches when estimating the effect\nof Amazon review sentiment on semi-simulated sales figures. Finally, we present\nan applied case study investigating the effects of complaint politeness on\nbureaucratic response times.",
          "link": "http://arxiv.org/abs/2010.12919",
          "publishedOn": "2021-05-24T07:23:02.719Z",
          "wordCount": 696,
          "title": "Causal Effects of Linguistic Properties. (arXiv:2010.12919v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10311",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tianyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>",
          "description": "Text generation has become one of the most important yet challenging tasks in\nnatural language processing (NLP). The resurgence of deep learning has greatly\nadvanced this field by neural generation models, especially the paradigm of\npretrained language models (PLMs). In this paper, we present an overview of the\nmajor advances achieved in the topic of PLMs for text generation. As the\npreliminaries, we present the general task definition and briefly describe the\nmainstream architectures of PLMs for text generation. As the core content, we\ndiscuss how to adapt existing PLMs to model different input data and satisfy\nspecial properties in the generated text. We further summarize several\nimportant fine-tuning strategies for text generation. Finally, we present\nseveral future directions and conclude this paper. Our survey aims to provide\ntext generation researchers a synthesis and pointer to related research.",
          "link": "http://arxiv.org/abs/2105.10311",
          "publishedOn": "2021-05-24T07:23:02.680Z",
          "wordCount": 577,
          "title": "Pretrained Language Models for Text Generation: A Survey. (arXiv:2105.10311v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.01910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaopeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyusong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tiancheng Zhao</a>",
          "description": "Although open-domain question answering (QA) draws great attention in recent\nyears, it requires large amounts of resources for building the full system and\nis often difficult to reproduce previous results due to complex configurations.\nIn this paper, we introduce SF-QA: simple and fair evaluation framework for\nopen-domain QA. SF-QA framework modularizes the pipeline open-domain QA system,\nwhich makes the task itself easily accessible and reproducible to research\ngroups without enough computing resources. The proposed evaluation framework is\npublicly available and anyone can contribute to the code and evaluations.",
          "link": "http://arxiv.org/abs/2101.01910",
          "publishedOn": "2021-05-24T07:23:02.661Z",
          "wordCount": 555,
          "title": "SF-QA: Simple and Fair Evaluation Library for Open-domain Question Answering. (arXiv:2101.01910v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.03659",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giorgi_J/0/1/0/all/0/1\">John Giorgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nitski_O/0/1/0/all/0/1\">Osvald Nitski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bader_G/0/1/0/all/0/1\">Gary Bader</a>",
          "description": "Sentence embeddings are an important component of many natural language\nprocessing (NLP) systems. Like word embeddings, sentence embeddings are\ntypically learned on large text corpora and then transferred to various\ndownstream tasks, such as clustering and retrieval. Unlike word embeddings, the\nhighest performing solutions for learning sentence embeddings require labelled\ndata, limiting their usefulness to languages and domains where labelled data is\nabundant. In this paper, we present DeCLUTR: Deep Contrastive Learning for\nUnsupervised Textual Representations. Inspired by recent advances in deep\nmetric learning (DML), we carefully design a self-supervised objective for\nlearning universal sentence embeddings that does not require labelled training\ndata. When used to extend the pretraining of transformer-based language models,\nour approach closes the performance gap between unsupervised and supervised\npretraining for universal sentence encoders. Importantly, our experiments\nsuggest that the quality of the learned embeddings scale with both the number\nof trainable parameters and the amount of unlabelled training data, making\nfurther improvements straightforward. Our code and pretrained models are\npublicly available and can be easily adapted to new domains or used to embed\nunseen text.",
          "link": "http://arxiv.org/abs/2006.03659",
          "publishedOn": "2021-05-24T07:23:02.646Z",
          "wordCount": 649,
          "title": "DeCLUTR: Deep Contrastive Learning for Unsupervised Textual Representations. (arXiv:2006.03659v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+White_J/0/1/0/all/0/1\">Jennifer C. White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1\">Naomi Saphra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Probes are models devised to investigate the encoding of knowledge -- e.g.\nsyntactic structure -- in contextual representations. Probes are often designed\nfor simplicity, which has led to restrictions on probe design that may not\nallow for the full exploitation of the structure of encoded information; one\nsuch restriction is linearity. We examine the case of a structural probe\n(Hewitt and Manning, 2019), which aims to investigate the encoding of syntactic\nstructure in contextual representations through learning only linear\ntransformations. By observing that the structural probe learns a metric, we are\nable to kernelize it and develop a novel non-linear variant with an identical\nnumber of parameters. We test on 6 languages and find that the radial-basis\nfunction (RBF) kernel, in conjunction with regularization, achieves a\nstatistically significant improvement over the baseline in all languages --\nimplying that at least part of the syntactic knowledge is encoded non-linearly.\nWe conclude by discussing how the RBF kernel resembles BERT's self-attention\nlayers and speculate that this resemblance leads to the RBF-based probe's\nstronger performance.",
          "link": "http://arxiv.org/abs/2105.10185",
          "publishedOn": "2021-05-24T07:23:02.615Z",
          "wordCount": 600,
          "title": "A Non-Linear Structural Probe. (arXiv:2105.10185v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10158",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Chenhao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jiaqing Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingping Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chengsong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>",
          "description": "Distantly supervision automatically generates plenty of training samples for\nrelation extraction. However, it also incurs two major problems: noisy labels\nand imbalanced training data. Previous works focus more on reducing wrongly\nlabeled relations (false positives) while few explore the missing relations\nthat are caused by incompleteness of knowledge base (false negatives).\nFurthermore, the quantity of negative labels overwhelmingly surpasses the\npositive ones in previous problem formulations. In this paper, we first provide\na thorough analysis of the above challenges caused by negative data. Next, we\nformulate the problem of relation extraction into as a positive unlabeled\nlearning task to alleviate false negative problem. Thirdly, we propose a\npipeline approach, dubbed \\textsc{ReRe}, that performs sentence-level relation\ndetection then subject/object extraction to achieve sample-efficient training.\nExperimental results show that the proposed method consistently outperforms\nexisting approaches and remains excellent performance even learned with a large\nquantity of false positive samples.",
          "link": "http://arxiv.org/abs/2105.10158",
          "publishedOn": "2021-05-24T07:23:02.608Z",
          "wordCount": 583,
          "title": "Revisiting the Negative Data of Distantly Supervised Relation Extraction. (arXiv:2105.10158v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10042",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Potdar_N/0/1/0/all/0/1\">Nihal Potdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avila_A/0/1/0/all/0/1\">Anderson R. Avila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_C/0/1/0/all/0/1\">Chao Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yiran Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiao Chen</a>",
          "description": "End-to-end spoken language understanding (SLU) has recently attracted\nincreasing interest. Compared to the conventional tandem-based approach that\ncombines speech recognition and language understanding as separate modules, the\nnew approach extracts users' intentions directly from the speech signals,\nresulting in joint optimization and low latency. Such an approach, however, is\ntypically designed to process one intention at a time, which leads users to\ntake multiple rounds to fulfill their requirements while interacting with a\ndialogue system. In this paper, we propose a streaming end-to-end framework\nthat can process multiple intentions in an online and incremental way. The\nbackbone of our framework is a unidirectional RNN trained with the\nconnectionist temporal classification (CTC) criterion. By this design, an\nintention can be identified when sufficient evidence has been accumulated, and\nmultiple intentions can be identified sequentially. We evaluate our solution on\nthe Fluent Speech Commands (FSC) dataset and the intent detection accuracy is\nabout 97 % on all multi-intent settings. This result is comparable to the\nperformance of the state-of-the-art non-streaming models, but is achieved in an\nonline and incremental way. We also employ our model to a keyword spotting task\nusing the Google Speech Commands dataset and the results are also highly\npromising.",
          "link": "http://arxiv.org/abs/2105.10042",
          "publishedOn": "2021-05-24T07:23:02.602Z",
          "wordCount": 647,
          "title": "A Streaming End-to-End Framework For Spoken Language Understanding. (arXiv:2105.10042v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10188",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xuefeng Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yulong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linfeng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>",
          "description": "Although neural models have achieved competitive results in dialogue systems,\nthey have shown limited ability in representing core semantics, such as\nignoring important entities. To this end, we exploit Abstract Meaning\nRepresentation (AMR) to help dialogue modeling. Compared with the textual\ninput, AMR explicitly provides core semantic knowledge and reduces data\nsparsity. We develop an algorithm to construct dialogue-level AMR graphs from\nsentence-level AMRs and explore two ways to incorporate AMRs into dialogue\nsystems. Experimental results on both dialogue understanding and response\ngeneration tasks show the superiority of our model. To our knowledge, we are\nthe first to leverage a formal semantic representation into neural dialogue\nmodeling.",
          "link": "http://arxiv.org/abs/2105.10188",
          "publishedOn": "2021-05-24T07:23:02.595Z",
          "wordCount": 535,
          "title": "Semantic Representation for Dialogue Modeling. (arXiv:2105.10188v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10323",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhiliang Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1\">Wei Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zihan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongkyu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yiping Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Nevin L. Zhang</a>",
          "description": "Personalized conversation models (PCMs) generate responses according to\nspeaker preferences. Existing personalized conversation tasks typically require\nmodels to extract speaker preferences from user descriptions or their\nconversation histories, which are scarce for newcomers and inactive users. In\nthis paper, we propose a few-shot personalized conversation task with an\nauxiliary social network. The task requires models to generate personalized\nresponses for a speaker given a few conversations from the speaker and a social\nnetwork. Existing methods are mainly designed to incorporate descriptions or\nconversation histories. Those methods can hardly model speakers with so few\nconversations or connections between speakers. To better cater for newcomers\nwith few resources, we propose a personalized conversation model (PCM) that\nlearns to adapt to new speakers as well as enabling new speakers to learn from\nresource-rich speakers. Particularly, based on a meta-learning based PCM, we\npropose a task aggregator (TA) to collect other speakers' information from the\nsocial network. The TA provides prior knowledge of the new speaker in its\nmeta-learning. Experimental results show our methods outperform all baselines\nin appropriateness, diversity, and consistency with speakers.",
          "link": "http://arxiv.org/abs/2105.10323",
          "publishedOn": "2021-05-24T07:23:02.589Z",
          "wordCount": 621,
          "title": "Learning from My Friends: Few-Shot Personalized Conversation Systems via Social Networks. (arXiv:2105.10323v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ennen_P/0/1/0/all/0/1\">Philipp Ennen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yen-Ting Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozbay_A/0/1/0/all/0/1\">Ali Girayhan Ozbay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Insalata_F/0/1/0/all/0/1\">Ferdinando Insalata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Ye Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jalali_S/0/1/0/all/0/1\">Sepehr Jalali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>",
          "description": "In a dialogue system pipeline, a natural language generation (NLG) unit\nconverts the dialogue direction and content to a corresponding natural language\nrealization. A recent trend for dialogue systems is to first pre-train on large\ndatasets and then fine-tune in a supervised manner using datasets annotated\nwith application-specific features. Though novel behaviours can be learned from\ncustom annotation, the required effort severely bounds the quantity of the\ntraining set, and the application-specific nature limits the reuse. In light of\nthe recent success of data-driven approaches, we propose the novel future\nbridging NLG (FBNLG) concept for dialogue systems and simulators. The critical\nstep is for an FBNLG to accept a future user or system utterance to bridge the\npresent context towards. Future bridging enables self supervised training over\nannotation-free datasets, decoupled the training of NLG from the rest of the\nsystem. An FBNLG, pre-trained with massive datasets, is expected to apply in\nclassical or new dialogue scenarios with minimal adaptation effort. We evaluate\na prototype FBNLG to show that future bridging can be a viable approach to a\nuniversal few-shot NLG for task-oriented and chit-chat dialogues.",
          "link": "http://arxiv.org/abs/2105.10267",
          "publishedOn": "2021-05-24T07:23:02.580Z",
          "wordCount": 638,
          "title": "Towards a Universal NLG for Dialogue Systems and Simulators with Future Bridging. (arXiv:2105.10267v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10334",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1\">Siru Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>",
          "description": "Logical reasoning, which is closely related to human cognition, is of vital\nimportance in human's understanding of texts. Recent years have witnessed\nincreasing attentions on machine's logical reasoning abilities. However,\nprevious studies commonly apply ad-hoc methods to model pre-defined relation\npatterns, such as linking named entities, which only considers global knowledge\ncomponents that are related to commonsense, without local perception of\ncomplete facts or events. Such methodology is obviously insufficient to deal\nwith complicated logical structures. Therefore, we argue that the natural logic\nunits would be the group of backbone constituents of the sentence such as the\nsubject-verb-object formed \"facts\", covering both global and local knowledge\npieces that are necessary as the basis for logical reasoning. Beyond building\nthe ad-hoc graphs, we propose a more general and convenient fact-driven\napproach to construct a supergraph on top of our newly defined fact units, and\nenhance the supergraph with further explicit guidance of local question and\noption interactions. Experiments on two challenging logical reasoning benchmark\ndatasets, ReClor and LogiQA, show that our proposed model, \\textsc{Focal\nReasoner}, outperforms the baseline models dramatically. It can also be\nsmoothly applied to other downstream tasks such as MuTual, a dialogue reasoning\ndataset, achieving competitive results.",
          "link": "http://arxiv.org/abs/2105.10334",
          "publishedOn": "2021-05-24T07:23:02.558Z",
          "wordCount": 617,
          "title": "Fact-driven Logical Reasoning. (arXiv:2105.10334v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10155",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gidiotis_A/0/1/0/all/0/1\">Alexios Gidiotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1\">Grigorios Tsoumakas</a>",
          "description": "We propose a novel approach to summarization based on Bayesian deep learning.\nWe approximate Bayesian summary generation by first extending state-of-the-art\nsummarization models with Monte Carlo dropout and then using them to perform\nmultiple stochastic forward passes. This method allows us to improve\nsummarization performance by simply using the median of multiple stochastic\nsummaries. We show that our variational equivalents of BART and PEGASUS can\noutperform their deterministic counterparts on multiple benchmark datasets. In\naddition, we rely on Bayesian inference to measure the uncertainty of the model\nwhen generating summaries. Having a reliable uncertainty measure, we can\nimprove the experience of the end user by filtering out generated summaries of\nhigh uncertainty. Furthermore, our proposed metric could be used as a criterion\nfor selecting samples for annotation, and can be paired nicely with active\nlearning and human-in-the-loop approaches.",
          "link": "http://arxiv.org/abs/2105.10155",
          "publishedOn": "2021-05-24T07:23:02.551Z",
          "wordCount": 549,
          "title": "Uncertainty-Aware Abstractive Summarization. (arXiv:2105.10155v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10344",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Sanwal_U/0/1/0/all/0/1\">Usman Sanwal</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hoang_T/0/1/0/all/0/1\">Thai Son Hoang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Petre_L/0/1/0/all/0/1\">Luigia Petre</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Petre_I/0/1/0/all/0/1\">Ion Petre</a>",
          "description": "Biology offers many examples of large-scale, complex, concurrent systems:\nmany processes take place in parallel, compete on resources and influence each\nother's behavior. The scalable modeling of biological systems continues to be a\nvery active field of research. In this paper we introduce a new approach based\non Event-B, a state-based formal method with refinement as its central\ningredient, allowing us to check for model consistency step-by-step in an\nautomated way. Our approach based on functions leads to an elegant and concise\nmodeling method. We demonstrate this approach by constructing what is, to our\nknowledge, the largest ever built Event-B model, describing the ErbB signaling\npathway, a key evolutionary pathway with a significant role in development and\nin many types of cancer. The Event-B model for the ErbB pathway describes 1320\nmolecular reactions through 242 events.",
          "link": "http://arxiv.org/abs/2105.10344",
          "publishedOn": "2021-05-24T07:23:02.542Z",
          "wordCount": 566,
          "title": "Towards Scalable Modeling of Biology in Event-B. (arXiv:2105.10344v1 [q-bio.MN])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahay_A/0/1/0/all/0/1\">Atul Sahay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasery_A/0/1/0/all/0/1\">Anshul Nasery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_A/0/1/0/all/0/1\">Ayush Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "Recently, unsupervised parsing of syntactic trees has gained considerable\nattention. A prototypical approach to such unsupervised parsing employs\nreinforcement learning and auto-encoders. However, no mechanism ensures that\nthe learnt model leverages the well-understood language grammar. We propose an\napproach that utilizes very generic linguistic knowledge of the language\npresent in the form of syntactic rules, thus inducing better syntactic\nstructures. We introduce a novel formulation that takes advantage of the\nsyntactic grammar rules and is independent of the base system. We achieve new\nstate-of-the-art results on two benchmarks datasets, MNLI and WSJ. The source\ncode of the paper is available at https://github.com/anshuln/Diora_with_rules.",
          "link": "http://arxiv.org/abs/2105.10193",
          "publishedOn": "2021-05-24T07:23:02.536Z",
          "wordCount": 543,
          "title": "Rule Augmented Unsupervised Constituency Parsing. (arXiv:2105.10193v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Colladon_A/0/1/0/all/0/1\">A. Fronzetti Colladon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gloor_P/0/1/0/all/0/1\">P. A. Gloor</a>",
          "description": "This paper investigates the research question if senders of large amounts of\nirrelevant or unsolicited information - commonly called \"spammers\" - distort\nthe network structure of social networks. Two large social networks are\nanalyzed, the first extracted from the Twitter discourse about a big\ntelecommunication company, and the second obtained from three years of email\ncommunication of 200 managers working for a large multinational company. This\nwork compares network robustness and the stability of centrality and\ninteraction metrics, as well as the use of language, after removing spammers\nand the most and least connected nodes. The results show that spammers do not\nsignificantly alter the structure of the information-carrying network, for most\nof the social indicators. The authors additionally investigate the correlation\nbetween e-mail subject line and content by tracking language sentiment,\nemotionality, and complexity, addressing the cases where collecting email\nbodies is not permitted for privacy reasons. The findings extend the research\nabout robustness and stability of social networks metrics, after the\napplication of graph simplification strategies. The results have practical\nimplication for network analysts and for those company managers who rely on\nnetwork analytics (applied to company emails and social media data) to support\ntheir decision-making processes.",
          "link": "http://arxiv.org/abs/2105.10256",
          "publishedOn": "2021-05-24T07:23:02.529Z",
          "wordCount": 656,
          "title": "Measuring the impact of spammers on e-mail and Twitter networks. (arXiv:2105.10256v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ambroszkiewicz_S/0/1/0/all/0/1\">Stanislaw Ambroszkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartyna_W/0/1/0/all/0/1\">Waldemar Bartyna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bylka_S/0/1/0/all/0/1\">Stanislaw Bylka</a>",
          "description": "Cloud Native Application CNApp (as a distributed system) is a collection of\nindependent components (micro-services) interacting via communication\nprotocols. This gives rise to present an abstract architecture of CNApp as\ndynamically re-configurable acyclic directed multi graph where vertices are\nmicroservices, and edges are the protocols. Generic mechanisms for such\nreconfigurations evidently correspond to higher-level functions (functionals).\nThis implies also internal abstract architecture of microservice as a\ncollection of event-triggered serverless functions (including functions\nimplementing the protocols) that are dynamically composed into event-dependent\ndata-flow graphs. Again, generic mechanisms for such compositions correspond to\ncalculus of functionals and relations.",
          "link": "http://arxiv.org/abs/2105.10362",
          "publishedOn": "2021-05-24T07:23:02.497Z",
          "wordCount": 543,
          "title": "Functionals in the Clouds: An abstract architecture of serverless Cloud-Native Apps. (arXiv:2105.10362v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bennett_A/0/1/0/all/0/1\">Andrew Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1\">Dipendra Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Than_N/0/1/0/all/0/1\">Nga Than</a>",
          "description": "Topic models are widely used in studying social phenomena. We conduct a\ncomparative study examining state-of-the-art neural versus non-neural topic\nmodels, performing a rigorous quantitative and qualitative assessment on a\ndataset of tweets about the COVID-19 pandemic. Our results show that not only\ndo neural topic models outperform their classical counterparts on standard\nevaluation metrics, but they also produce more coherent topics, which are of\ngreat benefit when studying complex social problems. We also propose a novel\nregularization term for neural topic models, which is designed to address the\nwell-documented problem of mode collapse, and demonstrate its effectiveness.",
          "link": "http://arxiv.org/abs/2105.10165",
          "publishedOn": "2021-05-24T07:23:02.488Z",
          "wordCount": 605,
          "title": "Have you tried Neural Topic Models? Comparative Analysis of Neural and Non-Neural Topic Models with Application to COVID-19 Twitter Data. (arXiv:2105.10165v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09984",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bedi_M/0/1/0/all/0/1\">Manjot Bedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shivani Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Md Shad Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>",
          "description": "Sarcasm detection and humor classification are inherently subtle problems,\nprimarily due to their dependence on the contextual and non-verbal information.\nFurthermore, existing studies in these two topics are usually constrained in\nnon-English languages such as Hindi, due to the unavailability of qualitative\nannotated datasets. In this work, we make two major contributions considering\nthe above limitations: (1) we develop a Hindi-English code-mixed dataset,\nMaSaC, for the multi-modal sarcasm detection and humor classification in\nconversational dialog, which to our knowledge is the first dataset of its kind;\n(2) we propose MSH-COMICS, a novel attention-rich neural architecture for the\nutterance classification. We learn efficient utterance representation utilizing\na hierarchical attention mechanism that attends to a small portion of the input\nsentence at a time. Further, we incorporate dialog-level contextual attention\nmechanism to leverage the dialog history for the multi-modal classification. We\nperform extensive experiments for both the tasks by varying multi-modal inputs\nand various submodules of MSH-COMICS. We also conduct comparative analysis\nagainst existing approaches. We observe that MSH-COMICS attains superior\nperformance over the existing models by > 1 F1-score point for the sarcasm\ndetection and 10 F1-score points in humor classification. We diagnose our model\nand perform thorough analysis of the results to understand the superiority and\npitfalls.",
          "link": "http://arxiv.org/abs/2105.09984",
          "publishedOn": "2021-05-24T07:23:02.459Z",
          "wordCount": 643,
          "title": "Multi-modal Sarcasm Detection and Humor Classification in Code-mixed Conversations. (arXiv:2105.09984v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10026",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maharana_A/0/1/0/all/0/1\">Adyasha Maharana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hannan_D/0/1/0/all/0/1\">Darryl Hannan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Story visualization is an under-explored task that falls at the intersection\nof many important research directions in both computer vision and natural\nlanguage processing. In this task, given a series of natural language captions\nwhich compose a story, an agent must generate a sequence of images that\ncorrespond to the captions. Prior work has introduced recurrent generative\nmodels which outperform text-to-image synthesis models on this task. However,\nthere is room for improvement of generated images in terms of visual quality,\ncoherence and relevance. We present a number of improvements to prior modeling\napproaches, including (1) the addition of a dual learning framework that\nutilizes video captioning to reinforce the semantic alignment between the story\nand generated images, (2) a copy-transform mechanism for\nsequentially-consistent story visualization, and (3) MART-based transformers to\nmodel complex interactions between frames. We present ablation studies to\ndemonstrate the effect of each of these techniques on the generative power of\nthe model for both individual images as well as the entire narrative.\nFurthermore, due to the complexity and generative nature of the task, standard\nevaluation metrics do not accurately reflect performance. Therefore, we also\nprovide an exploration of evaluation metrics for the model, focused on aspects\nof the generated frames such as the presence/quality of generated characters,\nthe relevance to captions, and the diversity of the generated images. We also\npresent correlation experiments of our proposed automated metrics with human\nevaluations. Code and data available at:\nhttps://github.com/adymaharana/StoryViz",
          "link": "http://arxiv.org/abs/2105.10026",
          "publishedOn": "2021-05-24T07:23:02.452Z",
          "wordCount": 686,
          "title": "Improving Generation and Evaluation of Visual Stories via Semantic Consistency. (arXiv:2105.10026v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10146",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kohli_H/0/1/0/all/0/1\">Harsh Kohli</a>",
          "description": "Modern transformer-based neural architectures yield impressive results in\nnearly every NLP task and Word Sense Disambiguation, the problem of discerning\nthe correct sense of a word in a given context, is no exception.\nState-of-the-art approaches in WSD today leverage lexical information along\nwith pre-trained embeddings from these models to achieve results comparable to\nhuman inter-annotator agreement on standard evaluation benchmarks. In the same\nvein, we experiment with several strategies to optimize bi-encoders for this\nspecific task and propose alternative methods of presenting lexical information\nto our model. Through our multi-stage pre-training and fine-tuning pipeline we\nfurther the state of the art in Word Sense Disambiguation.",
          "link": "http://arxiv.org/abs/2105.10146",
          "publishedOn": "2021-05-24T07:23:02.408Z",
          "wordCount": 540,
          "title": "Training Bi-Encoders for Word Sense Disambiguation. (arXiv:2105.10146v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_G/0/1/0/all/0/1\">Gargi Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1\">Po-Yao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_P/0/1/0/all/0/1\">Prahal Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aminzadeh_M/0/1/0/all/0/1\">Masoumeh Aminzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feichtenhofer_C/0/1/0/all/0/1\">Christoph Feichtenhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metze_F/0/1/0/all/0/1\">Florian Metze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>",
          "description": "We present a simplified, task-agnostic multi-modal pre-training approach that\ncan accept either video or text input, or both for a variety of end tasks.\nExisting pre-training are task-specific by adopting either a single cross-modal\nencoder that requires both modalities, limiting their use for retrieval-style\nend tasks or more complex multitask learning with two unimodal encoders,\nlimiting early cross-modal fusion. We instead introduce new pretraining masking\nschemes that better mix across modalities (e.g. by forcing masks for text to\npredict the closest video embeddings) while also maintaining separability (e.g.\nunimodal predictions are sometimes required, without using all the input).\nExperimental results show strong performance across a wider range of tasks than\nany previous methods, often outperforming task-specific pre-training.",
          "link": "http://arxiv.org/abs/2105.09996",
          "publishedOn": "2021-05-24T07:23:02.399Z",
          "wordCount": 565,
          "title": "VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding. (arXiv:2105.09996v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kawintiranon_K/0/1/0/all/0/1\">Kornraphop Kawintiranon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yaguang Liu</a>",
          "description": "General Data Protection Regulation (GDPR) becomes a standard law for data\nprotection in many countries. Currently, twelve countries adopt the regulation\nand establish their GDPR-like regulation. However, to evaluate the differences\nand similarities of these GDPR-like regulations is time-consuming and needs a\nlot of manual effort from legal experts. Moreover, GDPR-like regulations from\ndifferent countries are written in their languages leading to a more difficult\ntask since legal experts who know both languages are essential. In this paper,\nwe investigate a simple natural language processing (NLP) approach to tackle\nthe problem. We first extract chunks of information from GDPR-like documents\nand form structured data from natural language. Next, we use NLP methods to\ncompare documents to measure their similarity. Finally, we manually label a\nsmall set of data to evaluate our approach. The empirical result shows that the\nBERT model with cosine similarity outperforms other baselines. Our data and\ncode are publicly available.",
          "link": "http://arxiv.org/abs/2105.10117",
          "publishedOn": "2021-05-24T07:23:02.380Z",
          "wordCount": 600,
          "title": "Towards Automatic Comparison of Data Privacy Documents: A Preliminary Experiment on GDPR-like Laws. (arXiv:2105.10117v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10023",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rakshit_G/0/1/0/all/0/1\">Geetanjali Rakshit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flanigan_J/0/1/0/all/0/1\">Jeffrey Flanigan</a>",
          "description": "In this work, we introduce ASQ, a tool to automatically mine questions and\nanswers from a sentence, using its Abstract Meaning Representation (AMR).\nPrevious work has made a case for using question-answer pairs to specify\npredicate-argument structure of a sentence using natural language, which does\nnot require linguistic expertise or training. This has resulted in the creation\nof datasets such as QA-SRL and QAMR, for both of which, the question-answer\npair annotations were crowdsourced. Our approach has the same end-goal, but is\nautomatic, making it faster and cost-effective, without compromising on the\nquality and validity of the question-answer pairs thus obtained. A qualitative\nevaluation of the output generated by ASQ from the AMR 2.0 data shows that the\nquestion-answer pairs are natural and valid, and demonstrate good coverage of\nthe content. We run ASQ on the sentences from the QAMR dataset, to observe that\nthe semantic roles in QAMR are also captured by ASQ.We intend to make this tool\nand the results publicly available for others to use and build upon.",
          "link": "http://arxiv.org/abs/2105.10023",
          "publishedOn": "2021-05-24T07:23:02.344Z",
          "wordCount": 590,
          "title": "ASQ: Automatically Generating Question-Answer Pairs using AMRs. (arXiv:2105.10023v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shmueli_B/0/1/0/all/0/1\">Boaz Shmueli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_S/0/1/0/all/0/1\">Soumya Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ku_L/0/1/0/all/0/1\">Lun-Wei Ku</a>",
          "description": "Datasets with induced emotion labels are scarce but of utmost importance for\nmany NLP tasks. We present a new, automated method for collecting texts along\nwith their induced reaction labels. The method exploits the online use of\nreaction GIFs, which capture complex affective states. We show how to augment\nthe data with induced emotion and induced sentiment labels. We use our method\nto create and publish ReactionGIF, a first-of-its-kind affective dataset of 30K\ntweets. We provide baselines for three new tasks, including induced sentiment\nprediction and multilabel classification of induced emotions. Our method and\ndataset open new research opportunities in emotion detection and affective\ncomputing.",
          "link": "http://arxiv.org/abs/2105.09967",
          "publishedOn": "2021-05-24T07:23:02.332Z",
          "wordCount": 563,
          "title": "Happy Dance, Slow Clap: Using Reaction GIFs to Predict Induced Affect on Twitter. (arXiv:2105.09967v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10080",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_B/0/1/0/all/0/1\">Bin Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shasha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jie Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huijun Liu</a>",
          "description": "Span-based joint extraction simultaneously conducts named entity recognition\n(NER) and relation extraction (RE) in text span form. Recent studies have shown\nthat token labels can convey crucial task-specific information and enrich token\nsemantics. However, as far as we know, due to completely abstain from sequence\ntagging mechanism, all prior span-based work fails to use token label\nin-formation. To solve this problem, we pro-pose Sequence Tagging enhanced\nSpan-based Network (STSN), a span-based joint extrac-tion network that is\nenhanced by token BIO label information derived from sequence tag-ging based\nNER. By stacking multiple atten-tion layers in depth, we design a deep neu-ral\narchitecture to build STSN, and each atten-tion layer consists of three basic\nattention units. The deep neural architecture first learns seman-tic\nrepresentations for token labels and span-based joint extraction, and then\nconstructs in-formation interactions between them, which also realizes\nbidirectional information interac-tions between span-based NER and RE.\nFur-thermore, we extend the BIO tagging scheme to make STSN can extract\noverlapping en-tity. Experiments on three benchmark datasets show that our\nmodel consistently outperforms previous optimal models by a large margin,\ncreating new state-of-the-art results.",
          "link": "http://arxiv.org/abs/2105.10080",
          "publishedOn": "2021-05-24T07:23:02.205Z",
          "wordCount": 622,
          "title": "Boosting Span-based Joint Entity and Relation Extraction via Squence Tagging Mechanism. (arXiv:2105.10080v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zili Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1\">Marco Valentino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1\">Donal Landers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andre Freitas</a>",
          "description": "This paper describes N-XKT (Neural encoding based on eXplanatory Knowledge\nTransfer), a novel method for the automatic transfer of explanatory knowledge\nthrough neural encoding mechanisms. We demonstrate that N-XKT is able to\nimprove accuracy and generalization on science Question Answering (QA).\nSpecifically, by leveraging facts from background explanatory knowledge\ncorpora, the N-XKT model shows a clear improvement on zero-shot QA.\nFurthermore, we show that N-XKT can be fine-tuned on a target QA dataset,\n",
          "link": "http://arxiv.org/abs/2105.05737",
          "publishedOn": "2021-05-22T02:35:36.117Z",
          "wordCount": 554,
          "title": "Encoding Explanatory Knowledge for Zero-shot Science Question Answering. (arXiv:2105.05737v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06965",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prasad_G/0/1/0/all/0/1\">Grusha Prasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linzen_T/0/1/0/all/0/1\">Tal Linzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>",
          "description": "When language models process syntactically complex sentences, do they use\nabstract syntactic information present in these sentences in a manner that is\nconsistent with the grammar of English, or do they rely solely on a set of\nheuristics? We propose a method to tackle this question, AlterRep. For any\nlinguistic feature in the sentence, AlterRep allows us to generate\ncounterfactual representations by altering how this feature is encoded, while\nleaving all other aspects of the original representation intact. ",
          "link": "http://arxiv.org/abs/2105.06965",
          "publishedOn": "2021-05-22T02:35:36.111Z",
          "wordCount": 645,
          "title": "Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction. (arXiv:2105.06965v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leng_Y/0/1/0/all/0/1\">Yichong Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Linchen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Renqian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linquan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang-Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_E/0/1/0/all/0/1\">Ed Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Error correction techniques have been used to refine the output sentences\nfrom automatic speech recognition (ASR) models and achieve a lower word error\nrate (WER) than original ASR outputs. Previous works usually use a\nsequence-to-sequence model to correct an ASR output sentence autoregressively,\nwhich causes large latency and cannot be deployed in online ASR services. A\nstraightforward solution to reduce latency, inspired by non-autoregressive\n(NAR) neural machine translation, is to use an NAR sequence gen",
          "link": "http://arxiv.org/abs/2105.03842",
          "publishedOn": "2021-05-22T02:35:36.105Z",
          "wordCount": 751,
          "title": "FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition. (arXiv:2105.03842v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.05011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hazra_R/0/1/0/all/0/1\">Rishi Hazra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixit_S/0/1/0/all/0/1\">Sonu Dixit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1\">Sayambhu Sen</a>",
          "description": "Human language has been described as a system that makes \\textit{use of\nfinite means to express an unlimited array of thoughts}. Of particular interest\nis the aspect of compositionality, whereby, the meaning of a compound language\nexpression can be deduced from the meaning of its constituent parts. If\nartificial agents can develop compositional communication protocols akin to\nhuman language, they can be made to seamlessly generalize to unseen\ncombinations. However, the real question is, how do we induce com",
          "link": "http://arxiv.org/abs/2012.05011",
          "publishedOn": "2021-05-22T02:35:36.090Z",
          "wordCount": 674,
          "title": "Infinite use of finite means: Zero-Shot Generalization using Compositional Emergent Protocols. (arXiv:2012.05011v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1\">Tharindu Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zampieri_M/0/1/0/all/0/1\">Marcos Zampieri</a>",
          "description": "Offensive content is pervasive in social media and a reason for concern to\ncompanies and government organizations. Several studies have been recently\npublished investigating methods to detect the various forms of such content\n(e.g. hate speech, cyberbullying, and cyberaggression). The clear majority of\nthese studies deal with English partially because most annotated datasets\navailable contain English data. In this paper, we take advantage of available\nEnglish datasets by applying cross-lingual contextual wo",
          "link": "http://arxiv.org/abs/2105.05996",
          "publishedOn": "2021-05-22T02:35:36.075Z",
          "wordCount": 695,
          "title": "Multilingual Offensive Language Identification for Low-resource Languages. (arXiv:2105.05996v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03505",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_V/0/1/0/all/0/1\">Vanessa Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianxiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_R/0/1/0/all/0/1\">Rihao Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>",
          "description": "Learning prerequisite chains is an essential task for efficiently acquiring\nknowledge in both known and unknown domains. For example, one may be an expert\nin the natural language processing (NLP) domain but want to determine the best\norder to learn new concepts in an unfamiliar Computer Vision domain (CV). Both\ndomains share some common concepts, such as machine learning basics and deep\nlearning models. In this paper, we propose unsupervised cross-domain concept\nprerequisite chain learning using an optimize",
          "link": "http://arxiv.org/abs/2105.03505",
          "publishedOn": "2021-05-22T02:35:36.067Z",
          "wordCount": 588,
          "title": "Unsupervised Cross-Domain Prerequisite Chain Learning using Variational Graph Autoencoders. (arXiv:2105.03505v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xiyan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Wenming Xiao</a>",
          "description": "Lexicon information and pre-trained models, such as BERT, have been combined\nto explore Chinese sequence labelling tasks due to their respective strengths.\nHowever, existing methods solely fuse lexicon features via a shallow and random\ninitialized sequence layer and do not integrate them into the bottom layers of\nBERT. In this paper, we propose Lexicon Enhanced BERT (LEBERT) for Chinese\nsequence labelling, which integrates external lexicon knowledge into BERT\nlayers directly by a Lexicon Adapter layer. Comp",
          "link": "http://arxiv.org/abs/2105.07148",
          "publishedOn": "2021-05-22T02:35:36.057Z",
          "wordCount": 566,
          "title": "Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter. (arXiv:2105.07148v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.05947",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chandra_M/0/1/0/all/0/1\">Mohit Chandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pailla_D/0/1/0/all/0/1\">Dheeraj Pailla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_H/0/1/0/all/0/1\">Himanshu Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanchawala_A/0/1/0/all/0/1\">Aadilmehdi Sanchawala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_M/0/1/0/all/0/1\">Manish Shrivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1\">Ponnurangam Kumaraguru</a>",
          "description": "The exponential rise of online social media has enabled the creation,\ndistribution, and consumption of information at an unprecedented rate. However,\nit has also led to the burgeoning of various forms of online abuse. Increasing\ncases of online antisemitism have become one of the major concerns because of\nits socio-political consequences. Unlike other major forms of online abuse like\nracism, sexism, etc., online antisemitism has not been studied much from a\nmachine learning perspective. To the best of our k",
          "link": "http://arxiv.org/abs/2104.05947",
          "publishedOn": "2021-05-22T02:35:35.996Z",
          "wordCount": 668,
          "title": "\"Subverting the Jewtocracy\": Online Antisemitism Detection Using Multimodal Deep Learning. (arXiv:2104.05947v2 [cs.MM] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09680",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sungjoon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1\">Jihyung Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungdong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_W/0/1/0/all/0/1\">Won Ik Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiyoon Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jangwon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chisung Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junseong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yongsook Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1\">Taehwan Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joohong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Juhyun Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Sungwon Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1\">Younghoon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Inkwon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Sangwoo Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongjun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Myeonghwa Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1\">Seongbo Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_S/0/1/0/all/0/1\">Seungwon Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sunkyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_K/0/1/0/all/0/1\">Kyungtae Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jongwon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Kyumin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jamin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seonghyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_L/0/1/0/all/0/1\">Lucy Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1\">Jungwoo Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho Alice Oh Jungwoo Ha Kyunghyun Cho</a>",
          "description": "We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE\nis a collection of 8 Korean natural language understanding (NLU) tasks,\nincluding Topic Classification, Semantic Textual Similarity, Natural Language\nInference, Named Entity Recognition, Relation Extraction, Dependency Parsing,\nMachine Reading Comprehension, and Dialogue State Tracking. We build all of the\ntasks from scratch from diverse source corpora while respecting copyrights, to\nensure accessibility for anyone without any rest",
          "link": "http://arxiv.org/abs/2105.09680",
          "publishedOn": "2021-05-22T02:35:35.907Z",
          "wordCount": 735,
          "title": "KLUE: Korean Language Understanding Evaluation. (arXiv:2105.09680v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09660",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamborg_F/0/1/0/all/0/1\">Felix Hamborg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donnay_K/0/1/0/all/0/1\">Karsten Donnay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1\">Bela Gipp</a>",
          "description": "Extensive research on target-dependent sentiment classification (TSC) has led\nto strong classification performances in domains where authors tend to\nexplicitly express sentiment about specific entities or topics, such as in\nreviews or on social media. We investigate TSC in news articles, a much less\nresearched domain, despite the importance of news as an essential information\nsource in individual and societal decision making. This article introduces\nNewsTSC, a manually annotated dataset to explore TSC on ne",
          "link": "http://arxiv.org/abs/2105.09660",
          "publishedOn": "2021-05-22T02:35:35.900Z",
          "wordCount": 621,
          "title": "Towards Target-dependent Sentiment Classification in News Articles. (arXiv:2105.09660v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.11574",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1\">Jan Christian Blaise Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Resabal_J/0/1/0/all/0/1\">Jose Kristian Resabal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">James Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velasco_D/0/1/0/all/0/1\">Dan John Velasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Charibeth Cheng</a>",
          "description": "Transformers represent the state-of-the-art in Natural Language Processing\n(NLP) in recent years, proving effective even in tasks done in low-resource\nlanguages. While pretrained transformers for these languages can be made, it is\nchallenging to measure their true performance and capacity due to the lack of\nhard benchmark datasets, as well as the difficulty and cost of producing them.\nIn this paper, we present three contributions: First, we propose a methodology\nfor automatically producing Natural Language ",
          "link": "http://arxiv.org/abs/2010.11574",
          "publishedOn": "2021-05-22T02:35:35.892Z",
          "wordCount": 649,
          "title": "Exploiting News Article Structure for Automatic Corpus Generation. (arXiv:2010.11574v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sodhi_S/0/1/0/all/0/1\">Sukhdeep S. Sodhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chio_E/0/1/0/all/0/1\">Ellie Ka-In Chio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jash_A/0/1/0/all/0/1\">Ambarish Jash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1\">Santiago Onta&#xf1;&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apte_A/0/1/0/all/0/1\">Ajit Apte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Ankit Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeje_A/0/1/0/all/0/1\">Ayooluwakunmi Jeje</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuzmin_D/0/1/0/all/0/1\">Dima Kuzmin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_H/0/1/0/all/0/1\">Harry Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Tze Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Effrat_J/0/1/0/all/0/1\">Jon Effrat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bali_T/0/1/0/all/0/1\">Tarush Bali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1\">Nitin Jindal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_P/0/1/0/all/0/1\">Pei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sarvjeet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Senqiang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1\">Tameen Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wankhede_A/0/1/0/all/0/1\">Amol Wankhede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alzantot_M/0/1/0/all/0/1\">Moustafa Alzantot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Allen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_T/0/1/0/all/0/1\">Tushar Chandra</a>",
          "description": "As more and more online search queries come from voice, automatic speech\nrecognition becomes a key component to deliver relevant search results. Errors\nintroduced by automatic speech recognition (ASR) lead to irrelevant search\nresults returned to the user, thus causing user dissatisfaction. In this paper,\nwe introduce an approach, Mondegreen, to correct voice queries in text space\nwithout depending on audio signals, which may not always be available due to\nsystem constraints or privacy or bandwidth (for exa",
          "link": "http://arxiv.org/abs/2105.09930",
          "publishedOn": "2021-05-22T02:35:35.886Z",
          "wordCount": 678,
          "title": "Mondegreen: A Post-Processing Solution to Speech Recognition Error Correction for Voice Search Queries. (arXiv:2105.09930v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2006.16362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cordonnier_J/0/1/0/all/0/1\">Jean-Baptiste Cordonnier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loukas_A/0/1/0/all/0/1\">Andreas Loukas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>",
          "description": "Attention layers are widely used in natural language processing (NLP) and are\nbeginning to influence computer vision architectures. Training very large\ntransformer models allowed significant improvement in both fields, but once\ntrained, these networks show symptoms of over-parameterization. For instance,\nit is known that many attention heads can be pruned without impacting accuracy.\nThis work aims to enhance current understanding on how multiple heads interact.\nMotivated by the observation that attention he",
          "link": "http://arxiv.org/abs/2006.16362",
          "publishedOn": "2021-05-22T02:35:35.869Z",
          "wordCount": 628,
          "title": "Multi-Head Attention: Collaborate Instead of Concatenate. (arXiv:2006.16362v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09938",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1\">Dan Hendrycks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1\">Steven Basart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadavath_S/0/1/0/all/0/1\">Saurav Kadavath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazeika_M/0/1/0/all/0/1\">Mantas Mazeika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1\">Akul Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_E/0/1/0/all/0/1\">Ethan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burns_C/0/1/0/all/0/1\">Collin Burns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puranik_S/0/1/0/all/0/1\">Samir Puranik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Horace He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>",
          "description": "While programming is one of the most broadly applicable skills in modern\nsociety, modern machine learning models still cannot code solutions to basic\nproblems. It can be difficult to accurately assess code generation performance,\nand there has been surprisingly little work on evaluating code generation in a\nway that is both flexible and rigorous. To meet this challenge, we introduce\nAPPS, a benchmark for code generation. Unlike prior work in more restricted\nsettings, our benchmark measures the ability of mo",
          "link": "http://arxiv.org/abs/2105.09938",
          "publishedOn": "2021-05-22T02:35:35.861Z",
          "wordCount": 662,
          "title": "Measuring Coding Challenge Competence With APPS. (arXiv:2105.09938v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09835",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zuchao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Junru Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parnow_K/0/1/0/all/0/1\">Kevin Parnow</a>",
          "description": "Constituent and dependency parsing, the two classic forms of syntactic\nparsing, have been found to benefit from joint training and decoding under a\nuniform formalism, Head-driven Phrase Structure Grammar (HPSG). However,\ndecoding this unified grammar has a higher time complexity ($O(n^5)$) than\ndecoding either form individually ($O(n^3)$) since more factors have to be\nconsidered during decoding. We thus propose an improved head scorer that helps\nachieve a novel performance-preserved parser in $O$($n^3$) tim",
          "link": "http://arxiv.org/abs/2105.09835",
          "publishedOn": "2021-05-22T02:35:35.853Z",
          "wordCount": 552,
          "title": "Head-driven Phrase Structure Parsing in O($n^3$) Time Complexity. (arXiv:2105.09835v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2012.00955",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhengbao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Araki_J/0/1/0/all/0/1\">Jun Araki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1\">Haibo Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>",
          "description": "Recent works have shown that language models (LM) capture different types of\nknowledge regarding facts or common sense. However, because no model is\nperfect, they still fail to provide appropriate answers in many cases. In this\npaper, we ask the question \"how can we know when language models know, with\nconfidence, the answer to a particular query?\" We examine this question from\nthe point of view of calibration, the property of a probabilistic model's\npredicted probabilities actually being well correlated wi",
          "link": "http://arxiv.org/abs/2012.00955",
          "publishedOn": "2021-05-22T02:35:35.846Z",
          "wordCount": 672,
          "title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering. (arXiv:2012.00955v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.15409",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Can Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1\">Guocheng Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xinyan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiachen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>",
          "description": "Existed pre-training methods either focus on single-modal tasks or\nmulti-modal tasks, and cannot effectively adapt to each other. They can only\nutilize single-modal data (i.e. text or image) or limited multi-modal data\n(i.e. image-text pairs). In this work, we propose a unified-modal pre-training\narchitecture, namely UNIMO, which can effectively adapt to both single-modal\nand multi-modal understanding and generation tasks. Large scale of free text\ncorpus and image collections can be utilized to improve the ",
          "link": "http://arxiv.org/abs/2012.15409",
          "publishedOn": "2021-05-22T02:35:35.838Z",
          "wordCount": 665,
          "title": "UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning. (arXiv:2012.15409v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09867",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Scontras_G/0/1/0/all/0/1\">Gregory Scontras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tessler_M/0/1/0/all/0/1\">Michael Henry Tessler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franke_M/0/1/0/all/0/1\">Michael Franke</a>",
          "description": "Recent advances in computational cognitive science (i.e., simulation-based\nprobabilistic programs) have paved the way for significant progress in formal,\nimplementable models of pragmatics. Rather than describing a pragmatic\nreasoning process in prose, these models formalize and implement one, deriving\nboth qualitative and quantitative predictions of human behavior -- predictions\nthat consistently prove correct, demonstrating the viability and value of the\nframework. The current paper provides a practical i",
          "link": "http://arxiv.org/abs/2105.09867",
          "publishedOn": "2021-05-22T02:35:35.829Z",
          "wordCount": 522,
          "title": "A practical introduction to the Rational Speech Act modeling framework. (arXiv:2105.09867v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2010.07414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nejadgholi_I/0/1/0/all/0/1\">Isar Nejadgholi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiritchenko_S/0/1/0/all/0/1\">Svetlana Kiritchenko</a>",
          "description": "NLP research has attained high performances in abusive language detection as\na supervised classification task. While in research settings, training and test\ndatasets are usually obtained from similar data samples, in practice systems\nare often applied on data that are different from the training set in topic and\nclass distributions. Also, the ambiguity in class definitions inherited in this\ntask aggravates the discrepancies between source and target datasets. We\nexplore the topic bias and the task formulati",
          "link": "http://arxiv.org/abs/2010.07414",
          "publishedOn": "2021-05-22T02:35:35.810Z",
          "wordCount": 628,
          "title": "On Cross-Dataset Generalization in Automatic Detection of Online Abuse. (arXiv:2010.07414v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lenci_A/0/1/0/all/0/1\">Alessandro Lenci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahlgren_M/0/1/0/all/0/1\">Magnus Sahlgren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeuniaux_P/0/1/0/all/0/1\">Patrick Jeuniaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyllensten_A/0/1/0/all/0/1\">Amaru Cuba Gyllensten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miliani_M/0/1/0/all/0/1\">Martina Miliani</a>",
          "description": "Distributional semantics has deeply changed in the last decades. First,\npredict models stole the thunder from traditional count ones, and more recently\nboth of them were replaced in many NLP applications by contextualized vectors\nproduced by Transformer neural language models. Although an extensive body of\nresearch has been devoted to Distributional Semantic Model (DSM) evaluation, we\nstill lack a thorough comparison with respect to tested models, semantic tasks,\nand benchmark datasets. Moreover, previous w",
          "link": "http://arxiv.org/abs/2105.09825",
          "publishedOn": "2021-05-22T02:35:35.798Z",
          "wordCount": 663,
          "title": "A comprehensive comparative evaluation and analysis of Distributional Semantic Models. (arXiv:2105.09825v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Aashish Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zesch_T/0/1/0/all/0/1\">Torsten Zesch</a>",
          "description": "When evaluating the performance of automatic speech recognition models,\nusually word error rate within a certain dataset is used. Special care must be\ntaken in understanding the dataset in order to report realistic performance\nnumbers. We argue that many performance numbers reported probably underestimate\nthe expected error rate. We conduct experiments controlling for selection bias,\ngender as well as overlap (between training and test data) in content, voices,\nand recording conditions. We find that content",
          "link": "http://arxiv.org/abs/2105.09742",
          "publishedOn": "2021-05-22T02:35:35.788Z",
          "wordCount": 532,
          "title": "Robustness of end-to-end Automatic Speech Recognition Models -- A Case Study using Mozilla DeepSpeech. (arXiv:2105.09742v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1\">Patrick Lumban Tobing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>",
          "description": "This paper presents a novel high-fidelity and low-latency universal neural\nvocoder framework based on multiband WaveRNN with data-driven linear prediction\nfor discrete waveform modeling (MWDLP). MWDLP employs a coarse-fine bit WaveRNN\narchitecture for 10-bit mu-law waveform modeling. A sparse gated recurrent unit\nwith a relatively large size of hidden units is utilized, while the multiband\nmodeling is deployed to achieve real-time low-latency usage. A novel technique\nfor data-driven linear prediction (LP) w",
          "link": "http://arxiv.org/abs/2105.09856",
          "publishedOn": "2021-05-22T02:35:35.768Z",
          "wordCount": 635,
          "title": "High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling. (arXiv:2105.09856v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2005.01107",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lopez_L/0/1/0/all/0/1\">Luis Enrico Lopez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_D/0/1/0/all/0/1\">Diane Kathryn Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1\">Jan Christian Blaise Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Charibeth Cheng</a>",
          "description": "Question generation (QG) is a natural language generation task where a model\nis trained to ask questions corresponding to some input text. Most recent\napproaches frame QG as a sequence-to-sequence problem and rely on additional\nfeatures and mechanisms to increase performance; however, these often increase\nmodel complexity, and can rely on auxiliary data unavailable in practical use.\nA single Transformer-based unidirectional language model leveraging transfer\nlearning can be used to produce high quality ques",
          "link": "http://arxiv.org/abs/2005.01107",
          "publishedOn": "2021-05-22T02:35:35.758Z",
          "wordCount": 646,
          "title": "Simplifying Paragraph-level Question Generation via Transformer Language Models. (arXiv:2005.01107v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1\">Patrick Lumban Tobing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>",
          "description": "This paper presents a low-latency real-time (LLRT) non-parallel voice\nconversion (VC) framework based on cyclic variational autoencoder (CycleVAE)\nand multiband WaveRNN with data-driven linear prediction (MWDLP). CycleVAE is a\nrobust non-parallel multispeaker spectral model, which utilizes a\nspeaker-independent latent space and a speaker-dependent code to generate\nreconstructed/converted spectral features given the spectral features of an\ninput speaker. On the other hand, MWDLP is an efficient and a high-qu",
          "link": "http://arxiv.org/abs/2105.09858",
          "publishedOn": "2021-05-22T02:35:35.748Z",
          "wordCount": 646,
          "title": "Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear Prediction. (arXiv:2105.09858v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2010.10391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michalopoulos_G/0/1/0/all/0/1\">George Michalopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuanxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaka_H/0/1/0/all/0/1\">Hussam Kaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Helen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alexander Wong</a>",
          "description": "Contextual word embedding models, such as BioBERT and Bio_ClinicalBERT, have\nachieved state-of-the-art results in biomedical natural language processing\ntasks by focusing their pre-training process on domain-specific corpora.\nHowever, such models do not take into consideration expert domain knowledge.\n\nIn this work, we introduced UmlsBERT, a contextual embedding model that\nintegrates domain knowledge during the pre-training process via a novel\nknowledge augmentation strategy. More specifically, the augmenta",
          "link": "http://arxiv.org/abs/2010.10391",
          "publishedOn": "2021-05-22T02:35:35.735Z",
          "wordCount": 642,
          "title": "UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus. (arXiv:2010.10391v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.06269",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hettiarachchi_H/0/1/0/all/0/1\">Hansi Hettiarachchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1\">Tharindu Ranasinghe</a>",
          "description": "This paper presents the team BRUMS submission to SemEval-2020 Task 3: Graded\nWord Similarity in Context. The system utilises state-of-the-art contextualised\nword embeddings, which have some task-specific adaptations, including stacked\nembeddings and average embeddings. Overall, the approach achieves good\nevaluation scores across all the languages, while maintaining simplicity.\nFollowing the final rankings, our approach is ranked within the top 5 solutions\nof each language while preserving the 1st position o",
          "link": "http://arxiv.org/abs/2010.06269",
          "publishedOn": "2021-05-22T02:35:35.725Z",
          "wordCount": 556,
          "title": "BRUMS at SemEval-2020 Task 3: Contextualised Embeddings for Predicting the (Graded) Effect of Context in Word Similarity. (arXiv:2010.06269v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09649",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zixiu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1\">Rim Helaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vivek Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1\">Diego Reforgiato Recupero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1\">Daniele Riboni</a>",
          "description": "Empathetic response from the therapist is key to the success of clinical\npsychotherapy, especially motivational interviewing. Previous work on\ncomputational modelling of empathy in motivational interviewing has focused on\noffline, session-level assessment of therapist empathy, where empathy captures\nall efforts that the therapist makes to understand the client's perspective and\nconvey that understanding to the client. In this position paper, we propose a\nnovel task of turn-level detection of client need for",
          "link": "http://arxiv.org/abs/2105.09649",
          "publishedOn": "2021-05-22T02:35:35.716Z",
          "wordCount": 586,
          "title": "Towards Detecting Need for Empathetic Response in Motivational Interviewing. (arXiv:2105.09649v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1\">Danilo Dessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1\">Rim Helaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vivek Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1\">Diego Reforgiato Recupero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1\">Daniele Riboni</a>",
          "description": "Today, we are seeing an ever-increasing number of clinical notes that contain\nclinical results, images, and textual descriptions of patient's health state.\nAll these data can be analyzed and employed to cater novel services that can\nhelp people and domain experts with their common healthcare tasks. However,\nmany technologies such as Deep Learning and tools like Word Embeddings have\nstarted to be investigated only recently, and many challenges remain open when\nit comes to healthcare domain applications. To a",
          "link": "http://arxiv.org/abs/2105.09632",
          "publishedOn": "2021-05-22T02:35:35.623Z",
          "wordCount": 680,
          "title": "TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09702",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Profitlich_H/0/1/0/all/0/1\">Hans-J&#xfc;rgen Profitlich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonntag_D/0/1/0/all/0/1\">Daniel Sonntag</a>",
          "description": "We describe our work on information extraction in medical documents written\nin German, especially detecting negations using an architecture based on the\nUIMA pipeline. Based on our previous work on software modules to cover medical\nconcepts like diagnoses, examinations, etc. we employ a version of the NegEx\nregular expression algorithm with a large set of triggers as a baseline. We\nshow how a significantly smaller trigger set is sufficient to achieve similar\nresults, in order to reduce adaptation times to n",
          "link": "http://arxiv.org/abs/2105.09702",
          "publishedOn": "2021-05-22T02:35:35.575Z",
          "wordCount": 571,
          "title": "A Case Study on Pros and Cons of Regular Expression Detection and Dependency Parsing for Negation Extraction from German Medical Documents. Technical Report. (arXiv:2105.09702v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09816",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1\">Sebastian Hofst&#xe4;tter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_B/0/1/0/all/0/1\">Bhaskar Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1\">Hamed Zamani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Craswell_N/0/1/0/all/0/1\">Nick Craswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1\">Allan Hanbury</a>",
          "description": "An emerging recipe for achieving state-of-the-art effectiveness in neural\ndocument re-ranking involves utilizing large pre-trained language models -\ne.g., BERT - to evaluate all individual passages in the document and then\naggregating the outputs by pooling or additional Transformer layers. A major\ndrawback of this approach is high query latency due to the cost of evaluating\nevery passage in the document with BERT. To make matters worse, this high\ninference cost and latency varies based on the length of the",
          "link": "http://arxiv.org/abs/2105.09816",
          "publishedOn": "2021-05-22T02:35:35.534Z",
          "wordCount": 659,
          "title": "Intra-Document Cascading: Learning to Select Passages for Neural Document Ranking. (arXiv:2105.09816v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Atri_Y/0/1/0/all/0/1\">Yash Kumar Atri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pramanick_S/0/1/0/all/0/1\">Shraman Pramanick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_V/0/1/0/all/0/1\">Vikram Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>",
          "description": "In recent years, abstractive text summarization with multimodal inputs has\nstarted drawing attention due to its ability to accumulate information from\ndifferent source modalities and generate a fluent textual summary. However,\nexisting methods use short videos as the visual modality and short summary as\nthe ground-truth, therefore, perform poorly on lengthy videos and long\nground-truth summary. Additionally, there exists no benchmark dataset to\ngeneralize this task on videos of varying lengths. In this pape",
          "link": "http://arxiv.org/abs/2105.09601",
          "publishedOn": "2021-05-22T02:35:35.505Z",
          "wordCount": 667,
          "title": "See, Hear, Read: Leveraging Multimodality with Guided Attention for Abstractive Text Summarization. (arXiv:2105.09601v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09458",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lou_D/0/1/0/all/0/1\">Dongfang Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Z/0/1/0/all/0/1\">Zhilin Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>",
          "description": "We consider the problem of collectively detecting multiple events,\nparticularly in cross-sentence settings. The key to dealing with the problem is\nto encode semantic information and model event inter-dependency at a\ndocument-level. In this paper, we reformulate it as a Seq2Seq task and propose\na Multi-Layer Bidirectional Network (MLBiNet) to capture the document-level\nassociation of events and semantic information simultaneously. Specifically, a\nbidirectional decoder is firstly devised to model event inter-",
          "link": "http://arxiv.org/abs/2105.09458",
          "publishedOn": "2021-05-22T02:35:35.491Z",
          "wordCount": 569,
          "title": "MLBiNet: A Cross-Sentence Collective Event Detection Network. (arXiv:2105.09458v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09611",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_Gonzalez_D/0/1/0/all/0/1\">Daniel Fern&#xe1;ndez-Gonz&#xe1;lez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_C/0/1/0/all/0/1\">Carlos G&#xf3;mez-Rodr&#xed;guez</a>",
          "description": "Dependency parsing is a crucial step towards deep language understanding and,\ntherefore, widely demanded by numerous Natural Language Processing\napplications. In particular, left-to-right and top-down transition-based\nalgorithms that rely on Pointer Networks are among the most accurate approaches\nfor performing dependency parsing. Additionally, it has been observed for the\ntop-down algorithm that Pointer Networks' sequential decoding can be improved\nby implementing a hierarchical variant, more adequate to m",
          "link": "http://arxiv.org/abs/2105.09611",
          "publishedOn": "2021-05-22T02:35:35.476Z",
          "wordCount": 583,
          "title": "Dependency Parsing with Bottom-up Hierarchical Pointer Networks. (arXiv:2105.09611v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09404",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Ling Liu</a>",
          "description": "Neural network approaches have been applied to computational morphology with\ngreat success, improving the performance of most tasks by a large margin and\nproviding new perspectives for modeling. This paper starts with a brief\nintroduction to computational morphology, followed by a review of recent work\non computational morphology with neural network approaches, to provide an\noverview of the area. In the end, we will analyze the advantages and problems\nof neural network approaches to computational morphology",
          "link": "http://arxiv.org/abs/2105.09404",
          "publishedOn": "2021-05-22T02:35:35.455Z",
          "wordCount": 505,
          "title": "Computational Morphology with Neural Network Approaches. (arXiv:2105.09404v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09571",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gloor_P/0/1/0/all/0/1\">P. Gloor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colladon_A/0/1/0/all/0/1\">A. Fronzetti Colladon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giacomelli_G/0/1/0/all/0/1\">G. Giacomelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saran_T/0/1/0/all/0/1\">T. Saran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grippa_F/0/1/0/all/0/1\">F. Grippa</a>",
          "description": "We investigate the impact of a novel method called \"virtual mirroring\" to\npromote employee self-reflection and impact customer satisfaction. The method\nis based on measuring communication patterns, through social network and\nsemantic analysis, and mirroring them back to the individual. Our goal is to\ndemonstrate that self-reflection can trigger a change in communication\nbehaviors, which lead to increased customer satisfaction. We illustrate and\ntest our approach analyzing e-mails of a large global services ",
          "link": "http://arxiv.org/abs/2105.09571",
          "publishedOn": "2021-05-22T02:35:35.445Z",
          "wordCount": 611,
          "title": "The impact of virtual mirroring on customer satisfaction. (arXiv:2105.09571v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Existing multilingual machine translation approaches mainly focus on\nEnglish-centric directions, while the non-English directions still lag behind.\nIn this work, we aim to build a many-to-many translation system with an\nemphasis on the quality of non-English language directions. Our intuition is\nbased on the hypothesis that a universal cross-language representation leads to\nbetter multilingual translation performance. To this end, we propose \\method, a\ntraining method to obtain a single unified multilingual",
          "link": "http://arxiv.org/abs/2105.09501",
          "publishedOn": "2021-05-22T02:35:35.421Z",
          "wordCount": 576,
          "title": "Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_K/0/1/0/all/0/1\">Keyue Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yuzhuo Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhiyu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Distantly supervised (DS) relation extraction (RE) has attracted much\nattention in the past few years as it can utilize large-scale auto-labeled\ndata. However, its evaluation has long been a problem: previous works either\ntook costly and inconsistent methods to manually examine a small sample of\nmodel predictions, or directly test models on auto-labeled data -- which, by\nour check, produce as much as 53% wrong labels at the entity pair level in the\npopular NYT10 dataset. This problem has not only led to ina",
          "link": "http://arxiv.org/abs/2105.09543",
          "publishedOn": "2021-05-22T02:35:35.409Z",
          "wordCount": 643,
          "title": "Manual Evaluation Matters: Reviewing Test Protocols of Distantly Supervised Relation Extraction. (arXiv:2105.09543v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09392",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mai_G/0/1/0/all/0/1\">Gengchen Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janowicz_K/0/1/0/all/0/1\">Krzysztof Janowicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Rui Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1\">Ling Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lao_N/0/1/0/all/0/1\">Ni Lao</a>",
          "description": "As an important part of Artificial Intelligence (AI), Question Answering (QA)\naims at generating answers to questions phrased in natural language. While\nthere has been substantial progress in open-domain question answering, QA\nsystems are still struggling to answer questions which involve geographic\nentities or concepts and that require spatial operations. In this paper, we\ndiscuss the problem of geographic question answering (GeoQA). We first\ninvestigate the reasons why geographic questions are difficult t",
          "link": "http://arxiv.org/abs/2105.09392",
          "publishedOn": "2021-05-22T02:35:35.399Z",
          "wordCount": 595,
          "title": "Geographic Question Answering: Challenges, Uniqueness, Classification, and Future Directions. (arXiv:2105.09392v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09428",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lahlou_C/0/1/0/all/0/1\">Chuhong Lahlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crayton_A/0/1/0/all/0/1\">Ancil Crayton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trier_C/0/1/0/all/0/1\">Caroline Trier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willett_E/0/1/0/all/0/1\">Evan Willett</a>",
          "description": "In 2019, The Centers for Medicare and Medicaid Services (CMS) launched an\nArtificial Intelligence (AI) Health Outcomes Challenge seeking solutions to\npredict risk in value-based care for incorporation into CMS Innovation Center\npayment and service delivery models. Recently, modern language models have\nplayed key roles in a number of health related tasks. This paper presents, to\nthe best of our knowledge, the first application of these models to patient\nreadmission prediction. To facilitate this, we create a",
          "link": "http://arxiv.org/abs/2105.09428",
          "publishedOn": "2021-05-22T02:35:35.376Z",
          "wordCount": 592,
          "title": "Explainable Health Risk Predictor with Transformer-based Medicare Claim Encoder. (arXiv:2105.09428v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09653",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bestgen_Y/0/1/0/all/0/1\">Yves Bestgen</a>",
          "description": "This paper describes the system developed by the Laboratoire d'analyse\nstatistique des textes (LAST) for the Lexical Complexity Prediction shared task\nat SemEval-2021. The proposed system is made up of a LightGBM model fed with\nfeatures obtained from many word frequency lists, published lexical norms and\npsychometric data. For tackling the specificity of the multi-word task, it uses\nbigram association measures. Despite that the only contextual feature used was\nsentence length, the system achieved an honorab",
          "link": "http://arxiv.org/abs/2105.09653",
          "publishedOn": "2021-05-22T02:35:35.359Z",
          "wordCount": 533,
          "title": "LAST at SemEval-2021 Task 1: Improving Multi-Word Complexity Prediction Using Bigram Association Measures. (arXiv:2105.09653v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09509",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1\">Shirong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongtong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1\">Guilin Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuan-Fang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_S/0/1/0/all/0/1\">Sheng Bi</a>",
          "description": "Event detection (ED) aims at detecting event trigger words in sentences and\nclassifying them into specific event types. In real-world applications, ED\ntypically does not have sufficient labelled data, thus can be formulated as a\nfew-shot learning problem. To tackle the issue of low sample diversity in\nfew-shot ED, we propose a novel knowledge-based few-shot event detection method\nwhich uses a definition-based encoder to introduce external event knowledge as\nthe knowledge prior of event types. Furthermore, a",
          "link": "http://arxiv.org/abs/2105.09509",
          "publishedOn": "2021-05-22T02:35:35.337Z",
          "wordCount": 568,
          "title": "Adaptive Knowledge-Enhanced Bayesian Meta-Learning for Few-shot Event Detection. (arXiv:2105.09509v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09567",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lianwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1\">Yuan Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yuqian Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Ling Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1\">Zhaoyin Qi</a>",
          "description": "Recent studies constructing direct interactions between the claim and each\nsingle user response (a comment or a relevant article) to capture evidence have\nshown remarkable success in interpretable claim verification. Owing to\ndifferent single responses convey different cognition of individual users\n(i.e., audiences), the captured evidence belongs to the perspective of\nindividual cognition. However, individuals' cognition of social things is not\nalways able to truly reflect the objective. There may be one-si",
          "link": "http://arxiv.org/abs/2105.09567",
          "publishedOn": "2021-05-22T02:35:35.305Z",
          "wordCount": 672,
          "title": "Unified Dual-view Cognitive Model for Interpretable Claim Verification. (arXiv:2105.09567v1 [cs.CL])"
        }
      ]
    },
    {
      "title": "cs.CV updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.CV",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2105.08059",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Korkmaz_Y/0/1/0/all/0/1\">Yilmaz Korkmaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dar_S/0/1/0/all/0/1\">Salman UH Dar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yurt_M/0/1/0/all/0/1\">Mahmut Yurt</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ozbey_M/0/1/0/all/0/1\">Muzaffer &#xd6;zbey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cukur_T/0/1/0/all/0/1\">Tolga &#xc7;ukur</a>",
          "description": "Supervised deep learning has swiftly become a workhorse for accelerated MRI\nin recent years, offering state-of-the-art performance in image reconstruction\nfrom undersampled acquisitions. Training deep supervised models requires large\ndatasets of undersampled and fully-sampled acquisitions typically from a\nmatching set of subjects. Given scarce access to large medical datasets, this\nlimitation has sparked interest in unsupervised methods that reduce reliance on\nfully-sampled ground-truth data. A common framework is based on the deep image\nprior, where network-driven regularization is enforced directly during\ninference on undersampled acquisitions. Yet, canonical convolutional\narchitectures are suboptimal in capturing long-range relationships, and\nrandomly initialized networks may hamper convergence. To address these\nlimitations, here we introduce a novel unsupervised MRI reconstruction method\nbased on zero-Shot Learned Adversarial TransformERs (SLATER). SLATER embodies a\ndeep adversarial network with cross-attention transformer blocks to map noise\nand latent variables onto MR images. This unconditional network learns a\nhigh-quality MRI prior in a self-supervised encoding task. A zero-shot\nreconstruction is performed on undersampled test data, where inference is\nperformed by optimizing network parameters, latent and noise variables to\nensure maximal consistency to multi-coil MRI data. Comprehensive experiments on\nbrain MRI datasets clearly demonstrate the superior performance of SLATER\nagainst several state-of-the-art unsupervised methods.",
          "link": "http://arxiv.org/abs/2105.08059",
          "publishedOn": "2021-05-24T07:23:08.831Z",
          "wordCount": 666,
          "title": "Unsupervised MRI Reconstruction via Zero-Shot Learned Adversarial Transformers. (arXiv:2105.08059v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.11958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Etten_A/0/1/0/all/0/1\">Adam Van Etten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hogan_D/0/1/0/all/0/1\">Daniel Hogan</a>",
          "description": "Building footprints provide a useful proxy for a great many humanitarian\napplications. For example, building footprints are useful for high fidelity\npopulation estimates, and quantifying population statistics is fundamental to\n~1/4 of the United Nations Sustainable Development Goals Indicators. In this\npaper we (the SpaceNet Partners) discuss efforts to develop techniques for\nprecise building footprint localization, tracking, and change detection via the\nSpaceNet Multi-Temporal Urban Development Challenge (also known as SpaceNet 7).\nIn this NeurIPS 2020 competition, participants were asked identify and track\nbuildings in satellite imagery time series collected over rapidly urbanizing\nareas. The competition centered around a brand new open source dataset of\nPlanet Labs satellite imagery mosaics at 4m resolution, which includes 24\nimages (one per month) covering ~100 unique geographies. Tracking individual\nbuildings at this resolution is quite challenging, yet the winning participants\ndemonstrated impressive performance with the newly developed SpaceNet Change\nand Object Tracking (SCOT) metric. This paper details the top-5 winning\napproaches, as well as analysis of results that yielded a handful of\ninteresting anecdotes such as decreasing performance with latitude.",
          "link": "http://arxiv.org/abs/2102.11958",
          "publishedOn": "2021-05-24T07:23:08.826Z",
          "wordCount": 652,
          "title": "The SpaceNet Multi-Temporal Urban Development Challenge. (arXiv:2102.11958v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10420",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Silva_Rodriguez_J/0/1/0/all/0/1\">Julio Silva-Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Colomer_A/0/1/0/all/0/1\">Adri&#xe1;n Colomer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dolz_J/0/1/0/all/0/1\">Jose Dolz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Naranjo_V/0/1/0/all/0/1\">Valery Naranjo</a>",
          "description": "Prostate cancer is one of the main diseases affecting men worldwide. The gold\nstandard for diagnosis and prognosis is the Gleason grading system. In this\nprocess, pathologists manually analyze prostate histology slides under\nmicroscope, in a high time-consuming and subjective task. In the last years,\ncomputer-aided-diagnosis (CAD) systems have emerged as a promising tool that\ncould support pathologists in the daily clinical practice. Nevertheless, these\nsystems are usually trained using tedious and prone-to-error pixel-level\nannotations of Gleason grades in the tissue. To alleviate the need of manual\npixel-wise labeling, just a handful of works have been presented in the\nliterature. Motivated by this, we propose a novel weakly-supervised\ndeep-learning model, based on self-learning CNNs, that leverages only the\nglobal Gleason score of gigapixel whole slide images during training to\naccurately perform both, grading of patch-level patterns and biopsy-level\nscoring. To evaluate the performance of the proposed method, we perform\nextensive experiments on three different external datasets for the patch-level\nGleason grading, and on two different test sets for global Grade Group\nprediction. We empirically demonstrate that our approach outperforms its\nsupervised counterpart on patch-level Gleason grading by a large margin, as\nwell as state-of-the-art methods on global biopsy-level scoring. Particularly,\nthe proposed model brings an average improvement on the Cohen's quadratic kappa\n(k) score of nearly 18% compared to full-supervision for the patch-level\nGleason grading task.",
          "link": "http://arxiv.org/abs/2105.10420",
          "publishedOn": "2021-05-24T07:23:08.730Z",
          "wordCount": 674,
          "title": "Self-learning for weakly supervised Gleason grading of local patterns. (arXiv:2105.10420v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2011.14714",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chuang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1\">Zhitong Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mulin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuelong Li</a>",
          "description": "Recently, text detection has attracted sufficient attention in the field of\ncomputer vision and artificial intelligence. Among the existing approaches,\nregression-based models are limited to handle the texts with arbitrary shapes,\nwhile segmentation-based algorithms have high computational costs and suffer\nfrom the text adhesion problem. In this paper, we propose a new one-stage text\ndetector, termed as Bold Outline Text Detector (BOTD), which is able to process\nthe arbitrary-shaped text with low model complexity. Different from previous\nworks, BOTD utilizes the Polar Minimum Distance (PMD) to encode the shortest\ndistance between the center point and the contour of the text instance, and\ngenerates a Center Mask (CM) for each text instance. After learning the PMD\nheat map and CM map, the final results can be obtained with a simple Text\nReconstruction Module (TRM). Since the CM resides within the text box exactly,\nthe text adhesion problem is avoided naturally. Meanwhile, all the points on\nthe text contour share the same PMD, so the complexity of BOTD is much lower\nthan existing segmentation-based methods. Experimental results on three\nreal-world benchmarks show the state-of-the-art performance of BOTD.",
          "link": "http://arxiv.org/abs/2011.14714",
          "publishedOn": "2021-05-24T07:23:08.665Z",
          "wordCount": 675,
          "title": "BOTD: Bold Outline Text Detector. (arXiv:2011.14714v6 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khoshsirat_A/0/1/0/all/0/1\">Aria Khoshsirat</a>",
          "description": "Quantifying uncertainty in a model's predictions is important as it enables\nthe safety of an AI system to be increased by acting on the model's output in\nan informed manner. This is crucial for applications where the cost of an error\nis high, such as in autonomous vehicle control, medical image analysis,\nfinancial estimations or legal fields. Deep Neural Networks are powerful\npredictors that have recently achieved state-of-the-art performance on a wide\nspectrum of tasks. Quantifying predictive uncertainty in DNNs is a challenging\nand yet on-going problem. In this paper we propose a complete framework to\ncapture and quantify all of these three types of uncertainties in DNNs for\nimage classification. This framework includes an ensemble of CNNs for model\nuncertainty, a supervised reconstruction auto-encoder to capture distributional\nuncertainty and using the output of activation functions in the last layer of\nthe network, to capture data uncertainty. Finally we demonstrate the efficiency\nof our method on popular image datasets for classification.",
          "link": "http://arxiv.org/abs/2011.08712",
          "publishedOn": "2021-05-24T07:23:08.659Z",
          "wordCount": 651,
          "title": "Quantifying Uncertainty from Different Sources in Deep Neural Networks for Image Classification. (arXiv:2011.08712v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10490",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Silva_Rodriguez_J/0/1/0/all/0/1\">Julio Silva-Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Colomer_A/0/1/0/all/0/1\">Adri&#xe1;n Colomer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sales_M/0/1/0/all/0/1\">Mar&#xed;a A. Sales</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Molina_R/0/1/0/all/0/1\">Rafael Molina</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Naranjo_V/0/1/0/all/0/1\">Valery Naranjo</a>",
          "description": "The Gleason scoring system is the primary diagnostic and prognostic tool for\nprostate cancer. In recent years, with the development of digitisation devices,\nthe use of computer vision techniques for the analysis of biopsies has\nincreased. However, to the best of the authors' knowledge, the development of\nalgorithms to automatically detect individual cribriform patterns belonging to\nGleason grade 4 has not yet been studied in the literature. The objective of\nthe work presented in this paper is to develop a deep-learning-based system\nable to support pathologists in the daily analysis of prostate biopsies. The\nmethodological core of this work is a patch-wise predictive model based on\nconvolutional neural networks able to determine the presence of cancerous\npatterns. In particular, we train from scratch a simple self-design\narchitecture. The cribriform pattern is detected by retraining the set of\nfilters of the last convolutional layer in the network. From the reconstructed\nprediction map, we compute the percentage of each Gleason grade in the tissue\nto feed a multi-layer perceptron which provides a biopsy-level score.mIn our\nSICAPv2 database, composed of 182 annotated whole slide images, we obtained a\nCohen's quadratic kappa of 0.77 in the test set for the patch-level Gleason\ngrading with the proposed architecture trained from scratch. Our results\noutperform previous ones reported in the literature. Furthermore, this model\nreaches the level of fine-tuned state-of-the-art architectures in a\npatient-based four groups cross validation. In the cribriform pattern detection\ntask, we obtained an area under ROC curve of 0.82. Regarding the biopsy Gleason\nscoring, we achieved a quadratic Cohen's Kappa of 0.81 in the test subset.\nShallow CNN architectures trained from scratch outperform current\nstate-of-the-art methods for Gleason grades classification.",
          "link": "http://arxiv.org/abs/2105.10490",
          "publishedOn": "2021-05-24T07:23:08.646Z",
          "wordCount": 748,
          "title": "Going Deeper through the Gleason Scoring Scale: An Automatic end-to-end System for Histology Prostate Grading and Cribriform Pattern Detection. (arXiv:2105.10490v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2104.12056",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Woinoski_T/0/1/0/all/0/1\">Timothy Woinoski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bajic_I/0/1/0/all/0/1\">Ivan V. Baji&#x107;</a>",
          "description": "In this work, we propose a swimming analytics system for automatically\ndetermining swimmer stroke rates from overhead race video (ORV). General ORV is\ndefined as any footage of swimmers in competition, taken for the purposes of\nviewing or analysis. Examples of this are footage from live streams,\nbroadcasts, or specialized camera equipment, with or without camera motion.\nThese are the most typical forms of swimming competition footage. We detail how\nto create a system that will automatically collect swimmer stroke rates in any\ncompetition, given the video of the competition of interest. With this\ninformation, better systems can be created and additions to our analytics\nsystem can be proposed to automatically extract other swimming metrics of\ninterest.",
          "link": "http://arxiv.org/abs/2104.12056",
          "publishedOn": "2021-05-24T07:23:08.600Z",
          "wordCount": 590,
          "title": "Swimmer Stroke Rate Estimation From Overhead Race Video. (arXiv:2104.12056v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.11574",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Helmy_M/0/1/0/all/0/1\">Maged Helmy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dykyy_A/0/1/0/all/0/1\">Anastasiya Dykyy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1\">Tuyen Trung Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_P/0/1/0/all/0/1\">Paulo Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jul_E/0/1/0/all/0/1\">Eric Jul</a>",
          "description": "Capillaries are the smallest vessels in the body responsible for the delivery\nof oxygen and nutrients to the surrounding cells. Various diseases have been\nshown to alter the density of nutritive capillaries and the flow velocity of\nerythrocytes. In previous studies, capillary density and flow velocity have\nbeen assessed manually by trained specialists. Manual analysis of a 20-second\nlong microvascular video takes on average 20 minutes and requires extensive\ntraining. Several studies have reported that manual analysis hinders the\napplication of microvascular microscopy in a clinical setting. In this paper,\nwe present a fully automated system, called CapillaryNet, that can automate\nmicrovascular microscopy analysis so it can be used as a clinical application.\nMoreover, CapillaryNet measures several microvascular parameters that\nresearchers were previously unable to quantify, i.e. capillary hematocrit and\nintra-capillary flow velocity heterogeneity.",
          "link": "http://arxiv.org/abs/2104.11574",
          "publishedOn": "2021-05-24T07:23:08.571Z",
          "wordCount": 607,
          "title": "CapillaryNet: An Automated System to Analyze Microcirculation Videos from Handheld Vital Microscopy. (arXiv:2104.11574v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10465",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Boyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hujun Yin</a>",
          "description": "Graph convolutional networks (GCNs) have achieved great success in dealing\nwith data of non-Euclidean structures. Their success directly attributes to\nfitting graph structures effectively to data such as in social media and\nknowledge databases. For image processing applications, the use of graph\nstructures and GCNs have not been fully explored. In this paper, we propose a\nnovel encoder-decoder network with added graph convolutions by converting\nfeature maps to vertexes of a pre-generated graph to synthetically construct\ngraph-structured data. By doing this, we inexplicitly apply graph Laplacian\nregularization to the feature maps, making them more structured. The\nexperiments show that it significantly boosts performance for image restoration\ntasks, including deblurring and super-resolution. We believe it opens up\nopportunities for GCN-based approaches in more applications.",
          "link": "http://arxiv.org/abs/2105.10465",
          "publishedOn": "2021-05-24T07:23:08.542Z",
          "wordCount": 571,
          "title": "Graph Convolutional Networks in Feature Space for Image Deblurring and Super-resolution. (arXiv:2105.10465v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Real_R/0/1/0/all/0/1\">Ric Real</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopsill_J/0/1/0/all/0/1\">James Gopsill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_D/0/1/0/all/0/1\">David Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snider_C/0/1/0/all/0/1\">Chris Snider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hicks_B/0/1/0/all/0/1\">Ben Hicks</a>",
          "description": "Prior work has shown Convolutional Neural Networks (CNNs) trained on\nsurrogate Computer Aided Design (CAD) models are able to detect and classify\nreal-world artefacts from photographs. The applications of which support\ntwinning of digital and physical assets in design, including rapid extraction\nof part geometry from model repositories, information search \\& retrieval and\nidentifying components in the field for maintenance, repair, and recording. The\nperformance of CNNs in classification tasks have been shown dependent on\ntraining data set size and number of classes. Where prior works have used\nrelatively small surrogate model data sets ($<100$ models), the question\nremains as to the ability of a CNN to differentiate between models in\nincreasingly large model repositories. This paper presents a method for\ngenerating synthetic image data sets from online CAD model repositories, and\nfurther investigates the capacity of an off-the-shelf CNN architecture trained\non synthetic data to classify models as class size increases. 1,000 CAD models\nwere curated and processed to generate large scale surrogate data sets,\nfeaturing model coverage at steps of 10$^{\\circ}$, 30$^{\\circ}$, 60$^{\\circ}$,\nand 120$^{\\circ}$ degrees. The findings demonstrate the capability of computer\nvision algorithms to classify artefacts in model repositories of up to 200,\nbeyond this point the CNN's performance is observed to deteriorate\nsignificantly, limiting its present ability for automated twinning of physical\nto digital artefacts. Although, a match is more often found in the top-5\nresults showing potential for information search and retrieval on large\nrepositories of surrogate models.",
          "link": "http://arxiv.org/abs/2105.10448",
          "publishedOn": "2021-05-24T07:23:08.535Z",
          "wordCount": 704,
          "title": "Distinguishing artefacts: evaluating the saturation point of convolutional neural networks. (arXiv:2105.10448v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2005.01456",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ouaknine_A/0/1/0/all/0/1\">A. Ouaknine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newson_A/0/1/0/all/0/1\">A. Newson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rebut_J/0/1/0/all/0/1\">J. Rebut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tupin_F/0/1/0/all/0/1\">F. Tupin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1\">P. P&#xe9;rez</a>",
          "description": "High quality perception is essential for autonomous driving (AD) systems. To\nreach the accuracy and robustness that are required by such systems, several\ntypes of sensors must be combined. Currently, mostly cameras and laser scanners\n(lidar) are deployed to build a representation of the world around the vehicle.\nWhile radar sensors have been used for a long time in the automotive industry,\nthey are still under-used for AD despite their appealing characteristics\n(notably, their ability to measure the relative speed of obstacles and to\noperate even in adverse weather conditions). To a large extent, this situation\nis due to the relative lack of automotive datasets with real radar signals that\nare both raw and annotated. In this work, we introduce CARRADA, a dataset of\nsynchronized camera and radar recordings with range-angle-Doppler annotations.\nWe also present a semi-automatic annotation approach, which was used to\nannotate the dataset, and a radar semantic segmentation baseline, which we\nevaluate on several metrics. Both our code and dataset are available online.",
          "link": "http://arxiv.org/abs/2005.01456",
          "publishedOn": "2021-05-24T07:23:08.452Z",
          "wordCount": 685,
          "title": "CARRADA Dataset: Camera and Automotive Radar with Range-Angle-Doppler Annotations. (arXiv:2005.01456v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1\">Henry Kvinge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jefferson_B/0/1/0/all/0/1\">Brett Jefferson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joslyn_C/0/1/0/all/0/1\">Cliff Joslyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purvine_E/0/1/0/all/0/1\">Emilie Purvine</a>",
          "description": "As data grows in size and complexity, finding frameworks which aid in\ninterpretation and analysis has become critical. This is particularly true when\ndata comes from complex systems where extensive structure is available, but\nmust be drawn from peripheral sources. In this paper we argue that in such\nsituations, sheaves can provide a natural framework to analyze how well a\nstatistical model fits at the local level (that is, on subsets of related\ndatapoints) vs the global level (on all the data). The sheaf-based approach\nthat we propose is suitably general enough to be useful in a range of\napplications, from analyzing sensor networks to understanding the feature space\nof a deep learning model.",
          "link": "http://arxiv.org/abs/2105.10414",
          "publishedOn": "2021-05-24T07:23:08.383Z",
          "wordCount": 561,
          "title": "Sheaves as a Framework for Understanding and Interpreting Model Fit. (arXiv:2105.10414v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.00950",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kenfack_P/0/1/0/all/0/1\">Patrik Joslin Kenfack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arapov_D/0/1/0/all/0/1\">Daniil Dmitrievich Arapov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussain_R/0/1/0/all/0/1\">Rasheed Hussain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazmi_S/0/1/0/all/0/1\">S.M. Ahsan Kazmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Adil Mehmood Khan</a>",
          "description": "Generative adversarial networks (GANs) are one of the greatest advances in AI\nin recent years. With their ability to directly learn the probability\ndistribution of data, and then sample synthetic realistic data. Many\napplications have emerged, using GANs to solve classical problems in machine\nlearning, such as data augmentation, class unbalance problems, and fair\nrepresentation learning. In this paper, we analyze and highlight fairness\nconcerns of GANs model. In this regard, we show empirically that GANs models\nmay inherently prefer certain groups during the training process and therefore\nthey're not able to homogeneously generate data from different groups during\nthe testing phase. Furthermore, we propose solutions to solve this issue by\nconditioning the GAN model towards samples' group or using ensemble method\n(boosting) to allow the GAN model to leverage distributed structure of data\nduring the training phase and generate groups at equal rate during the testing\nphase.",
          "link": "http://arxiv.org/abs/2103.00950",
          "publishedOn": "2021-05-24T07:23:05.948Z",
          "wordCount": 624,
          "title": "On the Fairness of Generative Adversarial Networks (GANs). (arXiv:2103.00950v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.10036",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Matsuda_S/0/1/0/all/0/1\">Seiya Matsuda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kimura_A/0/1/0/all/0/1\">Akisato Kimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1\">Seiichi Uchida</a>",
          "description": "Various fonts give us various impressions, which are often represented by\nwords. This paper proposes Impressions2Font (Imp2Font) that generates font\nimages with specific impressions. Imp2Font is an extended version of\nconditional generative adversarial networks (GANs). More precisely, Imp2Font\naccepts an arbitrary number of impression words as the condition to generate\nthe font images. These impression words are converted into a soft-constraint\nvector by an impression embedding module built on a word embedding technique.\nQualitative and quantitative evaluations prove that Imp2Font generates font\nimages with higher quality than comparative methods by providing multiple\nimpression words or even unlearned words.",
          "link": "http://arxiv.org/abs/2103.10036",
          "publishedOn": "2021-05-24T07:23:05.933Z",
          "wordCount": 553,
          "title": "Impressions2Font: Generating Fonts by Specifying Impressions. (arXiv:2103.10036v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daneshjou_R/0/1/0/all/0/1\">Roxana Daneshjou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovarik_C/0/1/0/all/0/1\">Carrie Kovarik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1\">Justin M Ko</a>",
          "description": "Artificial intelligence (AI) algorithms using deep learning have advanced the\nclassification of skin disease images; however these algorithms have been\nmostly applied \"in silico\" and not validated clinically. Most dermatology AI\nalgorithms perform binary classification tasks (e.g. malignancy versus benign\nlesions), but this task is not representative of dermatologists' diagnostic\nrange. The American Academy of Dermatology Task Force on Augmented Intelligence\npublished a position statement emphasizing the importance of clinical\nvalidation to create human-computer synergy, termed augmented intelligence\n(AuI). Liu et al's recent paper, \"A deep learning system for differential\ndiagnosis of skin diseases\" represents a significant advancement of AI in\ndermatology, bringing it closer to clinical impact. However, significant issues\nmust be addressed before this algorithm can be integrated into clinical\nworkflow. These issues include accurate and equitable model development,\ndefining and assessing appropriate clinical outcomes, and real-world\nintegration.",
          "link": "http://arxiv.org/abs/2105.10477",
          "publishedOn": "2021-05-24T07:23:05.928Z",
          "wordCount": 591,
          "title": "Towards Realization of Augmented Intelligence in Dermatology: Advances and Future Directions. (arXiv:2105.10477v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kwan Ho Ryan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chong You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Haozhi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1\">John Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>",
          "description": "This work attempts to provide a plausible theoretical framework that aims to\ninterpret modern deep (convolutional) networks from the principles of data\ncompression and discriminative representation. We show that for\nhigh-dimensional multi-class data, the optimal linear discriminative\nrepresentation maximizes the coding rate difference between the whole dataset\nand the average of all the subsets. We show that the basic iterative gradient\nascent scheme for optimizing the rate reduction objective naturally leads to a\nmulti-layer deep network, named ReduNet, that shares common characteristics of\nmodern deep networks. The deep layered architectures, linear and nonlinear\noperators, and even parameters of the network are all explicitly constructed\nlayer-by-layer via forward propagation, instead of learned via back\npropagation. All components of so-obtained \"white-box\" network have precise\noptimization, statistical, and geometric interpretation. Moreover, all linear\noperators of the so-derived network naturally become multi-channel convolutions\nwhen we enforce classification to be rigorously shift-invariant. The derivation\nalso indicates that such a deep convolution network is significantly more\nefficient to construct and learn in the spectral domain. Our preliminary\nsimulations and experiments clearly verify the effectiveness of both the rate\nreduction objective and the associated ReduNet. All code and data are available\nat https://github.com/Ma-Lab-Berkeley.",
          "link": "http://arxiv.org/abs/2105.10446",
          "publishedOn": "2021-05-24T07:23:05.922Z",
          "wordCount": 672,
          "title": "ReduNet: A White-box Deep Network from the Principle of Maximizing Rate Reduction. (arXiv:2105.10446v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2002.12041",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Q/0/1/0/all/0/1\">Quan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fagui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>",
          "description": "The way features propagate in Fully Convolutional Networks is of momentous\nimportance to capture multi-scale contexts for obtaining precise segmentation\nmasks. This paper proposes a novel series-parallel hybrid paradigm called the\nChained Context Aggregation Module (CAM) to diversify feature propagation. CAM\ngains features of various spatial scales through chain-connected ladder-style\ninformation flows and fuses them in a two-stage process, namely pre-fusion and\nre-fusion. The serial flow continuously increases receptive fields of output\nneurons and those in parallel encode different region-based contexts. Each\ninformation flow is a shallow encoder-decoder with appropriate down-sampling\nscales to sufficiently capture contextual information. We further adopt an\nattention model in CAM to guide feature re-fusion. Based on these developments,\nwe construct the Chained Context Aggregation Network (CANet), which employs an\nasymmetric decoder to recover precise spatial details of prediction maps. We\nconduct extensive experiments on six challenging datasets, including Pascal VOC\n2012, Pascal Context, Cityscapes, CamVid, SUN-RGBD and GATECH. Results evidence\nthat CANet achieves state-of-the-art performance.",
          "link": "http://arxiv.org/abs/2002.12041",
          "publishedOn": "2021-05-24T07:23:05.914Z",
          "wordCount": 647,
          "title": "Attention-guided Chained Context Aggregation for Semantic Segmentation. (arXiv:2002.12041v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2003.02692",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hyeon Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taehoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Hyung Jin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1\">Wonjun Hwang</a>",
          "description": "We propose a self-supervised visual learning method by predicting the\nvariable playback speeds of a video. Without semantic labels, we learn the\nspatio-temporal visual representation of the video by leveraging the variations\nin the visual appearance according to different playback speeds under the\nassumption of temporal coherence. To learn the spatio-temporal visual\nvariations in the entire video, we have not only predicted a single playback\nspeed but also generated clips of various playback speeds and directions with\nrandomized starting points. Hence the visual representation can be successfully\nlearned from the meta information (playback speeds and directions) of the\nvideo. We also propose a new layer dependable temporal group normalization\nmethod that can be applied to 3D convolutional networks to improve the\nrepresentation learning performance where we divide the temporal features into\nseveral groups and normalize each one using the different corresponding\nparameters. We validate the effectiveness of our method by fine-tuning it to\nthe action recognition and video retrieval tasks on UCF-101 and HMDB-51.",
          "link": "http://arxiv.org/abs/2003.02692",
          "publishedOn": "2021-05-24T07:23:05.908Z",
          "wordCount": 638,
          "title": "Self-Supervised Visual Learning by Variable Playback Speeds Prediction of a Video. (arXiv:2003.02692v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.00265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaopeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tiancheng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyusong Lee</a>",
          "description": "Text-to-image retrieval is an essential task in cross-modal information\nretrieval, i.e., retrieving relevant images from a large and unlabelled dataset\ngiven textual queries. In this paper, we propose VisualSparta, a novel\n(Visual-text Sparse Transformer Matching) model that shows significant\nimprovement in terms of both accuracy and efficiency. VisualSparta is capable\nof outperforming previous state-of-the-art scalable methods in MSCOCO and\nFlickr30K. We also show that it achieves substantial retrieving speed\nadvantages, i.e., for a 1 million image index, VisualSparta using CPU gets\n~391X speedup compared to CPU vector search and ~5.4X speedup compared to\nvector search with GPU acceleration. Experiments show that this speed advantage\neven gets bigger for larger datasets because VisualSparta can be efficiently\nimplemented as an inverted index. To the best of our knowledge, VisualSparta is\nthe first transformer-based text-to-image retrieval model that can achieve\nreal-time searching for large-scale datasets, with significant accuracy\nimprovement compared to previous state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2101.00265",
          "publishedOn": "2021-05-24T07:23:05.891Z",
          "wordCount": 629,
          "title": "VisualSparta: An Embarrassingly Simple Approach to Large-scale Text-to-Image Search with Weighted Bag-of-words. (arXiv:2101.00265v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2004.08614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_K/0/1/0/all/0/1\">Kuldeep Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokhale_T/0/1/0/all/0/1\">Tejas Gokhale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rajhans Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turaga_P/0/1/0/all/0/1\">Pavan Turaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankaranarayanan_A/0/1/0/all/0/1\">Aswin Sankaranarayanan</a>",
          "description": "Recently, there has been substantial progress in image synthesis from\nsemantic labelmaps. However, methods used for this task assume the availability\nof complete and unambiguous labelmaps, with instance boundaries of objects, and\nclass labels for each pixel. This reliance on heavily annotated inputs\nrestricts the application of image synthesis techniques to real-world\napplications, especially under uncertainty due to weather, occlusion, or noise.\nOn the other hand, algorithms that can synthesize images from sparse labelmaps\nor sketches are highly desirable as tools that can guide content creators and\nartists to quickly generate scenes by simply specifying locations of a few\nobjects. In this paper, we address the problem of complex scene completion from\nsparse labelmaps. Under this setting, very few details about the scene (30\\% of\nobject instances) are available as input for image synthesis. We propose a\ntwo-stage deep network based method, called `Halluci-Net', that learns\nco-occurence relationships between objects in scenes, and then exploits these\nrelationships to produce a dense and complete labelmap. The generated dense\nlabelmap can then be used as input by state-of-the-art image synthesis\ntechniques like pix2pixHD to obtain the final image. The proposed method is\nevaluated on the Cityscapes dataset and it outperforms two baselines methods on\nperformance metrics like Fr\\'echet Inception Distance (FID), semantic\nsegmentation accuracy, and similarity in object co-occurrences. We also show\nqualitative results on a subset of ADE20K dataset that contains bedroom images.",
          "link": "http://arxiv.org/abs/2004.08614",
          "publishedOn": "2021-05-24T07:23:05.885Z",
          "wordCount": 709,
          "title": "Halluci-Net: Scene Completion by Exploiting Object Co-occurrence Relationships. (arXiv:2004.08614v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diallo_A/0/1/0/all/0/1\">A&#xef;ssatou Diallo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furnkranz_J/0/1/0/all/0/1\">Johannes F&#xfc;rnkranz</a>",
          "description": "Ordinal embedding aims at finding a low dimensional representation of objects\nfrom a set of constraints of the form \"item $j$ is closer to item $i$ than item\n$k$\". Typically, each object is mapped onto a point vector in a low dimensional\nmetric space. We argue that mapping to a density instead of a point vector\nprovides some interesting advantages, including an inherent reflection of the\nuncertainty about the representation itself and its relative location in the\nspace. Indeed, in this paper, we propose to embed each object as a Gaussian\ndistribution. We investigate the ability of these embeddings to capture the\nunderlying structure of the data while satisfying the constraints, and explore\nproperties of the representation. Experiments on synthetic and real-world\ndatasets showcase the advantages of our approach. In addition, we illustrate\nthe merit of modelling uncertainty, which enriches the visual perception of the\nmapped objects in the space.",
          "link": "http://arxiv.org/abs/2105.10457",
          "publishedOn": "2021-05-24T07:23:05.878Z",
          "wordCount": 575,
          "title": "Elliptical Ordinal Embedding. (arXiv:2105.10457v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.04076",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiang Li</a>",
          "description": "Visual attention is one of the most significant characteristics for selecting\nand understanding the outside redundancy world. The nature of complex scenes\nincludes enormous redundancy. The human vision system can not process all\ninformation simultaneously because of visual information bottleneck. The human\nvisual system mainly focuses on dominant parts of the scenes to reduce the\ninput visual redundancy information. It is commonly known as visual attention\nprediction or visual saliency map. This paper proposes a new psychophysical\nsaliency prediction architecture, WECSF, inspired by human low-level visual\ncortex function. The model consists of opponent color channels, wavelet\ntransform, wavelet energy map, and contrast sensitivity function for extracting\nlow-level image features and maximum approximation to the human visual system.\nThe proposed model is evaluated several datasets, including MIT1003, MIT300,\nTORONTO, SID4VAM and UCF Sports dataset to explain its efficiency. We also\nquantitatively and qualitatively compared the performance of saliency\nprediction with other state-of-the-art models. Our model achieved very stable\nand good performance. Second, we also confirmed that Fourier and\nspectral-inspired saliency prediction models achieved outperformance compared\nto other start-of-the-art non-neural networks and even deep neural network\nmodels on psychophysical synthesis images. Finally, the proposed model also can\nbe applied to spatial-temporal saliency prediction and got better performance.",
          "link": "http://arxiv.org/abs/2011.04076",
          "publishedOn": "2021-05-24T07:23:05.839Z",
          "wordCount": 706,
          "title": "An Psychophysical Oriented Saliency Map Prediction Model. (arXiv:2011.04076v8 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jiancheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1\">Rui Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>",
          "description": "We present MedMNIST, a collection of 10 pre-processed medical open datasets.\nMedMNIST is standardized to perform classification tasks on lightweight 28x28\nimages, which requires no background knowledge. Covering the primary data\nmodalities in medical image analysis, it is diverse on data scale (from 100 to\n100,000) and tasks (binary/multi-class, ordinal regression and multi-label).\nMedMNIST could be used for educational purpose, rapid prototyping, multi-modal\nmachine learning or AutoML in medical image analysis. Moreover, MedMNIST\nClassification Decathlon is designed to benchmark AutoML algorithms on all 10\ndatasets; We have compared several baseline methods, including open-source or\ncommercial AutoML tools. The datasets, evaluation code and baseline methods for\nMedMNIST are publicly available at https://medmnist.github.io/.",
          "link": "http://arxiv.org/abs/2010.14925",
          "publishedOn": "2021-05-24T07:23:05.833Z",
          "wordCount": 612,
          "title": "MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis. (arXiv:2010.14925v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kierdorf_J/0/1/0/all/0/1\">Jana Kierdorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_I/0/1/0/all/0/1\">Immanuel Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kicherer_A/0/1/0/all/0/1\">Anna Kicherer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabawa_L/0/1/0/all/0/1\">Laura Zabawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drees_L/0/1/0/all/0/1\">Lukas Drees</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roscher_R/0/1/0/all/0/1\">Ribana Roscher</a>",
          "description": "The need for accurate yield estimates for viticulture is becoming more\nimportant due to increasing competition in the wine market worldwide. One of\nthe most promising methods to estimate the harvest is berry counting, as it can\nbe approached non-destructively, and its process can be automated. In this\narticle, we present a method that addresses the challenge of occluded berries\nwith leaves to obtain a more accurate estimate of the number of berries that\nwill enable a better estimate of the harvest. We use generative adversarial\nnetworks, a deep learning-based approach that generates a likely scenario\nbehind the leaves exploiting learned patterns from images with non-occluded\nberries. Our experiments show that the estimate of the number of berries after\napplying our method is closer to the manually counted reference. In contrast to\napplying a factor to the berry count, our approach better adapts to local\nconditions by directly involving the appearance of the visible berries.\nFurthermore, we show that our approach can identify which areas in the image\nshould be changed by adding new berries without explicitly requiring\ninformation about hidden areas.",
          "link": "http://arxiv.org/abs/2105.10325",
          "publishedOn": "2021-05-24T07:23:05.827Z",
          "wordCount": 644,
          "title": "Behind the leaves -- Estimation of occluded grapevine berries with conditional generative adversarial networks. (arXiv:2105.10325v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1\">Muzammal Naseer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1\">Kanchana Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1\">Munawar Hayat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Ming-Hsuan Yang</a>",
          "description": "Vision transformers (ViT) have demonstrated impressive performance across\nvarious machine vision problems. These models are based on multi-head\nself-attention mechanisms that can flexibly attend to a sequence of image\npatches to encode contextual cues. An important question is how such\nflexibility in attending image-wide context conditioned on a given patch can\nfacilitate handling nuisances in natural images e.g., severe occlusions, domain\nshifts, spatial permutations, adversarial and natural perturbations. We\nsystematically study this question via an extensive set of experiments\nencompassing three ViT families and comparisons with a high-performing\nconvolutional neural network (CNN). We show and analyze the following\nintriguing properties of ViT: (a) Transformers are highly robust to severe\nocclusions, perturbations and domain shifts, e.g., retain as high as 60% top-1\naccuracy on ImageNet even after randomly occluding 80% of the image content.\n(b) The robust performance to occlusions is not due to a bias towards local\ntextures, and ViTs are significantly less biased towards textures compared to\nCNNs. When properly trained to encode shape-based features, ViTs demonstrate\nshape recognition capability comparable to that of human visual system,\npreviously unmatched in the literature. (c) Using ViTs to encode shape\nrepresentation leads to an interesting consequence of accurate semantic\nsegmentation without pixel-level supervision. (d) Off-the-shelf features from a\nsingle ViT model can be combined to create a feature ensemble, leading to high\naccuracy rates across a range of classification datasets in both traditional\nand few-shot learning paradigms. We show effective features of ViTs are due to\nflexible and dynamic receptive fields possible via the self-attention\nmechanism.",
          "link": "http://arxiv.org/abs/2105.10497",
          "publishedOn": "2021-05-24T07:23:05.819Z",
          "wordCount": 698,
          "title": "Intriguing Properties of Vision Transformers. (arXiv:2105.10497v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10441",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bagautdinov_T/0/1/0/all/0/1\">Timur Bagautdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenglei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simon_T/0/1/0/all/0/1\">Tomas Simon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prada_F/0/1/0/all/0/1\">Fabian Prada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiratori_T/0/1/0/all/0/1\">Takaaki Shiratori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Shih-En Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weipeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheikh_Y/0/1/0/all/0/1\">Yaser Sheikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saragih_J/0/1/0/all/0/1\">Jason Saragih</a>",
          "description": "We present a learning-based method for building driving-signal aware\nfull-body avatars. Our model is a conditional variational autoencoder that can\nbe animated with incomplete driving signals, such as human pose and facial\nkeypoints, and produces a high-quality representation of human geometry and\nview-dependent appearance. The core intuition behind our method is that better\ndrivability and generalization can be achieved by disentangling the driving\nsignals and remaining generative factors, which are not available during\nanimation. To this end, we explicitly account for information deficiency in the\ndriving signal by introducing a latent space that exclusively captures the\nremaining information, thus enabling the imputation of the missing factors\nrequired during full-body animation, while remaining faithful to the driving\nsignal. We also propose a learnable localized compression for the driving\nsignal which promotes better generalization, and helps minimize the influence\nof global chance-correlations often found in real datasets. For a given driving\nsignal, the resulting variational model produces a compact space of uncertainty\nfor missing factors that allows for an imputation strategy best suited to a\nparticular application. We demonstrate the efficacy of our approach on the\nchallenging problem of full-body animation for virtual telepresence with\ndriving signals acquired from minimal sensors placed in the environment and\nmounted on a VR-headset.",
          "link": "http://arxiv.org/abs/2105.10441",
          "publishedOn": "2021-05-24T07:23:05.800Z",
          "wordCount": 648,
          "title": "Driving-Signal Aware Full-Body Avatars. (arXiv:2105.10441v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10445",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Silva_Rodriguez_J/0/1/0/all/0/1\">Julio Silva-Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Colomer_A/0/1/0/all/0/1\">Adri&#xe1;n Colomer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Naranjo_V/0/1/0/all/0/1\">Valery Naranjo</a>",
          "description": "Prostate cancer is one of the main diseases affecting men worldwide. The\nGleason scoring system is the primary diagnostic tool for prostate cancer. This\nis obtained via the visual analysis of cancerous patterns in prostate biopsies\nperformed by expert pathologists, and the aggregation of the main Gleason\ngrades in a combined score. Computer-aided diagnosis systems allow to reduce\nthe workload of pathologists and increase the objectivity. Recently, efforts\nhave been made in the literature to develop algorithms aiming the direct\nestimation of the global Gleason score at biopsy/core level with global labels.\nHowever, these algorithms do not cover the accurate localization of the Gleason\npatterns into the tissue. In this work, we propose a deep-learning-based system\nable to detect local cancerous patterns in the prostate tissue using only the\nglobal-level Gleason score during training. The methodological core of this\nwork is the proposed weakly-supervised-trained convolutional neural network,\nWeGleNet, based on a multi-class segmentation layer after the feature\nextraction module, a global-aggregation, and the slicing of the background\nclass for the model loss estimation during training. We obtained a Cohen's\nquadratic kappa (k) of 0.67 for the pixel-level prediction of cancerous\npatterns in the validation cohort. We compared the model performance for\nsemantic segmentation of Gleason grades with supervised state-of-the-art\narchitectures in the test cohort. We obtained a pixel-level k of 0.61 and a\nmacro-averaged f1-score of 0.58, at the same level as fully-supervised methods.\nRegarding the estimation of the core-level Gleason score, we obtained a k of\n0.76 and 0.67 between the model and two different pathologists. WeGleNet is\ncapable of performing the semantic segmentation of Gleason grades similarly to\nfully-supervised methods without requiring pixel-level annotations.",
          "link": "http://arxiv.org/abs/2105.10445",
          "publishedOn": "2021-05-24T07:23:05.794Z",
          "wordCount": 738,
          "title": "WeGleNet: A Weakly-Supervised Convolutional Neural Network for the Semantic Segmentation of Gleason Grades in Prostate Histology Images. (arXiv:2105.10445v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenbo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1\">Lu Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nianjuan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiangbo Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jiaya Jia</a>",
          "description": "Single image super-resolution (SISR) deals with a fundamental problem of\nupsampling a low-resolution (LR) image to its high-resolution (HR) version.\nLast few years have witnessed impressive progress propelled by deep learning\nmethods. However, one critical challenge faced by existing methods is to strike\na sweet spot of deep model complexity and resulting SISR quality. This paper\naddresses this pain point by proposing a linearly-assembled pixel-adaptive\nregression network (LAPAR), which casts the direct LR to HR mapping learning\ninto a linear coefficient regression task over a dictionary of multiple\npredefined filter bases. Such a parametric representation renders our model\nhighly lightweight and easy to optimize while achieving state-of-the-art\nresults on SISR benchmarks. Moreover, based on the same idea, LAPAR is extended\nto tackle other restoration tasks, e.g., image denoising and JPEG image\ndeblocking, and again, yields strong performance. The code is available at\nhttps://github.com/dvlab-research/Simple-SR.",
          "link": "http://arxiv.org/abs/2105.10422",
          "publishedOn": "2021-05-24T07:23:05.788Z",
          "wordCount": 587,
          "title": "LAPAR: Linearly-Assembled Pixel-Adaptive Regression Network for Single Image Super-Resolution and Beyond. (arXiv:2105.10422v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10436",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tayyab_M/0/1/0/all/0/1\">Muhammad Tayyab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Ahmad Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahalanobis_A/0/1/0/all/0/1\">Abhijit Mahalanobis</a>",
          "description": "We propose an efficient and straightforward method for compressing deep\nconvolutional neural networks (CNNs) that uses basis filters to represent the\nconvolutional layers, and optimizes the performance of the compressed network\ndirectly in the basis space. Specifically, any spatial convolution layer of the\nCNN can be replaced by two successive convolution layers: the first is a set of\nthree-dimensional orthonormal basis filters, followed by a layer of\none-dimensional filters that represents the original spatial filters in the\nbasis space. We jointly fine-tune both the basis and the filter representation\nto directly mitigate any performance loss due to the truncation. Generality of\nthe proposed approach is demonstrated by applying it to several well known deep\nCNN architectures and data sets for image classification and object detection.\nWe also present the execution time and power usage at different compression\nlevels on the Xavier Jetson AGX processor.",
          "link": "http://arxiv.org/abs/2105.10436",
          "publishedOn": "2021-05-24T07:23:05.773Z",
          "wordCount": 582,
          "title": "Compressing Deep CNNs using Basis Representation and Spectral Fine-tuning. (arXiv:2105.10436v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10438",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huynh_D/0/1/0/all/0/1\">Dat Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhamifar_E/0/1/0/all/0/1\">Ehsan Elhamifar</a>",
          "description": "We develop a novel compositional generative model for zero- and few-shot\nlearning to recognize fine-grained classes with a few or no training samples.\nOur key observation is that generating holistic features for fine-grained\nclasses fails to capture small attribute differences between classes.\nTherefore, we propose a feature composition framework that learns to extract\nattribute features from training samples and combines them to construct\nfine-grained features for rare and unseen classes. Feature composition allows\nus to not only selectively compose features of every class from only relevant\ntraining samples, but also obtain diversity among composed features via\nchanging samples used for the composition. In addition, instead of building\nholistic features for classes, we use our attribute features to form dense\nrepresentations capable of capturing fine-grained attribute details of classes.\nWe propose a training scheme that uses a discriminative model to construct\nfeatures that are subsequently used to train the model itself. Therefore, we\ndirectly train the discriminative model on the composed features without\nlearning a separate generative model. We conduct experiments on four popular\ndatasets of DeepFashion, AWA2, CUB, and SUN, showing the effectiveness of our\nmethod.",
          "link": "http://arxiv.org/abs/2105.10438",
          "publishedOn": "2021-05-24T07:23:05.691Z",
          "wordCount": 604,
          "title": "Compositional Fine-Grained Low-Shot Learning. (arXiv:2105.10438v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10403",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bahmani_K/0/1/0/all/0/1\">Keivan Bahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plesh_R/0/1/0/all/0/1\">Richard Plesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_P/0/1/0/all/0/1\">Peter Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuckers_S/0/1/0/all/0/1\">Stephanie Schuckers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swyka_T/0/1/0/all/0/1\">Timothy Swyka</a>",
          "description": "In this work, we utilize progressive growth-based Generative Adversarial\nNetworks (GANs) to develop the Clarkson Fingerprint Generator (CFG). We\ndemonstrate that the CFG is capable of generating realistic, high fidelity,\n$512\\times512$ pixels, full, plain impression fingerprints. Our results suggest\nthat the fingerprints generated by the CFG are unique, diverse, and resemble\nthe training dataset in terms of minutiae configuration and quality, while not\nrevealing the underlying identities of the training data. We make the\npre-trained CFG model and the synthetically generated dataset publicly\navailable at https://github.com/keivanB/Clarkson_Finger_Gen",
          "link": "http://arxiv.org/abs/2105.10403",
          "publishedOn": "2021-05-24T07:23:05.675Z",
          "wordCount": 526,
          "title": "High Fidelity Fingerprint Generation: Quality, Uniqueness, and Privacy. (arXiv:2105.10403v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.04459",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greer_H/0/1/0/all/0/1\">Hastings Greer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwitt_R/0/1/0/all/0/1\">Roland Kwitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vialard_F/0/1/0/all/0/1\">Francois-Xavier Vialard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niethammer_M/0/1/0/all/0/1\">Marc Niethammer</a>",
          "description": "Learning maps between data samples is fundamental. Applications range from\nrepresentation learning, image translation and generative modeling, to the\nestimation of spatial deformations. Such maps relate feature vectors, or map\nbetween feature spaces. Well-behaved maps should be regular, which can be\nimposed explicitly or may emanate from the data itself. We explore what induces\nregularity for spatial transformations, e.g., when computing image\nregistrations. Classical optimization-based models compute maps between pairs\nof samples and rely on an appropriate regularizer for well-posedness. Recent\ndeep learning approaches have attempted to avoid using such regularizers\naltogether by relying on the sample population instead. We explore if it is\npossible to obtain spatial regularity using an inverse consistency loss only\nand elucidate what explains map regularity in such a context. We find that deep\nnetworks combined with an inverse consistency loss and randomized off-grid\ninterpolation yield well behaved, approximately diffeomorphic, spatial\ntransformations. Despite the simplicity of this approach, our experiments\npresent compelling evidence, on both synthetic and real data, that regular maps\ncan be obtained without carefully tuned explicit regularizers, while achieving\ncompetitive registration performance.",
          "link": "http://arxiv.org/abs/2105.04459",
          "publishedOn": "2021-05-24T07:23:05.669Z",
          "wordCount": 626,
          "title": "ICON: Learning Regular Maps Through Inverse Consistency. (arXiv:2105.04459v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.07112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alghonaim_R/0/1/0/all/0/1\">Raghad Alghonaim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1\">Edward Johns</a>",
          "description": "Domain randomisation is a very popular method for visual sim-to-real transfer\nin robotics, due to its simplicity and ability to achieve transfer without any\nreal-world images at all. Nonetheless, a number of design choices must be made\nto achieve optimal transfer. In this paper, we perform a comprehensive\nbenchmarking study on these different choices, with two key experiments\nevaluated on a real-world object pose estimation task. First, we study the\nrendering quality, and find that a small number of high-quality images is\nsuperior to a large number of low-quality images. Second, we study the type of\nrandomisation, and find that both distractors and textures are important for\ngeneralisation to novel environments.",
          "link": "http://arxiv.org/abs/2011.07112",
          "publishedOn": "2021-05-24T07:23:05.648Z",
          "wordCount": 581,
          "title": "Benchmarking Domain Randomisation for Visual Sim-to-Real Transfer. (arXiv:2011.07112v3 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.12106",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ercelik_E/0/1/0/all/0/1\">Eme&#xe7; Er&#xe7;elik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yurtsever_E/0/1/0/all/0/1\">Ekim Yurtsever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knoll_A/0/1/0/all/0/1\">Alois Knoll</a>",
          "description": "3D object detection is a core component of automated driving systems.\nState-of-the-art methods fuse RGB imagery and LiDAR point cloud data\nframe-by-frame for 3D bounding box regression. However, frame-by-frame 3D\nobject detection suffers from noise, field-of-view obstruction, and sparsity.\nWe propose a novel Temporal Fusion Module (TFM) to use information from\nprevious time-steps to mitigate these problems. First, a state-of-the-art\nfrustum network extracts point cloud features from raw RGB and LiDAR point\ncloud data frame-by-frame. Then, our TFM module fuses these features with a\nrecurrent neural network. As a result, 3D object detection becomes robust\nagainst single frame failures and transient occlusions. Experiments on the\nKITTI object tracking dataset show the efficiency of the proposed TFM, where we\nobtain ~6%, ~4%, and ~6% improvements on Car, Pedestrian, and Cyclist classes,\nrespectively, compared to frame-by-frame baselines. Furthermore, ablation\nstudies reinforce that the subject of improvement is temporal fusion and show\nthe effects of different placements of TFM in the object detection pipeline.\nOur code is open-source and available at\nhttps://github.com/emecercelik/Temp-Frustum-Net.git.",
          "link": "http://arxiv.org/abs/2104.12106",
          "publishedOn": "2021-05-24T07:23:05.631Z",
          "wordCount": null,
          "title": "Temp-Frustum Net: 3D Object Detection with Temporal Fusion. (arXiv:2104.12106v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1903.08051",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jie Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zibo Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Ahmed Shehab Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhiyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OReilly_J/0/1/0/all/0/1\">James O&#x27;Reilly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shizhong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yan Tong</a>",
          "description": "A novel Identity-Free conditional Generative Adversarial Network (IF-GAN) was\nproposed for Facial Expression Recognition (FER) to explicitly reduce high\ninter-subject variations caused by identity-related facial attributes, e.g.,\nage, race, and gender. As part of an end-to-end system, a cGAN was designed to\ntransform a given input facial expression image to an \"average\" identity face\nwith the same expression as the input. Then, identity-free FER is possible\nsince the generated images have the same synthetic \"average\" identity and\ndiffer only in their displayed expressions. Experiments on four facial\nexpression datasets, one with spontaneous expressions, show that IF-GAN\noutperforms the baseline CNN and achieves state-of-the-art performance for FER.",
          "link": "http://arxiv.org/abs/1903.08051",
          "publishedOn": "2021-05-24T07:23:05.629Z",
          "wordCount": null,
          "title": "Identity-Free Facial Expression Recognition using conditional Generative Adversarial Network. (arXiv:1903.08051v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.11251",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhihao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yuqian Fu</a>",
          "description": "Junctions reflect the important geometrical structure information of the\nimage, and are of primary significance to applications such as image matching\nand motion analysis. Previous event-based feature extraction methods are mainly\nfocused on corners, which mainly find their locations, however, ignoring the\ngeometrical structure information like orientations and scales of edges. This\npaper adapts the frame-based a-contrario junction detector(ACJ) to event data,\nproposing the event-based a-contrario junction detector(e-ACJ), which yields\njunctions' locations while giving the scales and orientations of their\nbranches. The proposed method relies on an a-contrario model and can operate on\nasynchronous events directly without generating synthesized event frames. We\nevaluate the performance on public event datasets. The result shows our method\nsuccessfully finds the orientations and scales of branches, while maintaining\nhigh accuracy in junction's location.",
          "link": "http://arxiv.org/abs/2101.11251",
          "publishedOn": "2021-05-24T07:23:05.613Z",
          "wordCount": null,
          "title": "e-ACJ: Accurate Junction Extraction For Event Cameras. (arXiv:2101.11251v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10856",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Yadav_O/0/1/0/all/0/1\">Ojasvi Yadav</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ghosal_K/0/1/0/all/0/1\">Koustav Ghosal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lutz_S/0/1/0/all/0/1\">Sebastian Lutz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Smolic_A/0/1/0/all/0/1\">Aljosa Smolic</a>",
          "description": "We address the problem of exposure correction of dark, blurry and noisy\nimages captured in low-light conditions in the wild. Classical image-denoising\nfilters work well in the frequency space but are constrained by several factors\nsuch as the correct choice of thresholds, frequency estimates etc. On the other\nhand, traditional deep networks are trained end-to-end in the RGB space by\nformulating this task as an image-translation problem. However, that is done\nwithout any explicit constraints on the inherent noise of the dark images and\nthus produce noisy and blurry outputs. To this end we propose a DCT/FFT based\nmulti-scale loss function, which when combined with traditional losses, trains\na network to translate the important features for visually pleasing output. Our\nloss function is end-to-end differentiable, scale-agnostic, and generic; i.e.,\nit can be applied to both RAW and JPEG images in most existing frameworks\nwithout additional overhead. Using this loss function, we report significant\nimprovements over the state-of-the-art using quantitative metrics and\nsubjective tests.",
          "link": "http://arxiv.org/abs/2104.10856",
          "publishedOn": "2021-05-24T07:23:05.602Z",
          "wordCount": null,
          "title": "Frequency Domain Loss Function for Deep Exposure Correction of Dark Images. (arXiv:2104.10856v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.11728",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Burgos_C/0/1/0/all/0/1\">Carlos Mauricio Villegas Burgos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tianqi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vamivakas_N/0/1/0/all/0/1\">Nick Vamivakas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuhao Zhu</a>",
          "description": "Deep learning using Convolutional Neural Networks (CNNs) has been shown to\nsignificantly out-performed many conventional vision algorithms. Despite\nefforts to increase the CNN efficiency both algorithmically and with\nspecialized hardware, deep learning remains difficult to deploy in\nresource-constrained environments. In this paper, we propose an end-to-end\nframework to explore optically compute the CNNs in free-space, much like a\ncomputational camera. Compared to existing free-space optics-based approaches\nwhich are limited to processing single-channel (i.e., grayscale) inputs, we\npropose the first general approach, based on nanoscale meta-surface optics,\nthat can process RGB data directly from the natural scenes. Our system achieves\nup to an order of magnitude energy saving, simplifies the sensor design, all\nthe while sacrificing little network accuracy.",
          "link": "http://arxiv.org/abs/2011.11728",
          "publishedOn": "2021-05-24T07:23:05.553Z",
          "wordCount": null,
          "title": "End-to-End Framework for Efficient Deep Learning Using Metasurfaces Optics. (arXiv:2011.11728v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10316",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Oleksiienko_I/0/1/0/all/0/1\">Illia Oleksiienko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1\">Alexandros Iosifidis</a>",
          "description": "Real-time detection of objects in the 3D scene is one of the tasks an\nautonomous agent needs to perform for understanding its surroundings. While\nrecent Deep Learning-based solutions achieve satisfactory performance, their\nhigh computational cost renders their application in real-life settings in\nwhich computations need to be performed on embedded platforms intractable. In\nthis paper, we analyze the efficiency of two popular voxel-based 3D object\ndetection methods providing a good compromise between high performance and\nspeed based on two aspects, their ability to detect objects located at large\ndistances from the agent and their ability to operate in real time on embedded\nplatforms equipped with high-performance GPUs. Our experiments show that these\nmethods mostly fail to detect distant small objects due to the sparsity of the\ninput point clouds at large distances. Moreover, models trained on near objects\nachieve similar or better performance compared to those trained on all objects\nin the scene. This means that the models learn object appearance\nrepresentations mostly from near objects. Our findings suggest that a\nconsiderable part of the computations of existing methods is focused on\nlocations of the scene that do not contribute with successful detection. This\nmeans that the methods can achieve a speed-up of $40$-$60\\%$ by restricting\noperation to near objects while not sacrificing much in performance.",
          "link": "http://arxiv.org/abs/2105.10316",
          "publishedOn": "2021-05-24T07:23:05.551Z",
          "wordCount": 659,
          "title": "Analysis of voxel-based 3D object detection methods efficiency for real-time embedded systems. (arXiv:2105.10316v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.07112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Celong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Junsong Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yi Xu</a>",
          "description": "In this paper, we present an efficient and robust deep learning solution for\nnovel view synthesis of complex scenes. In our approach, a 3D scene is\nrepresented as a light field, i.e., a set of rays, each of which has a\ncorresponding color when reaching the image plane. For efficient novel view\nrendering, we adopt a 4D parameterization of the light field, where each ray is\ncharacterized by a 4D parameter. We then formulate the light field as a 4D\nfunction that maps 4D coordinates to corresponding color values. We train a\ndeep fully connected network to optimize this implicit function and memorize\nthe 3D scene. Then, the scene-specific model is used to synthesize novel views.\nDifferent from previous light field approaches which require dense view\nsampling to reliably render novel views, our method can render novel views by\nsampling rays and querying the color for each ray from the network directly,\nthus enabling high-quality light field rendering with a sparser set of training\nimages. Our method achieves state-of-the-art novel view synthesis results while\nmaintaining an interactive frame rate.",
          "link": "http://arxiv.org/abs/2105.07112",
          "publishedOn": "2021-05-24T07:23:05.544Z",
          "wordCount": null,
          "title": "NeLF: Practical Novel View Synthesis with Neural Light Field. (arXiv:2105.07112v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Debasmit Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhalgat_Y/0/1/0/all/0/1\">Yash Bhalgat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1\">Fatih Porikli</a>",
          "description": "In this work, we propose a data-driven scheme to initialize the parameters of\na deep neural network. This is in contrast to traditional approaches which\nrandomly initialize parameters by sampling from transformed standard\ndistributions. Such methods do not use the training data to produce a more\ninformed initialization. Our method uses a sequential layer-wise approach where\neach layer is initialized using its input activations. The initialization is\ncast as an optimization problem where we minimize a combination of encoding and\ndecoding losses of the input activations, which is further constrained by a\nuser-defined latent code. The optimization problem is then restructured into\nthe well-known Sylvester equation, which has fast and efficient gradient-free\nsolutions. Our data-driven method achieves a boost in performance compared to\nrandom initialization methods, both before start of training and after training\nis over. We show that our proposed method is especially effective in few-shot\nand fine-tuning settings. We conclude this paper with analyses on time\ncomplexity and the effect of different latent codes on the recognition\nperformance.",
          "link": "http://arxiv.org/abs/2105.10335",
          "publishedOn": "2021-05-24T07:23:05.470Z",
          "wordCount": 616,
          "title": "Data-driven Weight Initialization with Sylvester Solvers. (arXiv:2105.10335v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2103.12248",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jialin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiasen Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mottaghi_R/0/1/0/all/0/1\">Roozbeh Mottaghi</a>",
          "description": "The problem of knowledge-based visual question answering involves answering\nquestions that require external knowledge in addition to the content of the\nimage. Such knowledge typically comes in a variety of forms, including visual,\ntextual, and commonsense knowledge. The use of more knowledge sources, however,\nalso increases the chance of retrieving more irrelevant or noisy facts, making\nit difficult to comprehend the facts and find the answer. To address this\nchallenge, we propose Multi-modal Answer Validation using External knowledge\n(MAVEx), where the idea is to validate a set of promising answer candidates\nbased on answer-specific knowledge retrieval. This is in contrast to existing\napproaches that search for the answer in a vast collection of often irrelevant\nfacts. Our approach aims to learn which knowledge source should be trusted for\neach answer candidate and how to validate the candidate using that source. We\nconsider a multi-modal setting, relying on both textual and visual knowledge\nresources, including images searched using Google, sentences from Wikipedia\narticles, and concepts from ConceptNet. Our experiments with OK-VQA, a\nchallenging knowledge-based VQA dataset, demonstrate that MAVEx achieves new\nstate-of-the-art results.",
          "link": "http://arxiv.org/abs/2103.12248",
          "publishedOn": "2021-05-24T07:23:05.413Z",
          "wordCount": null,
          "title": "Multi-Modal Answer Validation for Knowledge-Based VQA. (arXiv:2103.12248v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zihui Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Sucheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhengqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hang Zhao</a>",
          "description": "The popularity of multimodal sensors and the accessibility of the Internet\nhave brought us a massive amount of unlabeled multimodal data. Since existing\ndatasets and well-trained models are primarily unimodal, the modality gap\nbetween a unimodal network and unlabeled multimodal data poses an interesting\nproblem: how to transfer a pre-trained unimodal network to perform the same\ntask on unlabeled multimodal data? In this work, we propose multimodal\nknowledge expansion (MKE), a knowledge distillation-based framework to\neffectively utilize multimodal data without requiring labels. Opposite to\ntraditional knowledge distillation, where the student is designed to be\nlightweight and inferior to the teacher, we observe that a multimodal student\nmodel consistently denoises pseudo labels and generalizes better than its\nteacher. Extensive experiments on four tasks and different modalities verify\nthis finding. Furthermore, we connect the mechanism of MKE to semi-supervised\nlearning and offer both empirical and theoretical explanations to understand\nthe denoising capability of a multimodal student.",
          "link": "http://arxiv.org/abs/2103.14431",
          "publishedOn": "2021-05-24T07:23:05.387Z",
          "wordCount": null,
          "title": "Multimodal Knowledge Expansion. (arXiv:2103.14431v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10382",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Poiesi_F/0/1/0/all/0/1\">Fabio Poiesi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boscaini_D/0/1/0/all/0/1\">Davide Boscaini</a>",
          "description": "An effective 3D descriptor should be invariant to different geometric\ntransformations, such as scale and rotation, repeatable in the case of\nocclusions and clutter, and generalisable in different contexts when data is\ncaptured with different sensors. We present a simple but yet effective method\nto learn generalisable and distinctive 3D local descriptors that can be used to\nregister point clouds captured in different contexts with different sensors.\nPoint cloud patches are extracted, canonicalised with respect to their local\nreference frame, and encoded into scale and rotation-invariant compact\ndescriptors by a point permutation-invariant deep neural network. Our\ndescriptors can effectively generalise across sensor modalities from locally\nand randomly sampled points. We evaluate and compare our descriptors with\nalternative handcrafted and deep learning-based descriptors on several indoor\nand outdoor datasets reconstructed using both RGBD sensors and laser scanners.\nOur descriptors outperform most recent descriptors by a large margin in terms\nof generalisation, and become the state of the art also in benchmarks where\ntraining and testing are performed in the same scenarios.",
          "link": "http://arxiv.org/abs/2105.10382",
          "publishedOn": "2021-05-24T07:23:04.855Z",
          "wordCount": null,
          "title": "Generalisable and distinctive 3D local deep descriptors for point cloud registration. (arXiv:2105.10382v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shumeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Ziyuan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kaixin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zeng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1\">Cuntai Guan</a>",
          "description": "Deep learning has achieved promising segmentation performance on 3D left\natrium MR images. However, annotations for segmentation tasks are expensive,\ncostly and difficult to obtain. In this paper, we introduce a novel\nhierarchical consistency regularized mean teacher framework for 3D left atrium\nsegmentation. In each iteration, the student model is optimized by multi-scale\ndeep supervision and hierarchical consistency regularization, concurrently.\nExtensive experiments have shown that our method achieves competitive\nperformance as compared with full annotation, outperforming other\nstateof-the-art semi-supervised segmentation methods.",
          "link": "http://arxiv.org/abs/2105.10369",
          "publishedOn": "2021-05-24T07:23:04.567Z",
          "wordCount": 535,
          "title": "Hierarchical Consistency Regularized Mean Teacher for Semi-supervised 3D Left Atrium Segmentation. (arXiv:2105.10369v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10310",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Boutillon_A/0/1/0/all/0/1\">Arnaud Boutillon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conze_P/0/1/0/all/0/1\">Pierre-Henri Conze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pons_C/0/1/0/all/0/1\">Christelle Pons</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burdin_V/0/1/0/all/0/1\">Val&#xe9;rie Burdin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borotikar_B/0/1/0/all/0/1\">Bhushan Borotikar</a>",
          "description": "Automatic segmentation of magnetic resonance (MR) images is crucial for\nmorphological evaluation of the pediatric musculoskeletal system in clinical\npractice. However, the accuracy and generalization performance of individual\nsegmentation models are limited due to the restricted amount of annotated\npediatric data. Hence, we propose to train a segmentation model on multiple\ndatasets, arising from different parts of the anatomy, in a multi-task and\nmulti-domain learning framework. This approach allows to overcome the inherent\nscarcity of pediatric data while benefiting from a more robust shared\nrepresentation. The proposed segmentation network comprises shared\nconvolutional filters, domain-specific batch normalization parameters that\ncompute the respective dataset statistics and a domain-specific segmentation\nlayer. Furthermore, a supervised contrastive regularization is integrated to\nfurther improve generalization capabilities, by promoting intra-domain\nsimilarity and impose inter-domain margins in embedded space. We evaluate our\ncontributions on two pediatric imaging datasets of the ankle and shoulder\njoints for bone segmentation. Results demonstrate that the proposed model\noutperforms state-of-the-art approaches.",
          "link": "http://arxiv.org/abs/2105.10310",
          "publishedOn": "2021-05-24T07:23:04.483Z",
          "wordCount": 624,
          "title": "Multi-Task, Multi-Domain Deep Segmentation with Shared Representations and Contrastive Regularization for Sparse Pediatric Datasets. (arXiv:2105.10310v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shmueli_B/0/1/0/all/0/1\">Boaz Shmueli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_S/0/1/0/all/0/1\">Soumya Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ku_L/0/1/0/all/0/1\">Lun-Wei Ku</a>",
          "description": "Datasets with induced emotion labels are scarce but of utmost importance for\nmany NLP tasks. We present a new, automated method for collecting texts along\nwith their induced reaction labels. The method exploits the online use of\nreaction GIFs, which capture complex affective states. We show how to augment\nthe data with induced emotion and induced sentiment labels. We use our method\nto create and publish ReactionGIF, a first-of-its-kind affective dataset of 30K\ntweets. We provide baselines for three new tasks, including induced sentiment\nprediction and multilabel classification of induced emotions. Our method and\ndataset open new research opportunities in emotion detection and affective\ncomputing.",
          "link": "http://arxiv.org/abs/2105.09967",
          "publishedOn": "2021-05-24T07:23:03.560Z",
          "wordCount": 563,
          "title": "Happy Dance, Slow Clap: Using Reaction GIFs to Predict Induced Affect on Twitter. (arXiv:2105.09967v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10203",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gong_J/0/1/0/all/0/1\">Jingyu Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiachen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xin Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Haichuan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yanyun Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lizhuang Ma</a>",
          "description": "Hidden features in neural network usually fail to learn informative\nrepresentation for 3D segmentation as supervisions are only given on output\nprediction, while this can be solved by omni-scale supervision on intermediate\nlayers. In this paper, we bring the first omni-scale supervision method to\npoint cloud segmentation via the proposed gradual Receptive Field Component\nReasoning (RFCR), where target Receptive Field Component Codes (RFCCs) are\ndesigned to record categories within receptive fields for hidden units in the\nencoder. Then, target RFCCs will supervise the decoder to gradually infer the\nRFCCs in a coarse-to-fine categories reasoning manner, and finally obtain the\nsemantic labels. Because many hidden features are inactive with tiny magnitude\nand make minor contributions to RFCC prediction, we propose a Feature\nDensification with a centrifugal potential to obtain more unambiguous features,\nand it is in effect equivalent to entropy regularization over features. More\nactive features can further unleash the potential of our omni-supervision\nmethod. We embed our method into four prevailing backbones and test on three\nchallenging benchmarks. Our method can significantly improve the backbones in\nall three datasets. Specifically, our method brings new state-of-the-art\nperformances for S3DIS as well as Semantic3D and ranks the 1st in the ScanNet\nbenchmark among all the point-based methods. Code will be publicly available at\nhttps://github.com/azuki-miho/RFCR.",
          "link": "http://arxiv.org/abs/2105.10203",
          "publishedOn": "2021-05-24T07:23:03.554Z",
          "wordCount": 658,
          "title": "Omni-supervised Point Cloud Segmentation via Gradual Receptive Field Component Reasoning. (arXiv:2105.10203v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10228",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akazawa_T/0/1/0/all/0/1\">Teruaki Akazawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kinoshita_Y/0/1/0/all/0/1\">Yuma Kinoshita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiya_H/0/1/0/all/0/1\">Hitoshi Kiya</a>",
          "description": "In this paper, we propose a novel multi-color balance adjustment for color\nconstancy. The proposed method, called \"n-color balancing,\" allows us not only\nto perfectly correct n target colors on the basis of corresponding ground truth\ncolors but also to correct colors other than the n colors. In contrast,\nalthough white-balancing can perfectly adjust white, colors other than white\nare not considered in the framework of white-balancing in general. In an\nexperiment, the proposed multi-color balancing is demonstrated to outperform\nboth conventional white and multi-color balance adjustments including\nBradford's model.",
          "link": "http://arxiv.org/abs/2105.10228",
          "publishedOn": "2021-05-24T07:23:03.548Z",
          "wordCount": 572,
          "title": "Multi-color balance for color constancy. (arXiv:2105.10228v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10189",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Durall_R/0/1/0/all/0/1\">Ricard Durall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frolov_S/0/1/0/all/0/1\">Stanislav Frolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1\">Andreas Dengel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keuper_J/0/1/0/all/0/1\">Janis Keuper</a>",
          "description": "Transformer models have recently attracted much interest from computer vision\nresearchers and have since been successfully employed for several problems\ntraditionally addressed with convolutional neural networks. At the same time,\nimage synthesis using generative adversarial networks (GANs) has drastically\nimproved over the last few years. The recently proposed TransGAN is the first\nGAN using only transformer-based architectures and achieves competitive results\nwhen compared to convolutional GANs. However, since transformers are\ndata-hungry architectures, TransGAN requires data augmentation, an auxiliary\nsuper-resolution task during training, and a masking prior to guide the\nself-attention mechanism. In this paper, we study the combination of a\ntransformer-based generator and convolutional discriminator and successfully\nremove the need of the aforementioned required design choices. We evaluate our\napproach by conducting a benchmark of well-known CNN discriminators, ablate the\nsize of the transformer-based generator, and show that combining both\narchitectural elements into a hybrid model leads to better results.\nFurthermore, we investigate the frequency spectrum properties of generated\nimages and observe that our model retains the benefits of an attention based\ngenerator.",
          "link": "http://arxiv.org/abs/2105.10189",
          "publishedOn": "2021-05-24T07:23:03.540Z",
          "wordCount": 599,
          "title": "Combining Transformer Generators with Convolutional Discriminators. (arXiv:2105.10189v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09993",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Han_K/0/1/0/all/0/1\">Kai Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wong_K/0/1/0/all/0/1\">Kwan-Yee K. Wong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_M/0/1/0/all/0/1\">Miaomiao Liu</a>",
          "description": "This paper addresses the problem of reconstructing the surface shape of\ntransparent objects. The difficulty of this problem originates from the\nviewpoint dependent appearance of a transparent object, which quickly makes\nreconstruction methods tailored for diffuse surfaces fail disgracefully. In\nthis paper, we introduce a fixed viewpoint approach to dense surface\nreconstruction of transparent objects based on refraction of light. We present\na simple setup that allows us to alter the incident light paths before light\nrays enter the object by immersing the object partially in a liquid, and\ndevelop a method for recovering the object surface through reconstructing and\ntriangulating such incident light paths. Our proposed approach does not need to\nmodel the complex interactions of light as it travels through the object,\nneither does it assume any parametric form for the object shape nor the exact\nnumber of refractions and reflections taken place along the light paths. It can\ntherefore handle transparent objects with a relatively complex shape and\nstructure, with unknown and inhomogeneous refractive index. We also show that\nfor thin transparent objects, our proposed acquisition setup can be further\nsimplified by adopting a single refraction approximation. Experimental results\non both synthetic and real data demonstrate the feasibility and accuracy of our\nproposed approach.",
          "link": "http://arxiv.org/abs/2105.09993",
          "publishedOn": "2021-05-24T07:23:03.534Z",
          "wordCount": 662,
          "title": "Dense Reconstruction of Transparent Objects by Altering Incident Light Paths Through Refraction. (arXiv:2105.09993v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10175",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Salas_R/0/1/0/all/0/1\">Rosemberg Rodriguez Salas</a> (LIGM), <a href=\"http://arxiv.org/find/cs/1/au:+Dokladalova_E/0/1/0/all/0/1\">Eva Dokladalova</a> (LIGM), <a href=\"http://arxiv.org/find/cs/1/au:+Dokladal_P/0/1/0/all/0/1\">Petr Dokl&#xe1;dal</a> (CMM)",
          "description": "Deep convolutional neural networks accuracy is heavily impacted by rotations\nof the input data. In this paper, we propose a convolutional predictor that is\ninvariant to rotations in the input. This architecture is capable of predicting\nthe angular orientation without angle-annotated data. Furthermore, the\npredictor maps continuously the random rotation of the input to a circular\nspace of the prediction. For this purpose, we use the roto-translation\nproperties existing in the Scattering Transform Networks with a series of 3D\nConvolutions. We validate the results by training with upright and randomly\nrotated samples. This allows further applications of this work on fields like\nautomatic re-orientation of randomly oriented datasets.",
          "link": "http://arxiv.org/abs/2105.10175",
          "publishedOn": "2021-05-24T07:23:03.527Z",
          "wordCount": 565,
          "title": "Rotation invariant CNN using scattering transform for image classification. (arXiv:2105.10175v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10087",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhehua Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shoudong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yiting Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1\">Alex Pui-Wai Lee</a>",
          "description": "This paper presents a novel algorithm that registers a collection of\nmono-modal 3D images in a simultaneous fashion, named as Direct Simultaneous\nRegistration (DSR). The algorithm optimizes global poses of local frames\ndirectly based on the intensities of images (without extracting features from\nthe images). To obtain the optimal result, we start with formulating a Direct\nBundle Adjustment (DBA) problem which jointly optimizes pose parameters of\nlocal frames and intensities of panoramic image. By proving the independence of\nthe pose from panoramic image in the iterative process, DSR is proposed and\nproved to be able to generate the same optimal poses as DBA, but without\noptimizing the intensities of the panoramic image. The proposed DSR method is\nparticularly suitable in mono-modal registration and in the scenarios where\ndistinct features are not available, such as Transesophageal Echocardiography\n(TEE) images. The proposed method is validated via simulated and in-vivo 3D TEE\nimages. It is shown that the proposed method outperforms conventional\nsequential registration method in terms of accuracy and the obtained results\ncan produce good alignment in in-vivo images.",
          "link": "http://arxiv.org/abs/2105.10087",
          "publishedOn": "2021-05-24T07:23:03.509Z",
          "wordCount": 618,
          "title": "Direct Simultaneous Multi-Image Registration. (arXiv:2105.10087v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10076",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weligampola_H/0/1/0/all/0/1\">Harshana Weligampola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayatilaka_G/0/1/0/all/0/1\">Gihan Jayatilaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sritharan_S/0/1/0/all/0/1\">Suren Sritharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ekanayake_P/0/1/0/all/0/1\">Parakrama Ekanayake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ragel_R/0/1/0/all/0/1\">Roshan Ragel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herath_V/0/1/0/all/0/1\">Vijitha Herath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godaliyadda_R/0/1/0/all/0/1\">Roshan Godaliyadda</a>",
          "description": "Intrinsic Image Decomposition is an open problem of generating the\nconstituents of an image. Generating reflectance and shading from a single\nimage is a challenging task specifically when there is no ground truth. There\nis a lack of unsupervised learning approaches for decomposing an image into\nreflectance and shading using a single image. We propose a neural network\narchitecture capable of this decomposition using physics-based parameters\nderived from the image. Through experimental results, we show that (a) the\nproposed methodology outperforms the existing deep learning-based IID\ntechniques and (b) the derived parameters improve the efficacy significantly.\nWe conclude with a closer analysis of the results (numerical and example\nimages) showing several avenues for improvement.",
          "link": "http://arxiv.org/abs/2105.10076",
          "publishedOn": "2021-05-24T07:23:03.503Z",
          "wordCount": 563,
          "title": "An Optical physics inspired CNN approach for intrinsic image decomposition. (arXiv:2105.10076v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_G/0/1/0/all/0/1\">Gargi Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1\">Po-Yao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_P/0/1/0/all/0/1\">Prahal Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aminzadeh_M/0/1/0/all/0/1\">Masoumeh Aminzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feichtenhofer_C/0/1/0/all/0/1\">Christoph Feichtenhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metze_F/0/1/0/all/0/1\">Florian Metze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>",
          "description": "We present a simplified, task-agnostic multi-modal pre-training approach that\ncan accept either video or text input, or both for a variety of end tasks.\nExisting pre-training are task-specific by adopting either a single cross-modal\nencoder that requires both modalities, limiting their use for retrieval-style\nend tasks or more complex multitask learning with two unimodal encoders,\nlimiting early cross-modal fusion. We instead introduce new pretraining masking\nschemes that better mix across modalities (e.g. by forcing masks for text to\npredict the closest video embeddings) while also maintaining separability (e.g.\nunimodal predictions are sometimes required, without using all the input).\nExperimental results show strong performance across a wider range of tasks than\nany previous methods, often outperforming task-specific pre-training.",
          "link": "http://arxiv.org/abs/2105.09996",
          "publishedOn": "2021-05-24T07:23:03.497Z",
          "wordCount": 565,
          "title": "VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding. (arXiv:2105.09996v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10026",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Maharana_A/0/1/0/all/0/1\">Adyasha Maharana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hannan_D/0/1/0/all/0/1\">Darryl Hannan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>",
          "description": "Story visualization is an under-explored task that falls at the intersection\nof many important research directions in both computer vision and natural\nlanguage processing. In this task, given a series of natural language captions\nwhich compose a story, an agent must generate a sequence of images that\ncorrespond to the captions. Prior work has introduced recurrent generative\nmodels which outperform text-to-image synthesis models on this task. However,\nthere is room for improvement of generated images in terms of visual quality,\ncoherence and relevance. We present a number of improvements to prior modeling\napproaches, including (1) the addition of a dual learning framework that\nutilizes video captioning to reinforce the semantic alignment between the story\nand generated images, (2) a copy-transform mechanism for\nsequentially-consistent story visualization, and (3) MART-based transformers to\nmodel complex interactions between frames. We present ablation studies to\ndemonstrate the effect of each of these techniques on the generative power of\nthe model for both individual images as well as the entire narrative.\nFurthermore, due to the complexity and generative nature of the task, standard\nevaluation metrics do not accurately reflect performance. Therefore, we also\nprovide an exploration of evaluation metrics for the model, focused on aspects\nof the generated frames such as the presence/quality of generated characters,\nthe relevance to captions, and the diversity of the generated images. We also\npresent correlation experiments of our proposed automated metrics with human\nevaluations. Code and data available at:\nhttps://github.com/adymaharana/StoryViz",
          "link": "http://arxiv.org/abs/2105.10026",
          "publishedOn": "2021-05-24T07:23:03.489Z",
          "wordCount": 686,
          "title": "Improving Generation and Evaluation of Visual Stories via Semantic Consistency. (arXiv:2105.10026v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Collier_M/0/1/0/all/0/1\">Mark Collier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1\">Basil Mustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokiopoulou_E/0/1/0/all/0/1\">Efi Kokiopoulou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1\">Rodolphe Jenatton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berent_J/0/1/0/all/0/1\">Jesse Berent</a>",
          "description": "Large scale image classification datasets often contain noisy labels. We take\na principled probabilistic approach to modelling input-dependent, also known as\nheteroscedastic, label noise in these datasets. We place a multivariate Normal\ndistributed latent variable on the final hidden layer of a neural network\nclassifier. The covariance matrix of this latent variable, models the aleatoric\nuncertainty due to label noise. We demonstrate that the learned covariance\nstructure captures known sources of label noise between semantically similar\nand co-occurring classes. Compared to standard neural network training and\nother baselines, we show significantly improved accuracy on Imagenet ILSVRC\n2012 79.3% (+2.6%), Imagenet-21k 47.0% (+1.1%) and JFT 64.7% (+1.6%). We set a\nnew state-of-the-art result on WebVision 1.0 with 76.6% top-1 accuracy. These\ndatasets range from over 1M to over 300M training examples and from 1k classes\nto more than 21k classes. Our method is simple to use, and we provide an\nimplementation that is a drop-in replacement for the final fully-connected\nlayer in a deep classifier.",
          "link": "http://arxiv.org/abs/2105.10305",
          "publishedOn": "2021-05-24T07:23:03.482Z",
          "wordCount": 609,
          "title": "Correlated Input-Dependent Label Noise in Large-Scale Image Classification. (arXiv:2105.10305v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10013",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vendramini_M/0/1/0/all/0/1\">Marcos Vendramini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1\">Hugo Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Machado_A/0/1/0/all/0/1\">Alexei Machado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1\">Jefersson A. dos Santos</a>",
          "description": "Image classification methods are usually trained to perform predictions\ntaking into account a predefined group of known classes. Real-world problems,\nhowever, may not allow for a full knowledge of the input and label spaces,\nmaking failures in recognition a hazard to deep visual learning. Open set\nrecognition methods are characterized by the ability to correctly identifying\ninputs of known and unknown classes. In this context, we propose GeMOS: simple\nand plug-and-play open set recognition modules that can be attached to\npretrained Deep Neural Networks for visual recognition. The GeMOS framework\npairs pre-trained Convolutional Neural Networks with generative models for open\nset recognition to extract open set scores for each sample, allowing for\nfailure recognition in object recognition tasks. We conduct a thorough\nevaluation of the proposed method in comparison with state-of-the-art open set\nalgorithms, finding that GeMOS either outperforms or is statistically\nindistinguishable from more complex and costly models.",
          "link": "http://arxiv.org/abs/2105.10013",
          "publishedOn": "2021-05-24T07:23:03.461Z",
          "wordCount": 583,
          "title": "Opening Deep Neural Networks with Generative Models. (arXiv:2105.10013v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10313",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Broome_S/0/1/0/all/0/1\">Sofia Broom&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ask_K/0/1/0/all/0/1\">Katrina Ask</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_M/0/1/0/all/0/1\">Maheen Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andersen_P/0/1/0/all/0/1\">Pia Haubro Andersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kjellstrom_H/0/1/0/all/0/1\">Hedvig Kjellstr&#xf6;m</a>",
          "description": "Orthopedic disorders are a common cause for euthanasia among horses, which\noften could have been avoided with earlier detection. These conditions often\ncreate varying degrees of subtle but long-term pain. It is challenging to train\na visual pain recognition method with video data depicting such pain, since the\nresulting pain behavior also is subtle, sparsely appearing, and varying, making\nit challenging for even an expert human labeler to provide accurate\nground-truth for the data. We show that transferring features from a dataset of\nhorses with acute nociceptive pain (where labeling is less ambiguous) can aid\nthe learning to recognize more complex orthopedic pain. Moreover, we present a\nhuman expert baseline for the problem, as well as an extensive empirical study\nof various domain transfer methods and of what is detected by the pain\nrecognition method trained on acute pain in the orthopedic dataset. Finally,\nthis is accompanied with a discussion around the challenges posed by real-world\nanimal behavior datasets and how best practices can be established for similar\nfine-grained action recognition tasks. Our code is available at\nhttps://github.com/sofiabroome/painface-recognition.",
          "link": "http://arxiv.org/abs/2105.10313",
          "publishedOn": "2021-05-24T07:23:03.456Z",
          "wordCount": 629,
          "title": "Sharing Pain: Using Domain Transfer Between Pain Types for Recognition of Sparse Pain Expressions in Horses. (arXiv:2105.10313v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1\">Mansi Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abheesht Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_K/0/1/0/all/0/1\">Kadvekar Rohit Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panneer_A/0/1/0/all/0/1\">Avinash Panneer</a>",
          "description": "The task of predicting smooth and edge-consistent depth maps is notoriously\ndifficult for single image depth estimation. This paper proposes a novel\nBilateral Grid based 3D convolutional neural network, dubbed as 3DBG-UNet, that\nparameterizes high dimensional feature space by encoding compact 3D bilateral\ngrids with UNets and infers sharp geometric layout of the scene. Further,\nanother novel 3DBGES-UNet model is introduced that integrate 3DBG-UNet for\ninferring an accurate depth map given a single color view. The 3DBGES-UNet\nconcatenates 3DBG-UNet geometry map with the inception network edge\naccentuation map and a spatial object's boundary map obtained by leveraging\nsemantic segmentation and train the UNet model with ResNet backbone. Both\nmodels are designed with a particular attention to explicitly account for edges\nor minute details. Preserving sharp discontinuities at depth edges is critical\nfor many applications such as realistic integration of virtual objects in AR\nvideo or occlusion-aware view synthesis for 3D display applications.The\nproposed depth prediction network achieves state-of-the-art performance in both\nqualitative and quantitative evaluations on the challenging NYUv2-Depth data.\nThe code and corresponding pre-trained weights will be made publicly available.",
          "link": "http://arxiv.org/abs/2105.10129",
          "publishedOn": "2021-05-24T07:23:03.445Z",
          "wordCount": 653,
          "title": "A Novel 3D-UNet Deep Learning Framework Based on High-Dimensional Bilateral Grid for Edge Consistent Single Image Depth Estimation. (arXiv:2105.10129v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10081",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bassiouny_R/0/1/0/all/0/1\">Rodina Bassiouny</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Adel Mohamed</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Umapathy_K/0/1/0/all/0/1\">Karthi Umapathy</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1\">Naimul Khan</a> (1) ((1) Ryerson University, Toronto, Canada, (2) Mount Sinai Hospital, University of Toronto, Toronto, Canada)",
          "description": "Over the last few decades, Lung Ultrasound (LUS) has been increasingly used\nto diagnose and monitor different lung diseases in neonates. It is a non\ninvasive tool that allows a fast bedside examination while minimally handling\nthe neonate. Acquiring a LUS scan is easy, but understanding the artifacts\nconcerned with each respiratory disease is challenging. Mixed artifact patterns\nfound in different respiratory diseases may limit LUS readability by the\noperator. While machine learning (ML), especially deep learning can assist in\nautomated analysis, simply feeding the ultrasound images to an ML model for\ndiagnosis is not enough to earn the trust of medical professionals. The\nalgorithm should output LUS features that are familiar to the operator instead.\nTherefore, in this paper we present a unique approach for extracting seven\nmeaningful LUS features that can be easily associated with a specific\npathological lung condition: Normal pleura, irregular pleura, thick pleura,\nAlines, Coalescent B-lines, Separate B-lines and Consolidations. These\nartifacts can lead to early prediction of infants developing later respiratory\ndistress symptoms. A single multi-class region proposal-based object detection\nmodel faster-RCNN (fRCNN) was trained on lower posterior lung ultrasound videos\nto detect these LUS features which are further linked to four common neonatal\ndiseases. Our results show that fRCNN surpasses single stage models such as\nRetinaNet and can successfully detect the aforementioned LUS features with a\nmean average precision of 86.4%. Instead of a fully automatic diagnosis from\nimages without any interpretability, detection of such LUS features leave the\nultimate control of diagnosis to the clinician, which can result in a more\ntrustworthy intelligent system.",
          "link": "http://arxiv.org/abs/2105.10081",
          "publishedOn": "2021-05-24T07:23:03.439Z",
          "wordCount": 769,
          "title": "An interpretable object detection based model for the diagnosis of neonatal lung diseases using Ultrasound images. (arXiv:2105.10081v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10375",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhipeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaobo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xiaojiang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Baigui Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>",
          "description": "Face recognition has achieved significant progress in deep-learning era due\nto the ultra-large-scale and well-labeled datasets. However, training on\nultra-large-scale datasets is time-consuming and takes up a lot of hardware\nresource. Therefore, how to design an appropriate training approach is very\ncrucial and indispensable. The computational and hardware cost of training\nultra-large-scale datasets mainly focuses on the Fully-Connected (FC) layer\nrather than convolutional layers. To this end, we propose a novel training\napproach for ultra-large-scale face datasets, termed Faster Face Classification\n(F$^2$C). In F$^2$C, we first define a Gallery Net and a Probe Net that are\nused to generate identities' centers and extract faces' features for face\nrecognition, respectively. Gallery Net has the same structure as Probe Net and\ninherits the parameters from Probe Net with a moving average paradigm. After\nthat, to reduce the training time and hardware resource occupancy of the FC\nlayer, we propose the Dynamic Class Pool that stores the features from Gallery\nNet and calculates the inner product (logits) with positive samples (its\nidentities appear in Dynamic Class Pool) in each mini-batch. Dynamic Class Pool\ncan be regarded as a substitute for the FC layer and its size is much smaller\nthan FC, which is the reason why Dynamic Class Pool can largely reduce the time\nand resource cost. For negative samples (its identities are not appear in the\nDynamic Class Pool), we minimize the cosine similarities between negative\nsamples and Dynamic Class Pool. Then, to improve the update efficiency and\nspeed of Dynamic Class Pool's parameters, we design the Dual Loaders including\nIdentity-based and Instance-based Loaders. Dual Loaders load images from given\ndataset by instances and identities to generate batches for training.",
          "link": "http://arxiv.org/abs/2105.10375",
          "publishedOn": "2021-05-24T07:23:03.432Z",
          "wordCount": 731,
          "title": "An Efficient Training Approach for Very Large Scale Face Recognition. (arXiv:2105.10375v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10239",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ambati_A/0/1/0/all/0/1\">Anirudh Ambati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dubey_S/0/1/0/all/0/1\">Shiv Ram Dubey</a>",
          "description": "Covid-19 global pandemic continues to devastate health care systems across\nthe world. In many countries, the 2nd wave is very severe. Economical and rapid\ntesting, as well as diagnosis, is urgently needed to control the pandemic. At\npresent, the Covid-19 testing is costly and time-consuming. Chest X-Ray (CXR)\ntesting can be the fastest, scalable, and non-invasive method. The existing\nmethods suffer due to the limited CXR samples available from Covid-19. Thus,\ninspired by the limitations of the open-source work in this field, we propose\nattention guided contrastive CNN architecture (AC-CovidNet) for Covid-19\ndetection in CXR images. The proposed method learns the robust and\ndiscriminative features with the help of contrastive loss. Moreover, the\nproposed method gives more importance to the infected regions as guided by the\nattention mechanism. We compute the sensitivity of the proposed method over the\npublicly available Covid-19 dataset. It is observed that the proposed\nAC-CovidNet exhibits very promising performance as compared to the existing\nmethods even with limited training data. It can tackle the bottleneck of CXR\nCovid-19 datasets being faced by the researchers. The code used in this paper\nis released publicly at \\url{https://github.com/shivram1987/AC-CovidNet/}.",
          "link": "http://arxiv.org/abs/2105.10239",
          "publishedOn": "2021-05-24T07:23:03.409Z",
          "wordCount": 687,
          "title": "AC-CovidNet: Attention Guided Contrastive CNN for Recognition of Covid-19 in Chest X-Ray Images. (arXiv:2105.10239v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10214",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Nakanishi_M/0/1/0/all/0/1\">Masaki Nakanishi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sato_K/0/1/0/all/0/1\">Kazuki Sato</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Terada_H/0/1/0/all/0/1\">Hideo Terada</a>",
          "description": "In image anomaly detection, Autoencoders are the popular methods that\nreconstruct the input image that might contain anomalies and output a clean\nimage with no abnormalities. These Autoencoder-based methods usually calculate\nthe anomaly score from the reconstruction error, the difference between the\ninput image and the reconstructed image. On the other hand, the accuracy of the\nreconstruction is insufficient in many of these methods, so it leads to\ndegraded accuracy of anomaly detection. To improve the accuracy of the\nreconstruction, we consider defining loss function in the frequency domain. In\ngeneral, we know that natural images contain many low-frequency components and\nfew high-frequency components. Hence, to improve the accuracy of the\nreconstruction of high-frequency components, we introduce a new loss function\nnamed weighted frequency domain loss(WFDL). WFDL provides a sharper\nreconstructed image, which contributes to improving the accuracy of anomaly\ndetection. In this paper, we show our method's superiority over the\nconventional Autoencoder methods by comparing it with AUROC on the MVTec AD\ndataset.",
          "link": "http://arxiv.org/abs/2105.10214",
          "publishedOn": "2021-05-24T07:23:03.403Z",
          "wordCount": 605,
          "title": "Anomaly Detection By Autoencoder Based On Weighted Frequency Domain Loss. (arXiv:2105.10214v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10160",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuhang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fandong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chaoqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siwen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yizhou Yu</a>",
          "description": "Mammogram mass detection is crucial for diagnosing and preventing the breast\ncancers in clinical practice. The complementary effect of multi-view mammogram\nimages provides valuable information about the breast anatomical prior\nstructure and is of great significance in digital mammography interpretation.\nHowever, unlike radiologists who can utilize the natural reasoning ability to\nidentify masses based on multiple mammographic views, how to endow the existing\nobject detection models with the capability of multi-view reasoning is vital\nfor decision-making in clinical diagnosis but remains the boundary to explore.\nIn this paper, we propose an Anatomy-aware Graph convolutional Network (AGN),\nwhich is tailored for mammogram mass detection and endows existing detection\nmethods with multi-view reasoning ability. The proposed AGN consists of three\nsteps. Firstly, we introduce a Bipartite Graph convolutional Network (BGN) to\nmodel the intrinsic geometric and semantic relations of ipsilateral views.\nSecondly, considering that the visual asymmetry of bilateral views is widely\nadopted in clinical practice to assist the diagnosis of breast lesions, we\npropose an Inception Graph convolutional Network (IGN) to model the structural\nsimilarities of bilateral views. Finally, based on the constructed graphs, the\nmulti-view information is propagated through nodes methodically, which equips\nthe features learned from the examined view with multi-view reasoning ability.\nExperiments on two standard benchmarks reveal that AGN significantly exceeds\nthe state-of-the-art performance. Visualization results show that AGN provides\ninterpretable visual cues for clinical diagnosis.",
          "link": "http://arxiv.org/abs/2105.10160",
          "publishedOn": "2021-05-24T07:23:03.387Z",
          "wordCount": 685,
          "title": "Act Like a Radiologist: Towards Reliable Multi-view Correspondence Reasoning for Mammogram Mass Detection. (arXiv:2105.10160v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10233",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Juvonen_M/0/1/0/all/0/1\">Markus Juvonen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Siltanen_S/0/1/0/all/0/1\">Samuli Siltanen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moura_F/0/1/0/all/0/1\">Fernando Silva de Moura</a>",
          "description": "The photographic dataset collected for the Helsinki Deblur Challenge 2021\n(HDC2021) contains pairs of images taken by two identical cameras of the same\ntarget but with different conditions. One camera is always in focus and\nproduces sharp and low-noise images the other camera produces blurred and noisy\nimages as it is gradually more and more out of focus and has a higher ISO\nsetting. Even though the dataset was designed and captured with the HDC2021 in\nmind it can be used for any testing and benchmarking of image deblurring\nalgorithms. The data is available here: https://doi.org/10.5281/zenodo.477228",
          "link": "http://arxiv.org/abs/2105.10233",
          "publishedOn": "2021-05-24T07:23:03.380Z",
          "wordCount": 536,
          "title": "Helsinki Deblur Challenge 2021: description of photographic data. (arXiv:2105.10233v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Banik_S/0/1/0/all/0/1\">Soubarna Banik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gracia_A/0/1/0/all/0/1\">Alejandro Mendoza Gracia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knoll_A/0/1/0/all/0/1\">Alois Knoll</a>",
          "description": "3D human pose estimation is a difficult task, due to challenges such as\noccluded body parts and ambiguous poses. Graph convolutional networks encode\nthe structural information of the human skeleton in the form of an adjacency\nmatrix, which is beneficial for better pose prediction. We propose one such\ngraph convolutional network named PoseGraphNet for 3D human pose regression\nfrom 2D poses. Our network uses an adaptive adjacency matrix and kernels\nspecific to neighbor groups. We evaluate our model on the Human3.6M dataset\nwhich is a standard dataset for 3D pose estimation. Our model's performance is\nclose to the state-of-the-art, but with much fewer parameters. The model learns\ninteresting adjacency relations between joints that have no physical\nconnections, but are behaviorally similar.",
          "link": "http://arxiv.org/abs/2105.10379",
          "publishedOn": "2021-05-24T07:23:03.373Z",
          "wordCount": 563,
          "title": "3D Human Pose Regression using Graph Convolutional Network. (arXiv:2105.10379v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">C.-H. Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhabra_M/0/1/0/all/0/1\">Mohit Chhabra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Y.-C. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1\">Quan Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshinaga_T/0/1/0/all/0/1\">Tomoaki Yoshinaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murakam_T/0/1/0/all/0/1\">Tomokazu Murakam</a>",
          "description": "Camera movement and unpredictable environmental conditions like dust and wind\ninduce noise into video feeds. We observe that popular unsupervised MOT methods\nare dependent on noise-free conditions. We show that the addition of a small\namount of artificial random noise causes a sharp degradation in model\nperformance on benchmark metrics. We resolve this problem by introducing a\nrobust unsupervised multi-object tracking (MOT) model: AttU-Net. The proposed\nsingle-head attention model helps limit the negative impact of noise by\nlearning visual representations at different segment scales. AttU-Net shows\nbetter unsupervised MOT tracking performance over variational inference-based\nstate-of-the-art baselines. We evaluate our method in the MNIST and the Atari\ngame video benchmark. We also provide two extended video datasets consisting of\ncomplex visual patterns that include Kuzushiji characters and fashion images to\nvalidate the effectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2105.10005",
          "publishedOn": "2021-05-24T07:23:03.354Z",
          "wordCount": 592,
          "title": "Robust Unsupervised Multi-Object Tracking in Noisy Environments. (arXiv:2105.10005v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10238",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zapaishchykova_A/0/1/0/all/0/1\">Anna Zapaishchykova</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dreizin_D/0/1/0/all/0/1\">David Dreizin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1\">Zhaoshuo Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1\">Jie Ying Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Roohi_S/0/1/0/all/0/1\">Shahrooz Faghih Roohi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Unberath_M/0/1/0/all/0/1\">Mathias Unberath</a>",
          "description": "Pelvic ring disruptions result from blunt injury mechanisms and are often\nfound in patients with multi-system trauma. To grade pelvic fracture severity\nin trauma victims based on whole-body CT, the Tile AO/OTA classification is\nfrequently used. Due to the high volume of whole-body trauma CTs generated in\nbusy trauma centers, an automated approach to Tile classification would provide\nsubstantial value, e.,g., to prioritize the reading queue of the attending\ntrauma radiologist. In such scenario, an automated method should perform\ngrading based on a transparent process and based on interpretable features to\nenable interaction with human readers and lower their workload by offering\ninsights from a first automated read of the scan. This paper introduces an\nautomated yet interpretable pelvic trauma decision support system to assist\nradiologists in fracture detection and Tile grade classification. The method\noperates similarly to human interpretation of CT scans and first detects\ndistinct pelvic fractures on CT with high specificity using a Faster-RCNN model\nthat are then interpreted using a structural causal model based on clinical\nbest practices to infer an initial Tile grade. The Bayesian causal model and\nfinally, the object detector are then queried for likely co-occurring fractures\nthat may have been rejected initially due to the highly specific operating\npoint of the detector, resulting in an updated list of detected fractures and\ncorresponding final Tile grade. Our method is transparent in that it provides\nfinding location and type using the object detector, as well as information on\nimportant counterfactuals that would invalidate the system's recommendation and\nachieves an AUC of 83.3%/85.1% for translational/rotational instability.\nDespite being designed for human-machine teaming, our approach does not\ncompromise on performance compared to previous black-box approaches.",
          "link": "http://arxiv.org/abs/2105.10238",
          "publishedOn": "2021-05-24T07:23:03.348Z",
          "wordCount": 736,
          "title": "An Interpretable Approach to Automated Severity Scoring in Pelvic Trauma. (arXiv:2105.10238v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Q/0/1/0/all/0/1\">Qiyuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Bin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngo_C/0/1/0/all/0/1\">Chong-Wah Ngo</a>",
          "description": "In this paper, we propose the pyramid fusion dark channel prior (PF-DCP) for\nsingle image dehazing. Based on the well-known Dark Channel Prior (DCP), we\nintroduce an easy yet effective approach PF-DCP by employing the DCP algorithm\nat a pyramid of multi-scale images to alleviate the problem of patch size\nselection. In this case, we obtain the final transmission map by fusing\ntransmission maps at each level to recover a high-quality haze-free image.\nExperiments on RESIDE SOTS show that PF-DCP not only outperforms the\ntraditional prior-based methods with a large margin but also achieves\ncomparable or even better results of state-of-art deep learning approaches.\nFurthermore, the visual quality is also greatly improved with much fewer color\ndistortions and halo artifacts.",
          "link": "http://arxiv.org/abs/2105.10192",
          "publishedOn": "2021-05-24T07:23:03.341Z",
          "wordCount": 549,
          "title": "Pyramid Fusion Dark Channel Prior for Single Image Dehazing. (arXiv:2105.10192v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10201",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinshuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhicheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1\">Gang Wei</a>",
          "description": "Domain shift has always been one of the primary issues in video object\nsegmentation (VOS), for which models suffer from degeneration when tested on\nunfamiliar datasets. Recently, many online methods have emerged to narrow the\nperformance gap between training data (source domain) and test data (target\ndomain) by fine-tuning on annotations of test data which are usually in\nshortage. In this paper, we propose a novel method to tackle domain shift by\nfirst introducing adversarial domain adaptation to the VOS task, with\nsupervised training on the source domain and unsupervised training on the\ntarget domain. By fusing appearance and motion features with a convolution\nlayer, and by adding supervision onto the motion branch, our model achieves\nstate-of-the-art performance on DAVIS2016 with 82.6% mean IoU score after\nsupervised training. Meanwhile, our adversarial domain adaptation strategy\nsignificantly raises the performance of the trained model when applied on\nFBMS59 and Youtube-Object, without exploiting extra annotations.",
          "link": "http://arxiv.org/abs/2105.10201",
          "publishedOn": "2021-05-24T07:23:03.332Z",
          "wordCount": 584,
          "title": "DAVOS: Semi-Supervised Video Object Segmentation via Adversarial Domain Adaptation. (arXiv:2105.10201v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10110",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1\">Ge-Peng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_Y/0/1/0/all/0/1\">Yu-Cheng Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuming Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shouyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Rong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Ge Gao</a>",
          "description": "Owing to the difficulties of mining spatial-temporal cues, the existing\napproaches for video salient object detection (VSOD) are limited in\nunderstanding complex and noisy scenarios, and often fail in inferring\nprominent objects. To alleviate such shortcomings, we propose a simple yet\nefficient architecture, termed Guidance and Teaching Network (GTNet), to\nindependently distil effective spatial and temporal cues with implicit guidance\nand explicit teaching at feature- and decision-level, respectively. To be\nspecific, we (a) introduce a temporal modulator to implicitly bridge features\nfrom motion into the appearance branch, which is capable of fusing cross-modal\nfeatures collaboratively, and (b) utilise motion-guided mask to propagate the\nexplicit cues during the feature aggregation. This novel learning strategy\nachieves satisfactory results via decoupling the complex spatial-temporal cues\nand mapping informative cues across different modalities. Extensive experiments\non three challenging benchmarks show that the proposed method can run at ~28\nfps on a single TITAN Xp GPU and perform competitively against 14 cutting-edge\nbaselines.",
          "link": "http://arxiv.org/abs/2105.10110",
          "publishedOn": "2021-05-24T07:23:03.326Z",
          "wordCount": 601,
          "title": "Guidance and Teaching Network for Video Salient Object Detection. (arXiv:2105.10110v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1\">Kun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouraoui_Z/0/1/0/all/0/1\">Zied Bouraoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Ping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jameel_S/0/1/0/all/0/1\">Shoaib Jameel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schockaert_S/0/1/0/all/0/1\">Steven Schockaert</a>",
          "description": "Few-shot learning (FSL) is the task of learning to recognize previously\nunseen categories of images from a small number of training examples. This is a\nchallenging task, as the available examples may not be enough to unambiguously\ndetermine which visual features are most characteristic of the considered\ncategories. To alleviate this issue, we propose a method that additionally\ntakes into account the names of the image classes. While the use of class names\nhas already been explored in previous work, our approach differs in two key\naspects. First, while previous work has aimed to directly predict visual\nprototypes from word embeddings, we found that better results can be obtained\nby treating visual and text-based prototypes separately. Second, we propose a\nsimple strategy for learning class name embeddings using the BERT language\nmodel, which we found to substantially outperform the GloVe vectors that were\nused in previous work. We furthermore propose a strategy for dealing with the\nhigh dimensionality of these vectors, inspired by models for aligning\ncross-lingual word embeddings. We provide experiments on miniImageNet, CUB and\ntieredImageNet, showing that our approach consistently improves the\nstate-of-the-art in metric-based FSL.",
          "link": "http://arxiv.org/abs/2105.10195",
          "publishedOn": "2021-05-24T07:23:03.298Z",
          "wordCount": 626,
          "title": "Aligning Visual Prototypes with BERT Embeddings for Few-Shot Learning. (arXiv:2105.10195v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10262",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Satya Rajendra Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_S/0/1/0/all/0/1\">Shiv Ram Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MS_S/0/1/0/all/0/1\">Shruthi MS</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventrapragada_S/0/1/0/all/0/1\">Sairathan Ventrapragada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasharatha_S/0/1/0/all/0/1\">Saivamshi Salla Dasharatha</a>",
          "description": "Deep learning has shown a great improvement in the performance of visual\ntasks. Image retrieval is the task of extracting the visually similar images\nfrom a database for a query image. The feature matching is performed to rank\nthe images. Various hand-designed features have been derived in past to\nrepresent the images. Nowadays, the power of deep learning is being utilized\nfor automatic feature learning from data in the field of biomedical image\nanalysis. Autoencoder and Siamese networks are two deep learning models to\nlearn the latent space (i.e., features or embedding). Autoencoder works based\non the reconstruction of the image from latent space. Siamese network utilizes\nthe triplets to learn the intra-class similarity and inter-class dissimilarity.\nMoreover, Autoencoder is unsupervised, whereas Siamese network is supervised.\nWe propose a Joint Triplet Autoencoder Network (JTANet) by facilitating the\ntriplet learning in autoencoder framework. A joint supervised learning for\nSiamese network and unsupervised learning for Autoencoder is performed.\nMoreover, the Encoder network of Autoencoder is shared with Siamese network and\nreferred as the Siamcoder network. The features are extracted by using the\ntrained Siamcoder network for retrieval purpose. The experiments are performed\nover Histopathological Routine Colon Cancer dataset. We have observed the\npromising performance using the proposed JTANet model against the Autoencoder\nand Siamese models for colon cancer nuclei retrieval in histopathological\nimages.",
          "link": "http://arxiv.org/abs/2105.10262",
          "publishedOn": "2021-05-24T07:23:03.292Z",
          "wordCount": 659,
          "title": "Joint Triplet Autoencoder for Histopathological Colon Cancer Nuclei Retrieval. (arXiv:2105.10262v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10112",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_G/0/1/0/all/0/1\">Guang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wennan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lin Xu</a>",
          "description": "Many efforts have been devoted to designing sampling, mining, and weighting\nstrategies in high-level deep metric learning (DML) loss objectives. However,\nlittle attention has been paid to low-level but essential data transformation.\nIn this paper, we develop a novel mechanism, the independent domain embedding\naugmentation learning ({IDEAL}) method. It can simultaneously learn multiple\nindependent embedding spaces for multiple domains generated by predefined data\ntransformations. Our IDEAL is orthogonal to existing DML techniques and can be\nseamlessly combined with prior DML approaches for enhanced performance.\nEmpirical results on visual retrieval tasks demonstrate the superiority of the\nproposed method. For example, the IDEAL improves the performance of MS loss by\na large margin, 84.5\\% $\\rightarrow$ 87.1\\% on Cars-196, and 65.8\\%\n$\\rightarrow$ 69.5\\% on CUB-200 at Recall$@1$. Our IDEAL with MS loss also\nachieves the new state-of-the-art performance on three image retrieval\nbenchmarks, \\ie, \\emph{Cars-196}, \\emph{CUB-200}, and \\emph{SOP}. It\noutperforms the most recent DML approaches, such as Circle loss and XBM,\nsignificantly. The source code and pre-trained models of our method will be\navailable at\\emph{\\url{https://github.com/emdata-ailab/IDEAL}}.",
          "link": "http://arxiv.org/abs/2105.10112",
          "publishedOn": "2021-05-24T07:23:03.284Z",
          "wordCount": 610,
          "title": "IDEAL: Independent Domain Embedding Augmentation Learning. (arXiv:2105.10112v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10194",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hong_D/0/1/0/all/0/1\">Danfeng Hong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gao_L/0/1/0/all/0/1\">Lianru Gao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yao_J/0/1/0/all/0/1\">Jing Yao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yokoya_N/0/1/0/all/0/1\">Naoto Yokoya</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chanussot_J/0/1/0/all/0/1\">Jocelyn Chanussot</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Heiden_U/0/1/0/all/0/1\">Uta Heiden</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_B/0/1/0/all/0/1\">Bing Zhang</a>",
          "description": "Over the past decades, enormous efforts have been made to improve the\nperformance of linear or nonlinear mixing models for hyperspectral unmixing,\nyet their ability to simultaneously generalize various spectral variabilities\nand extract physically meaningful endmembers still remains limited due to the\npoor ability in data fitting and reconstruction and the sensitivity to various\nspectral variabilities. Inspired by the powerful learning ability of deep\nlearning, we attempt to develop a general deep learning approach for\nhyperspectral unmixing, by fully considering the properties of endmembers\nextracted from the hyperspectral imagery, called endmember-guided unmixing\nnetwork (EGU-Net). Beyond the alone autoencoder-like architecture, EGU-Net is a\ntwo-stream Siamese deep network, which learns an additional network from the\npure or nearly-pure endmembers to correct the weights of another unmixing\nnetwork by sharing network parameters and adding spectrally meaningful\nconstraints (e.g., non-negativity and sum-to-one) towards a more accurate and\ninterpretable unmixing solution. Furthermore, the resulting general framework\nis not only limited to pixel-wise spectral unmixing but also applicable to\nspatial information modeling with convolutional operators for spatial-spectral\nunmixing. Experimental results conducted on three different datasets with the\nground-truth of abundance maps corresponding to each material demonstrate the\neffectiveness and superiority of the EGU-Net over state-of-the-art unmixing\nalgorithms. The codes will be available from the website:\nhttps://github.com/danfenghong/IEEE_TNNLS_EGU-Net.",
          "link": "http://arxiv.org/abs/2105.10194",
          "publishedOn": "2021-05-24T07:23:03.277Z",
          "wordCount": 679,
          "title": "Endmember-Guided Unmixing Network (EGU-Net): A General Deep Learning Framework for Self-Supervised Hyperspectral Unmixing. (arXiv:2105.10194v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carton_F/0/1/0/all/0/1\">Florence Carton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filliat_D/0/1/0/all/0/1\">David Filliat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabarisoa_J/0/1/0/all/0/1\">Jaonary Rabarisoa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1\">Quoc Cuong Pham</a>",
          "description": "In recent years, we have witnessed increasingly high performance in the field\nof autonomous end-to-end driving. In particular, more and more research is\nbeing done on driving in urban environments, where the car has to follow high\nlevel commands to navigate. However, few evaluations are made on the ability of\nthese agents to react in an unexpected situation. Specifically, no evaluations\nare conducted on the robustness of driving agents in the event of a bad\nhigh-level command. We propose here an evaluation method, namely a benchmark\nthat allows to assess the robustness of an agent, and to appreciate its\nunderstanding of the environment through its ability to keep a safe behavior,\nregardless of the instruction.",
          "link": "http://arxiv.org/abs/2105.10014",
          "publishedOn": "2021-05-24T07:23:03.246Z",
          "wordCount": 567,
          "title": "Evaluating Robustness over High Level Driving Instruction for Autonomous Driving. (arXiv:2105.10014v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10159",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ung_H/0/1/0/all/0/1\">Huy Quang Ung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Cuong Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Hung Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakagawa_M/0/1/0/all/0/1\">Masaki Nakagawa</a>",
          "description": "Toward a computer-assisted marking for descriptive math questions,this paper\npresents clustering of online handwritten mathematical expressions (OnHMEs) to\nhelp human markers to mark them efficiently and reliably. We propose a\ngenerative sequence similarity function for computing a similarity score of two\nOnHMEs based on a sequence-to-sequence OnHME recognizer. Each OnHME is\nrepresented by a similarity-based representation (SbR) vector. The SbR matrix\nis inputted to the k-means algorithm for clustering OnHMEs. Experiments are\nconducted on an answer dataset (Dset_Mix) of 200 OnHMEs mixed of real patterns\nand synthesized patterns for each of 10 questions and a real online handwritten\nmathematical answer dataset of 122 student answers at most for each of 15\nquestions (NIER_CBT). The best clustering results achieved around 0.916 and\n0.915 for purity, and around 0.556 and 0.702 for the marking cost on Dset_Mix\nand NIER_CBT, respectively. Our method currently outperforms the previous\nmethods for clustering HMEs.",
          "link": "http://arxiv.org/abs/2105.10159",
          "publishedOn": "2021-05-24T07:23:03.240Z",
          "wordCount": 603,
          "title": "GSSF: A Generative Sequence Similarity Function based on a Seq2Seq model for clustering online handwritten mathematical answers. (arXiv:2105.10159v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10341",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bragilevsky_L/0/1/0/all/0/1\">Lior Bragilevsky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bajic_I/0/1/0/all/0/1\">Ivan V. Baji&#x107;</a>",
          "description": "In the race to bring Artificial Intelligence (AI) to the edge, collaborative\nintelligence has emerged as a promising way to lighten the computation load on\nedge devices that run applications based on Deep Neural Networks (DNNs).\nTypically, a deep model is split at a certain layer into edge and cloud\nsub-models. The deep feature tensor produced by the edge sub-model is\ntransmitted to the cloud, where the remaining computationally intensive\nworkload is performed by the cloud sub-model. The communication channel between\nthe edge and cloud is imperfect, which will result in missing data in the deep\nfeature tensor received at the cloud side. In this study, we examine the\neffectiveness of four low-rank tensor completion methods in recovering missing\ndata in the deep feature tensor. We consider both sparse tensors, such as those\nproduced by the VGG16 model, as well as non-sparse tensors, such as those\nproduced by ResNet34 model. We study tensor completion effectiveness in both\nconplexity-constrained and unconstrained scenario.",
          "link": "http://arxiv.org/abs/2105.10341",
          "publishedOn": "2021-05-24T07:23:03.234Z",
          "wordCount": 620,
          "title": "Error Resilient Collaborative Intelligence via Low-Rank Tensor Completion. (arXiv:2105.10341v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1\">Danfeng Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jingliang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jing Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chanussot_J/0/1/0/all/0/1\">Jocelyn Chanussot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiao Xiang Zhu</a>",
          "description": "As remote sensing (RS) data obtained from different sensors become available\nlargely and openly, multimodal data processing and analysis techniques have\nbeen garnering increasing interest in the RS and geoscience community. However,\ndue to the gap between different modalities in terms of imaging sensors,\nresolutions, and contents, embedding their complementary information into a\nconsistent, compact, accurate, and discriminative representation, to a great\nextent, remains challenging. To this end, we propose a shared and specific\nfeature learning (S2FL) model. S2FL is capable of decomposing multimodal RS\ndata into modality-shared and modality-specific components, enabling the\ninformation blending of multi-modalities more effectively, particularly for\nheterogeneous data sources. Moreover, to better assess multimodal baselines and\nthe newly-proposed S2FL model, three multimodal RS benchmark datasets, i.e.,\nHouston2013 -- hyperspectral and multispectral data, Berlin -- hyperspectral\nand synthetic aperture radar (SAR) data, Augsburg -- hyperspectral, SAR, and\ndigital surface model (DSM) data, are released and used for land cover\nclassification. Extensive experiments conducted on the three datasets\ndemonstrate the superiority and advancement of our S2FL model in the task of\nland cover classification in comparison with previously-proposed\nstate-of-the-art baselines. Furthermore, the baseline codes and datasets used\nin this paper will be made available freely at\nhttps://github.com/danfenghong/ISPRS_S2FL.",
          "link": "http://arxiv.org/abs/2105.10196",
          "publishedOn": "2021-05-24T07:23:03.226Z",
          "wordCount": 662,
          "title": "Multimodal Remote Sensing Benchmark Datasets for Land Cover Classification with A Shared and Specific Feature Learning Model. (arXiv:2105.10196v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10227",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Abdullahi_S/0/1/0/all/0/1\">Sani M. Abdullahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shuifa_S/0/1/0/all/0/1\">Sun Shuifa</a>",
          "description": "Cancelable biometric techniques have been used to prevent the compromise of\nbiometric data by generating and using their corresponding cancelable templates\nfor user authentication. However, the non-invertible distance preserving\ntransformation methods employed in various schemes are often vulnerable to\ninformation leakage since matching is performed in the transformed domain. In\nthis paper, we propose a non-invertible distance preserving scheme based on\nvector permutation and shift-order process. First, the dimension of feature\nvectors is reduced using kernelized principle component analysis (KPCA) prior\nto randomly permuting the extracted vector features. A shift-order process is\nthen applied to the generated features in order to achieve non-invertibility\nand combat similarity-based attacks. The generated hash codes are resilient to\ndifferent security and privacy attacks whilst fulfilling the major revocability\nand unlinkability requirements. Experimental evaluation conducted on 6 datasets\nof FVC2002 and FVC2004 reveals a high-performance accuracy of the proposed\nscheme better than other existing state-of-the-art schemes.",
          "link": "http://arxiv.org/abs/2105.10227",
          "publishedOn": "2021-05-24T07:23:03.208Z",
          "wordCount": 601,
          "title": "Random Hash Code Generation for Cancelable Fingerprint Templates using Vector Permutation and Shift-order Process. (arXiv:2105.10227v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Cuong Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1\">Thanh-Nghia Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Hung Tuan Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakagawa_M/0/1/0/all/0/1\">Masaki Nakagawa</a>",
          "description": "This paper presents a temporal classification method for all three subtasks\nof symbol segmentation, symbol recognition and relation classification in\nonline handwritten mathematical expressions (HMEs). The classification model is\ntrained by multiple paths of symbols and spatial relations derived from the\nSymbol Relation Tree (SRT) representation of HMEs. The method benefits from\nglobal context of a deep bidirectional Long Short-term Memory network, which\nlearns the temporal classification directly from online handwriting by the\nConnectionist Temporal Classification loss. To recognize an online HME, a\nsymbol-level parse tree with Context-Free Grammar is constructed, where symbols\nand spatial relations are obtained from the temporal classification results. We\nshow the effectiveness of the proposed method on the two latest CROHME\ndatasets.",
          "link": "http://arxiv.org/abs/2105.10156",
          "publishedOn": "2021-05-24T07:23:03.201Z",
          "wordCount": 557,
          "title": "Global Context for improving recognition of Online Handwritten Mathematical Expressions. (arXiv:2105.10156v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Chih-Hong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knoll_A/0/1/0/all/0/1\">Alois Knoll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_H/0/1/0/all/0/1\">Hsuan-Cheng Liao</a>",
          "description": "Within the context of autonomous driving, safety-related metrics for deep\nneural networks have been widely studied for image classification and object\ndetection. In this paper, we further consider safety-aware correctness and\nrobustness metrics specialized for semantic segmentation. The novelty of our\nproposal is to move beyond pixel-level metrics: Given two images with each\nhaving N pixels being class-flipped, the designed metrics should, depending on\nthe clustering of pixels being class-flipped or the location of occurrence,\nreflect a different level of safety criticality. The result evaluated on an\nautonomous driving dataset demonstrates the validity and practicality of our\nproposed methodology.",
          "link": "http://arxiv.org/abs/2105.10142",
          "publishedOn": "2021-05-24T07:23:03.194Z",
          "wordCount": 531,
          "title": "Safety Metrics for Semantic Segmentation in Autonomous Driving. (arXiv:2105.10142v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10288",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ayazoglu_M/0/1/0/all/0/1\">Mustafa Ayazoglu</a>",
          "description": "Single-Image Super Resolution (SISR) is a classical computer vision problem\nand it has been studied for over decades. With the recent success of deep\nlearning methods, recent work on SISR focuses solutions with deep learning\nmethodologies and achieves state-of-the-art results. However most of the\nstate-of-the-art SISR methods contain millions of parameters and layers, which\nlimits their practical applications. In this paper, we propose a hardware\n(Synaptics Dolphin NPU) limitation aware, extremely lightweight quantization\nrobust real-time super resolution network (XLSR). The proposed model's building\nblock is inspired from root modules for Image classification. We successfully\napplied root modules to SISR problem, further more to make the model uint8\nquantization robust we used Clipped ReLU at the last layer of the network and\nachieved great balance between reconstruction quality and runtime. Furthermore,\nalthough the proposed network contains 30x fewer parameters than VDSR its\nperformance surpasses it on Div2K validation set. The network proved itself by\nwinning Mobile AI 2021 Real-Time Single Image Super Resolution Challenge.",
          "link": "http://arxiv.org/abs/2105.10288",
          "publishedOn": "2021-05-24T07:23:03.187Z",
          "wordCount": 619,
          "title": "Extremely Lightweight Quantization Robust Real-Time Single-Image Super Resolution for Mobile Devices. (arXiv:2105.10288v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10104",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1\">Leilei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lin Xu</a>",
          "description": "Scale variation is one of the most challenging problems in face detection.\nModern face detectors employ feature pyramids to deal with scale variation.\nHowever, it might break the feature consistency across different scales of\nfaces. In this paper, we propose a simple yet effective method named the\nreceptive field pyramids (RFP) method to enhance the representation ability of\nfeature pyramids. It can learn different receptive fields in each feature map\nadaptively based on the varying scales of detected faces. Empirical results on\ntwo face detection benchmark datasets, i.e., WIDER FACE and UFDD, demonstrate\nthat our proposed method can accelerate the inference rate significantly while\nachieving state-of-the-art performance. The source code of our method is\navailable at \\url{https://github.com/emdata-ailab/EMface}.",
          "link": "http://arxiv.org/abs/2105.10104",
          "publishedOn": "2021-05-24T07:23:03.181Z",
          "wordCount": 557,
          "title": "EMface: Detecting Hard Faces by Exploring Receptive Field Pyraminds. (arXiv:2105.10104v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10131",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sato_Y/0/1/0/all/0/1\">Yuri Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mineshima_K/0/1/0/all/0/1\">Koji Mineshima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueda_K/0/1/0/all/0/1\">Kazuhiro Ueda</a>",
          "description": "There has been a widely held view that visual representations (e.g.,\nphotographs and illustrations) do not depict negation, for example, one that\ncan be expressed by a sentence \"the train is not coming\". This view is\nempirically challenged by analyzing the real-world visual representations of\ncomic (manga) illustrations. In the experiment using image captioning tasks, we\ngave people comic illustrations and asked them to explain what they could read\nfrom them. The collected data showed that some comic illustrations could depict\nnegation without any aid of sequences (multiple panels) or conventional devices\n(special symbols). This type of comic illustrations was subjected to further\nexperiments, classifying images into those containing negation and those not\ncontaining negation. While this image classification was easy for humans, it\nwas difficult for data-driven machines, i.e., deep learning models (CNN), to\nachieve the same high performance. Given the findings, we argue that some comic\nillustrations evoke background knowledge and thus can depict negation with\npurely visual elements.",
          "link": "http://arxiv.org/abs/2105.10131",
          "publishedOn": "2021-05-24T07:23:03.174Z",
          "wordCount": 617,
          "title": "Visual representation of negation: Real world data analysis on comic image design. (arXiv:2105.10131v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Aniruddha Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tejankar_A/0/1/0/all/0/1\">Ajinkya Tejankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koohpayegani_S/0/1/0/all/0/1\">Soroush Abbasi Koohpayegani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pirsiavash_H/0/1/0/all/0/1\">Hamed Pirsiavash</a>",
          "description": "Large-scale unlabeled data has allowed recent progress in self-supervised\nlearning methods that learn rich visual representations. State-of-the-art\nself-supervised methods for learning representations from images (MoCo and\nBYOL) use an inductive bias that different augmentations (e.g. random crops) of\nan image should produce similar embeddings. We show that such methods are\nvulnerable to backdoor attacks where an attacker poisons a part of the\nunlabeled data by adding a small trigger (known to the attacker) to the images.\nThe model performance is good on clean test images but the attacker can\nmanipulate the decision of the model by showing the trigger at test time.\nBackdoor attacks have been studied extensively in supervised learning and to\nthe best of our knowledge, we are the first to study them for self-supervised\nlearning. Backdoor attacks are more practical in self-supervised learning since\nthe unlabeled data is large and as a result, an inspection of the data to avoid\nthe presence of poisoned data is prohibitive. We show that in our targeted\nattack, the attacker can produce many false positives for the target category\nby using the trigger at test time. We also propose a knowledge distillation\nbased defense algorithm that succeeds in neutralizing the attack. Our code is\navailable here: https://github.com/UMBCvision/SSL-Backdoor .",
          "link": "http://arxiv.org/abs/2105.10123",
          "publishedOn": "2021-05-24T07:23:03.167Z",
          "wordCount": 633,
          "title": "Backdoor Attacks on Self-Supervised Learning. (arXiv:2105.10123v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09975",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mousavi_S/0/1/0/all/0/1\">Sara Mousavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhenning Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cross_K/0/1/0/all/0/1\">Kelley Cross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steadman_D/0/1/0/all/0/1\">Dawnie Steadman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mockus_A/0/1/0/all/0/1\">Audris Mockus</a>",
          "description": "Annotating images for semantic segmentation requires intense manual labor and\nis a time-consuming and expensive task especially for domains with a scarcity\nof experts, such as Forensic Anthropology. We leverage the evolving nature of\nimages depicting the decay process in human decomposition data to design a\nsimple yet effective pseudo-pixel-level label generation technique to reduce\nthe amount of effort for manual annotation of such images. We first identify\nsequences of images with a minimum variation that are most suitable to share\nthe same or similar annotation using an unsupervised approach. Given one\nuser-annotated image in each sequence, we propagate the annotation to the\nremaining images in the sequence by merging it with annotations produced by a\nstate-of-the-art CAM-based pseudo label generation technique. To evaluate the\nquality of our pseudo-pixel-level labels, we train two semantic segmentation\nmodels with VGG and ResNet backbones on images labeled using our pseudo\nlabeling method and those of a state-of-the-art method. The results indicate\nthat using our pseudo-labels instead of those generated using the\nstate-of-the-art method in the training process improves the mean-IoU and the\nfrequency-weighted-IoU of the VGG and ResNet-based semantic segmentation models\nby 3.36%, 2.58%, 10.39%, and 12.91% respectively.",
          "link": "http://arxiv.org/abs/2105.09975",
          "publishedOn": "2021-05-24T07:23:03.147Z",
          "wordCount": 630,
          "title": "Pseudo Pixel-level Labeling for Images with Evolving Content. (arXiv:2105.09975v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10154",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lumin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1\">Yingda Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">Sheng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wentao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanli Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaogang Wang</a>",
          "description": "Human pose estimation has achieved significant progress in recent years.\nHowever, most of the recent methods focus on improving accuracy using\ncomplicated models and ignoring real-time efficiency. To achieve a better\ntrade-off between accuracy and efficiency, we propose a novel neural\narchitecture search (NAS) method, termed ViPNAS, to search networks in both\nspatial and temporal levels for fast online video pose estimation. In the\nspatial level, we carefully design the search space with five different\ndimensions including network depth, width, kernel size, group number, and\nattentions. In the temporal level, we search from a series of temporal feature\nfusions to optimize the total accuracy and speed across multiple video frames.\nTo the best of our knowledge, we are the first to search for the temporal\nfeature fusion and automatic computation allocation in videos. Extensive\nexperiments demonstrate the effectiveness of our approach on the challenging\nCOCO2017 and PoseTrack2018 datasets. Our discovered model family, S-ViPNAS and\nT-ViPNAS, achieve significantly higher inference speed (CPU real-time) without\nsacrificing the accuracy compared to the previous state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2105.10154",
          "publishedOn": "2021-05-24T07:23:03.130Z",
          "wordCount": 617,
          "title": "ViPNAS: Efficient Video Pose Estimation via Neural Architecture Search. (arXiv:2105.10154v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10063",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Santos_E/0/1/0/all/0/1\">Ezequiel Fran&#xe7;a dos Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fontenelle_G/0/1/0/all/0/1\">Gabriel Fontenelle</a>",
          "description": "This paper presents a game, controlled by computer vision, in identification\nof hand gestures (hand-tracking). The proposed work is based on image\nsegmentation and construction of a convex hull with Jarvis Algorithm , and\ndetermination of the pattern based on the extraction of area characteristics in\nthe convex hull.",
          "link": "http://arxiv.org/abs/2105.10063",
          "publishedOn": "2021-05-24T07:23:03.121Z",
          "wordCount": 487,
          "title": "Uma implementa\\c{c}\\~ao do jogo Pedra, Papel e Tesoura utilizando Visao Computacional. (arXiv:2105.10063v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09464",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yongxiang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1\">Xiaolin Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yuncong Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lu Li</a>",
          "description": "Recently, plenty of work has tried to introduce transformers into computer\nvision tasks, with good results. Unlike classic convolution networks, which\nextract features within a local receptive field, transformers can adaptively\naggregate similar features from a global view using self-attention mechanism.\nFor object detection, Feature Pyramid Network (FPN) proposes feature\ninteraction across layers and proves its extremely importance. However, its\ninteraction is still in a local manner, which leaves a lot of",
          "link": "http://arxiv.org/abs/2105.09464",
          "publishedOn": "2021-05-22T03:02:52.677Z",
          "wordCount": 634,
          "title": "Content-Augmented Feature Pyramid Network with Light Linear Transformers. (arXiv:2105.09464v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09701",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Hao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weihua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xianzhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jianyang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yiqi Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shuting He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hao Li</a>",
          "description": "This paper introduces our solution for the Track2 in AI City Challenge 2021\n(AICITY21). The Track2 is a vehicle re-identification (ReID) task with both the\nreal-world data and synthetic data. We mainly focus on four points, i.e.\ntraining data, unsupervised domain-adaptive (UDA) training, post-processing,\nmodel ensembling in this challenge. (1) Both cropping training data and using\nsynthetic data can help the model learn more discriminative features. (2) Since\nthere is a new scenario in the test set that dos",
          "link": "http://arxiv.org/abs/2105.09701",
          "publishedOn": "2021-05-22T03:02:52.626Z",
          "wordCount": 610,
          "title": "An Empirical Study of Vehicle Re-Identification on the AI City Challenge. (arXiv:2105.09701v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03814",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Autthasan_P/0/1/0/all/0/1\">Phairot Autthasan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chaisaen_R/0/1/0/all/0/1\">Rattanaphon Chaisaen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sudhawiyangkul_T/0/1/0/all/0/1\">Thapanun Sudhawiyangkul</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rangpong_P/0/1/0/all/0/1\">Phurin Rangpong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiatthaveephong_S/0/1/0/all/0/1\">Suktipol Kiatthaveephong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dilokthanakul_N/0/1/0/all/0/1\">Nat Dilokthanakul</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bhakdisongkhram_G/0/1/0/all/0/1\">Gun Bhakdisongkhram</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Phan_H/0/1/0/all/0/1\">Huy Phan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guan_C/0/1/0/all/0/1\">Cuntai Guan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wilaiprasitporn_T/0/1/0/all/0/1\">Theerawit Wilaiprasitporn</a>",
          "description": "Advances in the motor imagery (MI)-based brain-computer interfaces (BCIs)\nallow control of several applications by decoding neurophysiological phenomena,\nwhich are usually recorded by electroencephalography (EEG) using a non-invasive\ntechnique. Despite great advances in MI-based BCI, EEG rhythms are specific to\na subject and various changes over time. These issues point to significant\nchallenges to enhance the classification performance, especially in a\nsubject-independent manner. To overcome these challeng",
          "link": "http://arxiv.org/abs/2102.03814",
          "publishedOn": "2021-05-22T03:02:52.386Z",
          "wordCount": 664,
          "title": "MIN2Net: End-to-End Multi-Task Learning for Subject-Independent Motor Imagery EEG Classification. (arXiv:2102.03814v3 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Aaditya Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hingane_S/0/1/0/all/0/1\">Shreeshail Hingane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_X/0/1/0/all/0/1\">Xinyu Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Artistic style transfer aims to transfer the style characteristics of one\nimage onto another image while retaining its content. Existing approaches\ncommonly leverage various normalization techniques, although these face\nlimitations in adequately transferring diverse textures to different spatial\nlocations. Self-Attention-based approaches have tackled this issue with partial\nsuccess but suffer from unwanted artifacts. Motivated by these observations,\nthis paper aims to combine the best of both worlds: self-a",
          "link": "http://arxiv.org/abs/2105.06129",
          "publishedOn": "2021-05-22T03:02:52.228Z",
          "wordCount": 616,
          "title": "SAFIN: Arbitrary Style Transfer With Self-Attentive Factorized Instance Normalization. (arXiv:2105.06129v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paletta_Q/0/1/0/all/0/1\">Quentin Paletta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lasenby_J/0/1/0/all/0/1\">Joan Lasenby</a>",
          "description": "Improving irradiance forecasting is critical to further increase the share of\nsolar in the energy mix. On a short time scale, fish-eye cameras on the ground\nare used to capture cloud displacements causing the local variability of the\nelectricity production. As most of the solar radiation comes directly from the\nSun, current forecasting approaches use its position in the image as a\nreference to interpret the cloud cover dynamics. However, existing Sun tracking\nmethods rely on external data and a calibration ",
          "link": "http://arxiv.org/abs/2012.01059",
          "publishedOn": "2021-05-22T03:02:51.863Z",
          "wordCount": 634,
          "title": "A Temporally Consistent Image-based Sun Tracking Algorithm for Solar Energy Forecasting Applications. (arXiv:2012.01059v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03196",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Samani_E/0/1/0/all/0/1\">Ekta U. Samani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xingjian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1\">Ashis G. Banerjee</a>",
          "description": "Object recognition in unseen indoor environments remains a challenging\nproblem for visual perception of mobile robots. In this letter, we propose the\nuse of topologically persistent features, which rely on the objects' shape\ninformation, to address this challenge. In particular, we extract two kinds of\nfeatures, namely, sparse persistence image (PI) and amplitude, by applying\npersistent homology to multi-directional height function-based filtrations of\nthe cubical complexes representing the object segmentat",
          "link": "http://arxiv.org/abs/2010.03196",
          "publishedOn": "2021-05-22T03:02:51.744Z",
          "wordCount": 761,
          "title": "Visual Object Recognition in Indoor Environments Using Topologically Persistent Features. (arXiv:2010.03196v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tsotsos_J/0/1/0/all/0/1\">John K. Tsotsos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jun Luo</a>",
          "description": "Learned networks in the domain of visual recognition and cognition impress in\npart because even though they are trained with datasets many orders of\nmagnitude smaller than the full population of possible images, they exhibit\nsufficient generalization to be applicable to new and previously unseen data.\nAlthough many have examined issues regarding generalization from several\nperspectives, we wondered If a network is trained with a biased dataset that\nmisses particular samples corresponding to some defining do",
          "link": "http://arxiv.org/abs/2105.09934",
          "publishedOn": "2021-05-22T03:02:51.709Z",
          "wordCount": 730,
          "title": "Probing the Effect of Selection Bias on NN Generalization with a Thought Experiment. (arXiv:2105.09934v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09830",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Weidler_T/0/1/0/all/0/1\">Tonio Weidler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehnen_J/0/1/0/all/0/1\">Julian Lehnen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denman_Q/0/1/0/all/0/1\">Quinton Denman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebok_D/0/1/0/all/0/1\">D&#xe1;vid Seb&#x151;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gerhard Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Driessens_K/0/1/0/all/0/1\">Kurt Driessens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Senden_M/0/1/0/all/0/1\">Mario Senden</a>",
          "description": "Lateral connections play an important role for sensory processing in visual\ncortex by supporting discriminable neuronal responses even to highly similar\nfeatures. In the present work, we show that establishing a biologically\ninspired Mexican hat lateral connectivity profile along the filter domain can\nsignificantly improve the classification accuracy of a variety of lightweight\nconvolutional neural networks without the addition of trainable network\nparameters. Moreover, we demonstrate that it is possible to",
          "link": "http://arxiv.org/abs/2105.09830",
          "publishedOn": "2021-05-22T03:02:51.668Z",
          "wordCount": 573,
          "title": "Biologically Inspired Semantic Lateral Connectivity for Convolutional Neural Networks. (arXiv:2105.09830v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09880",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+McNally_W/0/1/0/all/0/1\">William McNally</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walters_P/0/1/0/all/0/1\">Pascale Walters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vats_K/0/1/0/all/0/1\">Kanav Vats</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alexander Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McPhee_J/0/1/0/all/0/1\">John McPhee</a>",
          "description": "Existing multi-camera solutions for automatic scorekeeping in steel-tip darts\nare very expensive and thus inaccessible to most players. Motivated to develop\na more accessible low-cost solution, we present a new approach to keypoint\ndetection and apply it to predict dart scores from a single image taken from\nany camera angle. This problem involves detecting multiple keypoints that may\nbe of the same class and positioned in close proximity to one another. The\nwidely adopted framework for regressing keypoints ",
          "link": "http://arxiv.org/abs/2105.09880",
          "publishedOn": "2021-05-22T03:02:51.661Z",
          "wordCount": 718,
          "title": "DeepDarts: Modeling Keypoints as Objects for Automatic Scorekeeping in Darts using a Single Camera. (arXiv:2105.09880v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09720",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mudiyanselage_T/0/1/0/all/0/1\">Thosini Bamunu Mudiyanselage</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Senanayake_N/0/1/0/all/0/1\">Nipuna Senanayake</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ji_C/0/1/0/all/0/1\">Chunyan Ji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_Y/0/1/0/all/0/1\">Yi Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanqing Zhang</a>",
          "description": "The novel corona virus (Covid-19) has introduced significant challenges due\nto its rapid spreading nature through respiratory transmission. As a result,\nthere is a huge demand for Artificial Intelligence (AI) based quick disease\ndiagnosis methods as an alternative to high demand tests such as Polymerase\nChain Reaction (PCR). Chest X-ray (CXR) Image analysis is such cost-effective\nradiography technique due to resource availability and quick screening. But, a\nsufficient and systematic data collection that is ",
          "link": "http://arxiv.org/abs/2105.09720",
          "publishedOn": "2021-05-22T03:02:51.631Z",
          "wordCount": 747,
          "title": "Covid-19 Detection from Chest X-ray and Patient Metadata using Graph Convolutional Neural Networks. (arXiv:2105.09720v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09750",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Du_Z/0/1/0/all/0/1\">Zongcai Du</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jie Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_G/0/1/0/all/0/1\">Gangshan Wu</a>",
          "description": "Along with the rapid development of real-world applications, higher\nrequirements on the accuracy and efficiency of image super-resolution (SR) are\nbrought forward. Though existing methods have achieved remarkable success, the\nmajority of them demand plenty of computational resources and large amount of\nRAM, and thus they can not be well applied to mobile device. In this paper, we\naim at designing efficient architecture for 8-bit quantization and deploy it on\nmobile device. First, we conduct an experiment ab",
          "link": "http://arxiv.org/abs/2105.09750",
          "publishedOn": "2021-05-22T03:02:51.625Z",
          "wordCount": 596,
          "title": "Anchor-based Plain Net for Mobile Image Super-Resolution. (arXiv:2105.09750v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09279",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hornauer_S/0/1/0/all/0/1\">Sascha Hornauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Stella X. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaffarzadegan_S/0/1/0/all/0/1\">Shabnam Ghaffarzadegan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_L/0/1/0/all/0/1\">Liu Ren</a>",
          "description": "Recent progress in network-based audio event classification has shown the\nbenefit of pre-training models on visual data such as ImageNet. While this\nprocess allows knowledge transfer across different domains, training a model on\nlarge-scale visual datasets is time consuming. On several audio event\nclassification benchmarks, we show a fast and effective alternative that\npre-trains the model unsupervised, only on audio data and yet delivers on-par\nperformance with ImageNet pre-training. Furthermore, we show t",
          "link": "http://arxiv.org/abs/2105.09279",
          "publishedOn": "2021-05-22T03:02:51.614Z",
          "wordCount": 573,
          "title": "Unsupervised Discriminative Learning of Sounds for Audio Event Classification. (arXiv:2105.09279v2 [cs.SD] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08506",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ahmed_S/0/1/0/all/0/1\">Sara Atito Ali Ahmed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yavuz_M/0/1/0/all/0/1\">Mehmet Can Yavuz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sen_M/0/1/0/all/0/1\">Mehmet Umut Sen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gulsen_F/0/1/0/all/0/1\">Fatih Gulsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tutar_O/0/1/0/all/0/1\">Onur Tutar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korkmazer_B/0/1/0/all/0/1\">Bora Korkmazer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Samanci_C/0/1/0/all/0/1\">Cesur Samanci</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sirolu_S/0/1/0/all/0/1\">Sabri Sirolu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hamid_R/0/1/0/all/0/1\">Rauf Hamid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Eryurekli_A/0/1/0/all/0/1\">Ali Ergun Eryurekli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mammadov_T/0/1/0/all/0/1\">Toghrul Mammadov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yanikoglu_B/0/1/0/all/0/1\">Berrin Yanikoglu</a>",
          "description": "Detecting COVID-19 in computed tomography (CT) or radiography images has been\nproposed as a supplement to the definitive RT-PCR test. We present a deep\nlearning ensemble for detecting COVID-19 infection, combining slice-based (2D)\nand volume-based (3D) approaches. The 2D system detects the infection on each\nCT slice independently, combining them to obtain the patient-level decision via\ndifferent methods (averaging and long-short term memory networks). The 3D\nsystem takes the whole CT volume to arrive to the",
          "link": "http://arxiv.org/abs/2105.08506",
          "publishedOn": "2021-05-22T03:02:50.556Z",
          "wordCount": 693,
          "title": "COVID-19 Detection in Computed Tomography Images with 2D and 3D Approaches. (arXiv:2105.08506v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1\">Masaya Ueda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kimura_A/0/1/0/all/0/1\">Akisato Kimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1\">Seiichi Uchida</a>",
          "description": "Various fonts give different impressions, such as legible, rough, and\ncomic-text.This paper aims to analyze the correlation between the local shapes,\nor parts, and the impression of fonts. By focusing on local shapes instead of\nthe whole letter shape, we can realize letter-shape independent and more\ngeneral analysis. The analysis is performed by newly combining SIFT and\nDeepSets, to extract an arbitrary number of essential parts from a particular\nfont and aggregate them to infer the font impressions by nonl",
          "link": "http://arxiv.org/abs/2103.14216",
          "publishedOn": "2021-05-22T03:02:50.545Z",
          "wordCount": 569,
          "title": "Which Parts determine the Impression of the Font?. (arXiv:2103.14216v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.04838",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pahwa_R/0/1/0/all/0/1\">Ramanpreet S Pahwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_S/0/1/0/all/0/1\">Soon Wee Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1\">Ren Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_R/0/1/0/all/0/1\">Richard Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_O/0/1/0/all/0/1\">Oo Zaw Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jie_W/0/1/0/all/0/1\">Wang Jie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_V/0/1/0/all/0/1\">Vempati Srinivasa Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nwe_T/0/1/0/all/0/1\">Tin Lay Nwe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yanjing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_J/0/1/0/all/0/1\">Jens Timo Neumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pichumani_R/0/1/0/all/0/1\">Ramani Pichumani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gregorich_T/0/1/0/all/0/1\">Thomas Gregorich</a>",
          "description": "For over 40 years lithographic silicon scaling has driven circuit integration\nand performance improvement in the semiconductor industry. As silicon scaling\nslows down, the industry is increasingly dependent on IC package technologies\nto contribute to further circuit integration and performance improvements. This\nis a paradigm shift and requires the IC package industry to reduce the size and\nincrease the density of internal interconnects on a scale which has never been\ndone before. Traditional package charac",
          "link": "http://arxiv.org/abs/2103.04838",
          "publishedOn": "2021-05-22T03:02:50.503Z",
          "wordCount": 754,
          "title": "Machine-learning based methodologies for 3d x-ray measurement, characterization and optimization for buried structures in advanced ic packages. (arXiv:2103.04838v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09422",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giunchiglia_F/0/1/0/all/0/1\">Fausto Giunchiglia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagchi_M/0/1/0/all/0/1\">Mayukh Bagchi</a>",
          "description": "We assume that substances in the world are represented by two types of\nconcepts, namely substance concepts and classification concepts, the former\ninstrumental to (visual) perception, the latter to (language based)\nclassification. Based on this distinction, we introduce a general methodology\nfor building lexico-semantic hierarchies of substance concepts, where nodes are\nannotated with the media, e.g.,videos or photos, from which substance concepts\nare extracted, and are associated with the corresponding cla",
          "link": "http://arxiv.org/abs/2105.09422",
          "publishedOn": "2021-05-22T03:02:50.463Z",
          "wordCount": 567,
          "title": "Classifying concepts via visual properties. (arXiv:2105.09422v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.08147",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ramesh_V/0/1/0/all/0/1\">Vignav Ramesh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rister_B/0/1/0/all/0/1\">Blaine Rister</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Chest X-rays of coronavirus disease 2019 (COVID-19) patients are frequently\nobtained to determine the extent of lung disease and are a valuable source of\ndata for creating artificial intelligence models. Most work to date assessing\ndisease severity on chest imaging has focused on segmenting computed tomography\n(CT) images; however, given that CTs are performed much less frequently than\nchest X-rays for COVID-19 patients, automated lung lesion segmentation on chest\nX-rays could be clinically valuable. There ",
          "link": "http://arxiv.org/abs/2105.08147",
          "publishedOn": "2021-05-22T03:02:50.451Z",
          "wordCount": 779,
          "title": "COVID-19 Lung Lesion Segmentation Using a Sparsely Supervised Mask R-CNN on Chest X-rays Automatically Computed from Volumetric CTs. (arXiv:2105.08147v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.13693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pares_F/0/1/0/all/0/1\">Ferran Par&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arias_Duart_A/0/1/0/all/0/1\">Anna Arias-Duart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Gasulla_D/0/1/0/all/0/1\">Dario Garcia-Gasulla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campo_Frances_G/0/1/0/all/0/1\">Gema Campo-Franc&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viladrich_N/0/1/0/all/0/1\">Nina Viladrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayguade_E/0/1/0/all/0/1\">Eduard Ayguad&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labarta_J/0/1/0/all/0/1\">Jes&#xfa;s Labarta</a>",
          "description": "In the image classification task, the most common approach is to resize all\nimages in a dataset to a unique shape, while reducing their precision to a size\nwhich facilitates experimentation at scale. This practice has benefits from a\ncomputational perspective, but it entails negative side-effects on performance\ndue to loss of information and image deformation. In this work we introduce the\nMAMe dataset, an image classification dataset with remarkable high resolution\nand variable shape properties. The goal o",
          "link": "http://arxiv.org/abs/2007.13693",
          "publishedOn": "2021-05-22T03:02:50.435Z",
          "wordCount": 725,
          "title": "The MAMe Dataset: On the relevance of High Resolution and Variable Shape image properties. (arXiv:2007.13693v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.17123",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Trung-Nghia Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yubo Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tan-Cong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_M/0/1/0/all/0/1\">Minh-Quan Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Khanh-Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_T/0/1/0/all/0/1\">Thanh-Toan Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1\">Minh-Triet Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tam V. Nguyen</a>",
          "description": "This paper pushes the envelope on camouflaged regions to decompose them into\nmeaningful components, namely, camouflaged instances. To promote the new task\nof camouflaged instance segmentation in-the-wild, we introduce a new dataset,\nnamely CAMO++, by extending our preliminary CAMO dataset (camouflaged object\nsegmentation) in terms of quantity and diversity. The new dataset substantially\nincreases the number of images with hierarchical pixel-wise ground-truths. We\nalso provide a benchmark suite for the task ",
          "link": "http://arxiv.org/abs/2103.17123",
          "publishedOn": "2021-05-22T03:02:50.417Z",
          "wordCount": 611,
          "title": "Camouflaged Instance Segmentation In-The-Wild: Dataset And Benchmark Suite. (arXiv:2103.17123v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhaofei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1\">Wei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Tiejun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonghong Tian</a>",
          "description": "Spiking Neural Networks (SNNs) have been attached great importance due to\ntheir biological plausibility and high energy-efficiency on neuromorphic chips.\nAs these chips are usually resource-constrained, the compression of SNNs is\nthus crucial along the road of practical use of SNNs. Most existing methods\ndirectly apply pruning approaches in artificial neural networks (ANNs) to SNNs,\nwhich ignore the difference between ANNs and SNNs, thus limiting the\nperformance of the pruned SNNs. Besides, these methods ar",
          "link": "http://arxiv.org/abs/2105.04916",
          "publishedOn": "2021-05-22T03:02:50.329Z",
          "wordCount": 696,
          "title": "Pruning of Deep Spiking Neural Networks through Gradient Rewiring. (arXiv:2105.04916v2 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.14066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Min Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_B/0/1/0/all/0/1\">Bo Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zihao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Junxing Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1\">Degang Sun</a>",
          "description": "Object detection can be regarded as a pixel clustering task, and its boundary\nis determined by four extreme points (leftmost, top, rightmost, and bottom).\nHowever, most studies focus on the center or corner points of the object, which\nare actually conditional results of the extreme points. In this paper, we\npresent an Extreme-Point-Prediction-Based object detector (EPP-Net), which\ndirectly regresses the relative displacement vector between each pixel and the\nfour extreme points. We also propose a new metric",
          "link": "http://arxiv.org/abs/2104.14066",
          "publishedOn": "2021-05-22T03:02:50.312Z",
          "wordCount": 613,
          "title": "Objects as Extreme Points. (arXiv:2104.14066v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.10270",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bouhsain_S/0/1/0/all/0/1\">Smail Ait Bouhsain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saadatnejad_S/0/1/0/all/0/1\">Saeed Saadatnejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alahi_A/0/1/0/all/0/1\">Alexandre Alahi</a>",
          "description": "In order to be globally deployed, autonomous cars must guarantee the safety\nof pedestrians. This is the reason why forecasting pedestrians' intentions\nsufficiently in advance is one of the most critical and challenging tasks for\nautonomous vehicles. This work tries to solve this problem by jointly\npredicting the intention and visual states of pedestrians. In terms of visual\nstates, whereas previous work focused on x-y coordinates, we will also predict\nthe size and indeed the whole bounding box of the pedest",
          "link": "http://arxiv.org/abs/2010.10270",
          "publishedOn": "2021-05-22T03:02:50.307Z",
          "wordCount": 647,
          "title": "Pedestrian Intention Prediction: A Multi-task Perspective. (arXiv:2010.10270v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08825",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bie_X/0/1/0/all/0/1\">Xiaoyu Bie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alameda_Pineda_X/0/1/0/all/0/1\">Xavier Alameda-Pineda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreno_Noguer_F/0/1/0/all/0/1\">Francesc Moreno-Noguer</a>",
          "description": "Human motion prediction aims to forecast future human poses given a sequence\nof past 3D skeletons. While this problem has recently received increasing\nattention, it has mostly been tackled for single humans in isolation. In this\npaper we explore this problem from a novel perspective, involving humans\nperforming collaborative tasks. We assume that the input of our system are two\nsequences of past skeletons for two interacting persons, and we aim to predict\nthe future motion for each of them. For this purpose",
          "link": "http://arxiv.org/abs/2105.08825",
          "publishedOn": "2021-05-22T03:02:50.290Z",
          "wordCount": 661,
          "title": "Multi-Person Extreme Motion Prediction with Cross-Interaction Attention. (arXiv:2105.08825v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1\">Bj&#xf6;rn L&#xfc;tjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leshchinskiy_B/0/1/0/all/0/1\">Brandon Leshchinskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Requena_Mesa_C/0/1/0/all/0/1\">Christian Requena-Mesa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chishtie_F/0/1/0/all/0/1\">Farrukh Chishtie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_Rodriguez_N/0/1/0/all/0/1\">Natalia D&#xed;az-Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boulais_O/0/1/0/all/0/1\">Oc&#xe9;ane Boulais</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankaranarayanan_A/0/1/0/all/0/1\">Aruna Sankaranarayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pina_A/0/1/0/all/0/1\">Aaron Pi&#xf1;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raissi_C/0/1/0/all/0/1\">Chedy Ra&#xef;ssi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavin_A/0/1/0/all/0/1\">Alexander Lavin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newman_D/0/1/0/all/0/1\">Dava Newman</a>",
          "description": "As climate change increases the intensity of natural disasters, society needs\nbetter tools for adaptation. Floods, for example, are the most frequent natural\ndisaster, and better tools for flood risk communication could increase the\nsupport for flood-resilient infrastructure development. Our work aims to enable\nmore visual communication of large-scale climate impacts via visualizing the\noutput of coastal flood models as satellite imagery. We propose the first deep\nlearning pipeline to ensure physical-consis",
          "link": "http://arxiv.org/abs/2104.04785",
          "publishedOn": "2021-05-22T03:02:50.255Z",
          "wordCount": 685,
          "title": "Physically-Consistent Generative Adversarial Networks for Coastal Flood Visualization. (arXiv:2104.04785v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1\">Xinya Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kaisiyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wayne Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1\">Chen Change Loy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xun Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Feng Xu</a>",
          "description": "Despite previous success in generating audio-driven talking heads, most of\nthe previous studies focus on the correlation between speech content and the\nmouth shape. Facial emotion, which is one of the most important features on\nnatural human faces, is always neglected in their methods. In this work, we\npresent Emotional Video Portraits (EVP), a system for synthesizing high-quality\nvideo portraits with vivid emotional dynamics driven by audios. Specifically,\nwe propose the Cross-Reconstructed Emotion Disenta",
          "link": "http://arxiv.org/abs/2104.07452",
          "publishedOn": "2021-05-22T03:02:50.246Z",
          "wordCount": 612,
          "title": "Audio-Driven Emotional Video Portraits. (arXiv:2104.07452v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03857",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dou_Y/0/1/0/all/0/1\">YiMin Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kewen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jianbing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Y/0/1/0/all/0/1\">Yingjie Xi</a>",
          "description": "Detection faults in seismic data is a crucial step for seismic structural\ninterpretation, reservoir characterization and well placement. Some recent\nworks regard it as an image segmentation task. The task of image segmentation\nrequires huge labels, especially 3D seismic data, which has a complex structure\nand lots of noise. Therefore, its annotation requires expert experience and a\nhuge workload. In this study, we present {\\lambda}-BCE and {\\lambda}-smooth\nL1loss to effectively train 3D-CNN by some slices f",
          "link": "http://arxiv.org/abs/2105.03857",
          "publishedOn": "2021-05-22T03:02:50.225Z",
          "wordCount": 724,
          "title": "Seismic Fault Segmentation via 3D-CNN Training by a Few 2D Slices Labels. (arXiv:2105.03857v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yuqing Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1\">Olivia Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1\">Deepak Pathak</a>",
          "description": "Policies trained in simulation often fail when transferred to the real world\ndue to the `reality gap' where the simulator is unable to accurately capture\nthe dynamics and visual properties of the real world. Current approaches to\ntackle this problem, such as domain randomization, require prior knowledge and\nengineering to determine how much to randomize system parameters in order to\nlearn a policy that is robust to sim-to-real transfer while also not being too\nconservative. We propose a method for automatic",
          "link": "http://arxiv.org/abs/2104.07662",
          "publishedOn": "2021-05-22T03:02:50.151Z",
          "wordCount": 681,
          "title": "Auto-Tuned Sim-to-Real Transfer. (arXiv:2104.07662v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arnavaz_K/0/1/0/all/0/1\">Kasra Arnavaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_O/0/1/0/all/0/1\">Oswin Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krivokapic_J/0/1/0/all/0/1\">Jelena M. Krivokapic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heilmann_S/0/1/0/all/0/1\">Silja Heilmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baerentzen_J/0/1/0/all/0/1\">Jakob Andreas B&#xe6;rentzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nyeng_P/0/1/0/all/0/1\">Pia Nyeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feragen_A/0/1/0/all/0/1\">Aasa Feragen</a>",
          "description": "Motivated by a challenging tubular network segmentation task, this paper\ntackles two commonly encountered problems in biomedical imaging: Topological\nconsistency of the segmentation, and limited annotations. We propose a\ntopological score which measures both topological and geometric consistency\nbetween the predicted and ground truth segmentations, applied for model\nselection and validation. We apply our topological score in three scenarios: i.\na U-net ii. a U-net pretrained on an autoencoder, and iii. a se",
          "link": "http://arxiv.org/abs/2105.09737",
          "publishedOn": "2021-05-22T03:02:50.032Z",
          "wordCount": 590,
          "title": "Semi-supervised, Topology-Aware Segmentation of Tubular Structures from Live Imaging 3D Microscopy. (arXiv:2105.09737v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08413",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1\">Ruimin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiayi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">He Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Baofeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jie Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuting Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chunlei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuyao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1\">Jie Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Hongjiang Wei</a>",
          "description": "Quantitative susceptibility mapping (QSM) has demonstrated great potential in\nquantifying tissue susceptibility in various brain diseases. However, the\nintrinsic ill-posed inverse problem relating the tissue phase to the underlying\nsusceptibility distribution affects the accuracy for quantifying tissue\nsusceptibility. Recently, deep learning has shown promising results to improve\naccuracy by reducing the streaking artifacts. However, there exists a mismatch\nbetween the observed phase and the theoretical for",
          "link": "http://arxiv.org/abs/2101.08413",
          "publishedOn": "2021-05-22T03:02:50.014Z",
          "wordCount": 660,
          "title": "MoDL-QSM: Model-based Deep Learning for Quantitative Susceptibility Mapping. (arXiv:2101.08413v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wangyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Abraham Noah Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biljecki_F/0/1/0/all/0/1\">Filip Biljecki</a>",
          "description": "There is a prevailing trend to study urban morphology quantitatively thanks\nto the growing accessibility to various forms of spatial big data, increasing\ncomputing power, and use cases benefiting from such information. The methods\ndeveloped up to now measure urban morphology with numerical indices describing\ndensity, proportion, and mixture, but they do not directly represent\nmorphological features from human's visual and intuitive perspective. We take\nthe first step to bridge the gap by proposing a deep le",
          "link": "http://arxiv.org/abs/2105.09908",
          "publishedOn": "2021-05-22T03:02:50.007Z",
          "wordCount": 703,
          "title": "Classification of Urban Morphology with Deep Learning: Application on Urban Vitality. (arXiv:2105.09908v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.13482",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zheng_K/0/1/0/all/0/1\">Kang Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yirui Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1\">Xiaoyun Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_F/0/1/0/all/0/1\">Fakai Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1\">Le Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_C/0/1/0/all/0/1\">Chihung Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_L/0/1/0/all/0/1\">Lingyun Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xie_G/0/1/0/all/0/1\">Guotong Xie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xiao_J/0/1/0/all/0/1\">Jing Xiao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kuo_C/0/1/0/all/0/1\">Chang-Fu Kuo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Miao_S/0/1/0/all/0/1\">Shun Miao</a>",
          "description": "Bone mineral density (BMD) is a clinically critical indicator of\nosteoporosis, usually measured by dual-energy X-ray absorptiometry (DEXA). Due\nto the limited accessibility of DEXA machines and examinations, osteoporosis is\noften under-diagnosed and under-treated, leading to increased fragility\nfracture risks. Thus it is highly desirable to obtain BMDs with alternative\ncost-effective and more accessible medical imaging examinations such as X-ray\nplain films. In this work, we formulate the BMD estimation fro",
          "link": "http://arxiv.org/abs/2103.13482",
          "publishedOn": "2021-05-22T03:02:50.001Z",
          "wordCount": 649,
          "title": "Semi-Supervised Learning for Bone Mineral Density Estimation in Hip X-ray Images. (arXiv:2103.13482v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.04096",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Speth_J/0/1/0/all/0/1\">Jeremy Speth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vance_N/0/1/0/all/0/1\">Nathan Vance</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flynn_P/0/1/0/all/0/1\">Patrick Flynn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowyer_K/0/1/0/all/0/1\">Kevin Bowyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Czajka_A/0/1/0/all/0/1\">Adam Czajka</a>",
          "description": "Remote photoplethysmography (rPPG), a family of techniques for monitoring\nblood volume changes, may be especially useful for widespread contactless\nhealth monitoring using face video from consumer-grade visible-light cameras.\nThe COVID-19 pandemic has caused the widespread use of protective face masks.\nWe found that occlusions from cloth face masks increased the mean absolute\nerror of heart rate estimation by more than 80\\% when deploying methods\ndesigned on unmasked faces. We show that augmenting unmasked ",
          "link": "http://arxiv.org/abs/2101.04096",
          "publishedOn": "2021-05-22T03:02:49.985Z",
          "wordCount": 714,
          "title": "Remote Pulse Estimation in the Presence of Face Masks. (arXiv:2101.04096v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10762",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Murphy_R/0/1/0/all/0/1\">Robert A. Murphy</a>",
          "description": "We show how to use random field theory in a supervised, energy-based model\nfor multiple pseudo image classification of 2D integer matrices. In the model,\neach row of a 2D integer matrix is a pseudo image where a local receptive field\nfocuses on multiple portions of individual rows for simultaneous learning. The\nmodel is used for a classification task consisting of presence of patient\nbiomarkers indicative of a particular disease.",
          "link": "http://arxiv.org/abs/2104.10762",
          "publishedOn": "2021-05-22T03:02:49.979Z",
          "wordCount": 540,
          "title": "Multiple Simultaneous Pseudo Image Classification with Random Fields and a Deep Belief Network for Disease Indication. (arXiv:2104.10762v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09939",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Brown_A/0/1/0/all/0/1\">Andrew Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalogeiton_V/0/1/0/all/0/1\">Vicky Kalogeiton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1\">Andrew Zisserman</a>",
          "description": "The objective of this work is person-clustering in videos -- grouping\ncharacters according to their identity. Previous methods focus on the narrower\ntask of face-clustering, and for the most part ignore other cues such as the\nperson's voice, their overall appearance (hair, clothes, posture), and the\nediting structure of the videos. Similarly, most current datasets evaluate only\nthe task of face-clustering, rather than person-clustering. This limits their\napplicability to downstream applications such as stor",
          "link": "http://arxiv.org/abs/2105.09939",
          "publishedOn": "2021-05-22T03:02:49.972Z",
          "wordCount": 633,
          "title": "Face, Body, Voice: Video Person-Clustering with Multiple Modalities. (arXiv:2105.09939v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.01165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Demir_I/0/1/0/all/0/1\">Ilke Demir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciftci_U/0/1/0/all/0/1\">Umur A. Ciftci</a>",
          "description": "Following the recent initiatives for the democratization of AI, deep fake\ngenerators have become increasingly popular and accessible, causing dystopian\nscenarios towards social erosion of trust. A particular domain, such as\nbiological signals, attracted attention towards detection methods that are\ncapable of exploiting authenticity signatures in real videos that are not yet\nfaked by generative approaches. In this paper, we first propose several\nprominent eye and gaze features that deep fakes exhibit differe",
          "link": "http://arxiv.org/abs/2101.01165",
          "publishedOn": "2021-05-22T03:02:49.966Z",
          "wordCount": 660,
          "title": "Where Do Deep Fakes Look? Synthetic Face Detection via Gaze Tracking. (arXiv:2101.01165v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00641",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dubey_S/0/1/0/all/0/1\">Shiv Ram Dubey</a>",
          "description": "The content based image retrieval aims to find the similar images from a\nlarge scale dataset against a query image. Generally, the similarity between\nthe representative features of the query image and dataset images is used to\nrank the images for retrieval. In early days, various hand designed feature\ndescriptors have been investigated based on the visual cues such as color,\ntexture, shape, etc. that represent the images. However, the deep learning has\nemerged as a dominating alternative of hand-designed fe",
          "link": "http://arxiv.org/abs/2012.00641",
          "publishedOn": "2021-05-22T03:02:49.959Z",
          "wordCount": 678,
          "title": "A Decade Survey of Content Based Image Retrieval using Deep Learning. (arXiv:2012.00641v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Rundi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Changxi Zheng</a>",
          "description": "Deep generative models of 3D shapes have received a great deal of research\ninterest. Yet, almost all of them generate discrete shape representations, such\nas voxels, point clouds, and polygon meshes. We present the first 3D generative\nmodel for a drastically different shape representation -- describing a shape as\na sequence of computer-aided design (CAD) operations. Unlike meshes and point\nclouds, CAD models encode the user creation process of 3D shapes, widely used\nin numerous industrial and engineering de",
          "link": "http://arxiv.org/abs/2105.09492",
          "publishedOn": "2021-05-22T03:02:49.934Z",
          "wordCount": 608,
          "title": "DeepCAD: A Deep Generative Network for Computer-Aided Design Models. (arXiv:2105.09492v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Thai_B/0/1/0/all/0/1\">Binh Nguyen-Thai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1\">Vuong Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morgan_C/0/1/0/all/0/1\">Catherine Morgan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badawi_N/0/1/0/all/0/1\">Nadia Badawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Truyen Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1\">Svetha Venkatesh</a>",
          "description": "The absence or abnormality of fidgety movements of joints or limbs is\nstrongly indicative of cerebral palsy in infants. Developing computer-based\nmethods for assessing infant movements in videos is pivotal for improved\ncerebral palsy screening. Most existing methods use appearance-based features\nand are thus sensitive to strong but irrelevant signals caused by background\nclutter or a moving camera. Moreover, these features are computed over the\nwhole frame, thus they measure gross whole body movements rathe",
          "link": "http://arxiv.org/abs/2105.09783",
          "publishedOn": "2021-05-22T03:02:49.928Z",
          "wordCount": 657,
          "title": "A Spatio-temporal Attention-based Model for Infant Movement Assessment from Videos. (arXiv:2105.09783v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09937",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Agu_N/0/1/0/all/0/1\">Nkechinyere N. Agu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Joy T. Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_H/0/1/0/all/0/1\">Hanqing Chao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lourentzou_I/0/1/0/all/0/1\">Ismini Lourentzou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Arjun Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moradi_M/0/1/0/all/0/1\">Mehdi Moradi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1\">Pingkun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hendler_J/0/1/0/all/0/1\">James Hendler</a>",
          "description": "Radiologists usually observe anatomical regions of chest X-ray images as well\nas the overall image before making a decision. However, most existing deep\nlearning models only look at the entire X-ray image for classification, failing\nto utilize important anatomical information. In this paper, we propose a novel\nmulti-label chest X-ray classification model that accurately classifies the\nimage finding and also localizes the findings to their correct anatomical\nregions. Specifically, our model consists of two m",
          "link": "http://arxiv.org/abs/2105.09937",
          "publishedOn": "2021-05-22T03:02:49.922Z",
          "wordCount": 619,
          "title": "AnaXNet: Anatomy Aware Multi-label Finding Classification in Chest X-ray. (arXiv:2105.09937v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09936",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Clever_H/0/1/0/all/0/1\">Henry M. Clever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grady_P/0/1/0/all/0/1\">Patrick Grady</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turk_G/0/1/0/all/0/1\">Greg Turk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kemp_C/0/1/0/all/0/1\">Charles C. Kemp</a>",
          "description": "Contact pressure between the human body and its surroundings has important\nimplications. For example, it plays a role in comfort, safety, posture, and\nhealth. We present a method that infers contact pressure between a human body\nand a mattress from a depth image. Specifically, we focus on using a depth\nimage from a downward facing camera to infer pressure on a body at rest in bed\noccluded by bedding, which is directly applicable to the prevention of pressure\ninjuries in healthcare. Our approach involves aug",
          "link": "http://arxiv.org/abs/2105.09936",
          "publishedOn": "2021-05-22T03:02:49.915Z",
          "wordCount": 633,
          "title": "BodyPressure -- Inferring Body Pose and Contact Pressure from a Depth Image. (arXiv:2105.09936v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09906",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Aditya Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Girishekar_E/0/1/0/all/0/1\">Eshwar Shamanna Girishekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_P/0/1/0/all/0/1\">Padmakar Anil Deshpande</a>",
          "description": "Automated image captioning is one of the applications of Deep Learning which\ninvolves fusion of work done in computer vision and natural language\nprocessing, and it is typically performed using Encoder-Decoder architectures.\nIn this project, we have implemented and experimented with various flavors of\nmulti-modal image captioning networks where ResNet101, DenseNet121 and VGG19\nbased CNN Encoders and Attention based LSTM Decoders were explored. We have\nstudied the effect of beam size and the use of pretraine",
          "link": "http://arxiv.org/abs/2105.09906",
          "publishedOn": "2021-05-22T03:02:49.891Z",
          "wordCount": 582,
          "title": "Empirical Analysis of Image Caption Generation using Deep Learning. (arXiv:2105.09906v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09907",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tu_X/0/1/0/all/0/1\">Xiaoguang Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qiankun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ai_W/0/1/0/all/0/1\">Wenjie Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_G/0/1/0/all/0/1\">Guodong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiashi Feng</a>",
          "description": "In real-world scenarios, many factors may harm face recognition performance,\ne.g., large pose, bad illumination,low resolution, blur and noise. To address\nthese challenges, previous efforts usually first restore the low-quality faces\nto high-quality ones and then perform face recognition. However, most of these\nmethods are stage-wise, which is sub-optimal and deviates from the reality. In\nthis paper, we address all these challenges jointly for unconstrained face\nrecognition. We propose an Multi-Degradation ",
          "link": "http://arxiv.org/abs/2105.09907",
          "publishedOn": "2021-05-22T03:02:49.882Z",
          "wordCount": 647,
          "title": "Joint Face Image Restoration and Frontalization for Recognition. (arXiv:2105.09907v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09913",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Perera_S/0/1/0/all/0/1\">Shehan Perera</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adhikari_S/0/1/0/all/0/1\">Srikar Adhikari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yilmaz_A/0/1/0/all/0/1\">Alper Yilmaz</a>",
          "description": "The rapid and seemingly endless expansion of COVID-19 can be traced back to\nthe inefficiency and shortage of testing kits that offer accurate results in a\ntimely manner. An emerging popular technique, which adopts improvements made in\nmobile ultrasound technology, allows for healthcare professionals to conduct\nrapid screenings on a large scale. We present an image-based solution that aims\nat automating the testing process which allows for rapid mass testing to be\nconducted with or without a trained medical ",
          "link": "http://arxiv.org/abs/2105.09913",
          "publishedOn": "2021-05-22T03:02:49.864Z",
          "wordCount": 617,
          "title": "POCFormer: A Lightweight Transformer Architecture for Detection of COVID-19 Using Point of Care Ultrasound. (arXiv:2105.09913v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Ran Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mingkun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1\">Rujun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Bo Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Zhuoling Xiao</a>",
          "description": "The technology for Visual Odometry (VO) that estimates the position and\norientation of the moving object through analyzing the image sequences captured\nby on-board cameras, has been well investigated with the rising interest in\nautonomous driving. This paper studies monocular VO from the perspective of\nDeep Learning (DL). Unlike most current learning-based methods, our approach,\ncalled DeepAVO, is established on the intuition that features contribute\ndiscriminately to different motion patterns. Specifically",
          "link": "http://arxiv.org/abs/2105.09899",
          "publishedOn": "2021-05-22T03:02:49.755Z",
          "wordCount": 619,
          "title": "DeepAVO: Efficient Pose Refining with Feature Distilling for Deep Visual Odometry. (arXiv:2105.09899v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2001.02161",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tripathi_N/0/1/0/all/0/1\">Nivedita Tripathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yogamani_S/0/1/0/all/0/1\">Senthil Yogamani</a>",
          "description": "Automated Parking is becoming a standard feature in modern vehicles. Existing\nparking systems build a local map to be able to plan for maneuvering towards a\ndetected slot. Next generation parking systems have an use case where they\nbuild a persistent map of the environment where the car is frequently parked,\nsay for example, home parking or office parking. The pre-built map helps in\nre-localizing the vehicle better when its trying to park the next time. This is\nachieved by augmenting the parking system with",
          "link": "http://arxiv.org/abs/2001.02161",
          "publishedOn": "2021-05-22T03:02:49.750Z",
          "wordCount": 642,
          "title": "Trained Trajectory based Automated Parking System using Visual SLAM on Surround View Cameras. (arXiv:2001.02161v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.08797",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hayou_S/0/1/0/all/0/1\">Soufiane Hayou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ton_J/0/1/0/all/0/1\">Jean-Francois Ton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>",
          "description": "Overparameterized Neural Networks (NN) display state-of-the-art performance.\nHowever, there is a growing need for smaller, energy-efficient, neural networks\ntobe able to use machine learning applications on devices with limited\ncomputational resources. A popular approach consists of using pruning\ntechniques. While these techniques have traditionally focused on pruning\npre-trained NN (LeCun et al.,1990; Hassibi et al., 1993), recent work by Lee et\nal. (2018) has shown promising results when pruning at initia",
          "link": "http://arxiv.org/abs/2002.08797",
          "publishedOn": "2021-05-22T03:02:49.619Z",
          "wordCount": 619,
          "title": "Robust Pruning at Initialization. (arXiv:2002.08797v5 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09396",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yufu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolotouros_N/0/1/0/all/0/1\">Nikos Kolotouros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daniilidis_K/0/1/0/all/0/1\">Kostas Daniilidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badger_M/0/1/0/all/0/1\">Marc Badger</a>",
          "description": "Animals are diverse in shape, but building a deformable shape model for a new\nspecies is not always possible due to the lack of 3D data. We present a method\nto capture new species using an articulated template and images of that\nspecies. In this work, we focus mainly on birds. Although birds represent\nalmost twice the number of species as mammals, no accurate shape model is\navailable. To capture a novel species, we first fit the articulated template to\neach training sample. By disentangling pose and shape, ",
          "link": "http://arxiv.org/abs/2105.09396",
          "publishedOn": "2021-05-22T03:02:49.604Z",
          "wordCount": 596,
          "title": "Birds of a Feather: Capturing Avian Shape Models from Images. (arXiv:2105.09396v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2003.01383",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siebert_J/0/1/0/all/0/1\">Jan Paul Siebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiangrong Xu</a>",
          "description": "This paper proposes a novel automatically generating image masks method for\nthe state-of-the-art Mask R-CNN deep learning method. The Mask R-CNN method\nachieves the best results in object detection until now, however, it is very\ntime-consuming and laborious to get the object Masks for training, the proposed\nmethod is composed by a two-stage design, to automatically generating image\nmasks, the first stage implements a fully convolutional networks (FCN) based\nsegmentation network, the second stage network, a ",
          "link": "http://arxiv.org/abs/2003.01383",
          "publishedOn": "2021-05-22T03:02:49.598Z",
          "wordCount": 603,
          "title": "Fully Convolutional Networks for Automatically Generating Image Masks to Train Mask R-CNN. (arXiv:2003.01383v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madan_M/0/1/0/all/0/1\">Manav Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakob_P/0/1/0/all/0/1\">Peter Jakob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_Schirling_T/0/1/0/all/0/1\">Tobias Schmid-Schirling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1\">Abhinav Valada</a>",
          "description": "Multi-view classification is inspired by the behavior of humans, especially\nwhen fine-grained features or in our case rarely occurring anomalies are to be\ndetected. Current contributions point to the problem of how high-dimensional\ndata can be fused. In this work, we build upon the deep support vector data\ndescription algorithm and address multi-perspective anomaly detection using\nthree different fusion techniques i.e. early fusion, late fusion, and late\nfusion with multiple decoders. We employ different au",
          "link": "http://arxiv.org/abs/2105.09903",
          "publishedOn": "2021-05-22T03:02:49.593Z",
          "wordCount": 633,
          "title": "Multi-Perspective Anomaly Detection. (arXiv:2105.09903v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yanli Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1\">Brenden M. Lake</a>",
          "description": "Humans are highly efficient learners, with the ability to grasp the meaning\nof a new concept from just a few examples. Unlike popular computer vision\nsystems, humans can flexibly leverage the compositional structure of the visual\nworld, understanding new concepts as combinations of existing concepts. In the\ncurrent paper, we study how people learn different types of visual\ncompositions, using abstract visual forms with rich relational structure. We\nfind that people can make meaningful compositional generali",
          "link": "http://arxiv.org/abs/2105.09848",
          "publishedOn": "2021-05-22T03:02:49.586Z",
          "wordCount": 587,
          "title": "Flexible Compositional Learning of Structured Visual Concepts. (arXiv:2105.09848v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09491",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhibo Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yuchen Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zeming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jian Sun</a>",
          "description": "Recently few-shot object detection is widely adopted to deal with\ndata-limited situations. While most previous works merely focus on the\nperformance on few-shot categories, we claim that detecting all classes is\ncrucial as test samples may contain any instances in realistic applications,\nwhich requires the few-shot detector to learn new concepts without forgetting.\nThrough analysis on transfer learning based methods, some neglected but\nbeneficial properties are utilized to design a simple yet effective few-",
          "link": "http://arxiv.org/abs/2105.09491",
          "publishedOn": "2021-05-22T03:02:49.581Z",
          "wordCount": 583,
          "title": "Generalized Few-Shot Object Detection without Forgetting. (arXiv:2105.09491v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09451",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Trung-Nghia Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tam V. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Z/0/1/0/all/0/1\">Zhongliang Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1\">Minh-Triet Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugimoto_A/0/1/0/all/0/1\">Akihiro Sugimoto</a>",
          "description": "Camouflaged objects attempt to conceal their texture into the background and\ndiscriminating them from the background is hard even for human beings. The main\nobjective of this paper is to explore the camouflaged object segmentation\nproblem, namely, segmenting the camouflaged object(s) for a given image. This\nproblem has not been well studied in spite of a wide range of potential\napplications including the preservation of wild animals and the discovery of\nnew species, surveillance systems, search-and-rescue m",
          "link": "http://arxiv.org/abs/2105.09451",
          "publishedOn": "2021-05-22T03:02:49.574Z",
          "wordCount": 649,
          "title": "Anabranch Network for Camouflaged Object Segmentation. (arXiv:2105.09451v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Borkar_J/0/1/0/all/0/1\">Jaydeep Borkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "There has been a rise in the use of Machine Learning as a Service (MLaaS)\nVision APIs as they offer multiple services including pre-built models and\nalgorithms, which otherwise take a huge amount of resources if built from\nscratch. As these APIs get deployed for high-stakes applications, it's very\nimportant that they are robust to different manipulations. Recent works have\nonly focused on typical adversarial attacks when evaluating the robustness of\nvision APIs. We propose two new aspects of adversarial ima",
          "link": "http://arxiv.org/abs/2105.09685",
          "publishedOn": "2021-05-22T03:02:49.568Z",
          "wordCount": 694,
          "title": "Simple Transparent Adversarial Examples. (arXiv:2105.09685v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2005.13934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hug_R/0/1/0/all/0/1\">Ronny Hug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1\">Stefan Becker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hubner_W/0/1/0/all/0/1\">Wolfgang H&#xfc;bner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arens_M/0/1/0/all/0/1\">Michael Arens</a>",
          "description": "Methods to quantify the complexity of trajectory datasets are still a missing\npiece in benchmarking human trajectory prediction models. In order to gain a\nbetter understanding of the complexity of trajectory prediction tasks and\nfollowing the intuition, that more complex datasets contain more information,\nan approach for quantifying the amount of information contained in a dataset\nfrom a prototype-based dataset representation is proposed. The dataset\nrepresentation is obtained by first employing a non-trivi",
          "link": "http://arxiv.org/abs/2005.13934",
          "publishedOn": "2021-05-22T03:02:49.548Z",
          "wordCount": 600,
          "title": "Quantifying the Complexity of Standard Benchmarking Datasets for Long-Term Human Trajectory Prediction. (arXiv:2005.13934v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09544",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Miao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lingni Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somasundaram_K/0/1/0/all/0/1\">Kiran Somasundaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1\">Kristen Grauman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1\">James M. Rehg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chao Li</a>",
          "description": "Given a video captured from a first person perspective and recorded in a\nfamiliar environment, can we recognize what the person is doing and identify\nwhere the action occurs in the 3D space? We address this challenging problem of\njointly recognizing and localizing actions of a mobile user on a known 3D map\nfrom egocentric videos. To this end, we propose a novel deep probabilistic\nmodel. Our model takes the inputs of a Hierarchical Volumetric Representation\n(HVR) of the environment and an egocentric video, i",
          "link": "http://arxiv.org/abs/2105.09544",
          "publishedOn": "2021-05-22T03:02:49.541Z",
          "wordCount": 612,
          "title": "Egocentric Activity Recognition and Localization on a 3D Map. (arXiv:2105.09544v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09932",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhijian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Alexander Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Sibo Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karaman_S/0/1/0/all/0/1\">Sertac Karaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>",
          "description": "Deep learning has been used to demonstrate end-to-end neural network learning\nfor autonomous vehicle control from raw sensory input. While LiDAR sensors\nprovide reliably accurate information, existing end-to-end driving solutions\nare mainly based on cameras since processing 3D data requires a large memory\nfootprint and computation cost. On the other hand, increasing the robustness of\nthese systems is also critical; however, even estimating the model's\nuncertainty is very challenging due to the cost of sampl",
          "link": "http://arxiv.org/abs/2105.09932",
          "publishedOn": "2021-05-22T03:02:49.535Z",
          "wordCount": 618,
          "title": "Efficient and Robust LiDAR-Based End-to-End Navigation. (arXiv:2105.09932v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09548",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jia_D/0/1/0/all/0/1\">Dengqiang Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Shangqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qunlong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xinzhe Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1\">Xiahai Zhuang</a>",
          "description": "Registration networks have shown great application potentials in medical\nimage analysis. However, supervised training methods have a great demand for\nlarge and high-quality labeled datasets, which is time-consuming and sometimes\nimpractical due to data sharing issues. Unsupervised image registration\nalgorithms commonly employ intensity-based similarity measures as loss\nfunctions without any manual annotations. These methods estimate the\nparameterized transformations between pairs of moving and fixed images ",
          "link": "http://arxiv.org/abs/2105.09548",
          "publishedOn": "2021-05-22T03:02:49.518Z",
          "wordCount": 645,
          "title": "A low-rank representation for unsupervised registration of medical images. (arXiv:2105.09548v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09909",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Dipayan Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1\">Saumik Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_U/0/1/0/all/0/1\">Umapada Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chanda_S/0/1/0/all/0/1\">Sukalpa Chanda</a>",
          "description": "Reservoir Computing (RC) offers a viable option to deploy AI algorithms on\nlow-end embedded system platforms. Liquid State Machine (LSM) is a bio-inspired\nRC model that mimics the cortical microcircuits and uses spiking neural\nnetworks (SNN) that can be directly realized on neuromorphic hardware. In this\npaper, we present a novel Parallelized LSM (PLSM) architecture that\nincorporates spatio-temporal read-out layer and semantic constraints on model\noutput. To the best of our knowledge, such a formulation has",
          "link": "http://arxiv.org/abs/2105.09909",
          "publishedOn": "2021-05-22T03:02:49.513Z",
          "wordCount": 613,
          "title": "PLSM: A Parallelized Liquid State Machine for Unintentional Action Detection. (arXiv:2105.09909v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09684",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">Haoyue Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1\">Song Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_S/0/1/0/all/0/1\">S.-H. Gary Chan</a>",
          "description": "Labeled crowd scene images are expensive and scarce. To significantly reduce\nthe requirement of the labeled images, we propose ColorCount, a novel CNN-based\napproach by combining self-supervised transfer colorization learning and global\nprior classification to leverage the abundantly available unlabeled data. The\nself-supervised colorization branch learns the semantics and surface texture of\nthe image by using its color components as pseudo labels. The classification\nbranch extracts global group priors by l",
          "link": "http://arxiv.org/abs/2105.09684",
          "publishedOn": "2021-05-22T03:02:49.507Z",
          "wordCount": 570,
          "title": "Crowd Counting by Self-supervised Transfer Colorization Learning and Global Prior Classification. (arXiv:2105.09684v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09683",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Cheng_B/0/1/0/all/0/1\">Bo Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_R/0/1/0/all/0/1\">Ruhui Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_H/0/1/0/all/0/1\">Hang Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhu_L/0/1/0/all/0/1\">Laili Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xiang_W/0/1/0/all/0/1\">Wei Xiang</a>",
          "description": "Background and Objective: The new type of coronavirus is also called\nCOVID-19. It began to spread at the end of 2019 and has now spread across the\nworld. Until October 2020, It has infected around 37 million people and claimed\nabout 1 million lives. We propose a deep learning model that can help\nradiologists and clinicians use chest X-rays to diagnose COVID-19 cases and\nshow the diagnostic features of pneumonia. Methods: The approach in this study\nis: 1) we propose a data enhancement method to increase the ",
          "link": "http://arxiv.org/abs/2105.09683",
          "publishedOn": "2021-05-22T03:02:49.494Z",
          "wordCount": 807,
          "title": "DPN-SENet:A self-attention mechanism neural network for detection and diagnosis of COVID-19 from chest x-ray images. (arXiv:2105.09683v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09597",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxiao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jianbo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Long Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Rui Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1\">Larry Davis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1\">Dimitris N. Metaxas</a>",
          "description": "Attention mechanisms have been widely applied to cross-modal tasks such as\nimage captioning and information retrieval, and have achieved remarkable\nimprovements due to its capability to learn fine-grained relevance across\ndifferent modalities. However, existing attention models could be sub-optimal\nand lack preciseness because there is no direct supervision involved during\ntraining. In this work, we propose Contrastive Content Re-sourcing (CCR) and\nContrastive Content Swapping (CCS) constraints to address s",
          "link": "http://arxiv.org/abs/2105.09597",
          "publishedOn": "2021-05-22T03:02:49.478Z",
          "wordCount": 587,
          "title": "More Than Just Attention: Learning Cross-Modal Attentions with Contrastive Constraints. (arXiv:2105.09597v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09590",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1\">Shijie Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Tong Lin</a>",
          "description": "Recently, collaborative learning proposed by Song and Chai has achieved\nremarkable improvements in image classification tasks by simultaneously\ntraining multiple classifier heads. However, huge memory footprints required by\nsuch multi-head structures may hinder the training of large-capacity baseline\nmodels. The natural question is how to achieve collaborative learning within a\nsingle network without duplicating any modules. In this paper, we propose four\nways of collaborative learning among different parts",
          "link": "http://arxiv.org/abs/2105.09590",
          "publishedOn": "2021-05-22T03:02:49.472Z",
          "wordCount": 638,
          "title": "Intra-Model Collaborative Learning of Neural Networks. (arXiv:2105.09590v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karnan_H/0/1/0/all/0/1\">Haresh Karnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warnell_G/0/1/0/all/0/1\">Garrett Warnell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xuesu Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1\">Peter Stone</a>",
          "description": "While imitation learning for vision based autonomous mobile robot navigation\nhas recently received a great deal of attention in the research community,\nexisting approaches typically require state action demonstrations that were\ngathered using the deployment platform. However, what if one cannot easily\noutfit their platform to record these demonstration signals or worse yet the\ndemonstrator does not have access to the platform at all? Is imitation learning\nfor vision based autonomous navigation even possible",
          "link": "http://arxiv.org/abs/2105.09371",
          "publishedOn": "2021-05-22T03:02:49.397Z",
          "wordCount": 671,
          "title": "VOILA: Visual-Observation-Only Imitation Learning for Autonomous Navigation. (arXiv:2105.09371v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chhablani_G/0/1/0/all/0/1\">Gunjan Chhablani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abheesht Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_H/0/1/0/all/0/1\">Harshit Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dash_T/0/1/0/all/0/1\">Tirtharaj Dash</a>",
          "description": "Superpixels are higher-order perceptual groups of pixels in an image, often\ncarrying much more information than raw pixels. There is an inherent relational\nstructure to the relationship among different superpixels of an image. This\nrelational information can convey some form of domain information about the\nimage, e.g. relationship between superpixels representing two eyes in a cat\nimage. Our interest in this paper is to construct computer vision models,\nspecifically those based on Deep Neural Networks (DNNs",
          "link": "http://arxiv.org/abs/2105.09448",
          "publishedOn": "2021-05-22T03:02:49.389Z",
          "wordCount": 693,
          "title": "Superpixel-based Domain-Knowledge Infusion in Computer Vision. (arXiv:2105.09448v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09600",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Hu_Z/0/1/0/all/0/1\">Zhihao Hu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_G/0/1/0/all/0/1\">Guo Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_D/0/1/0/all/0/1\">Dong Xu</a>",
          "description": "Learning based video compression attracts increasing attention in the past\nfew years. The previous hybrid coding approaches rely on pixel space operations\nto reduce spatial and temporal redundancy, which may suffer from inaccurate\nmotion estimation or less effective motion compensation. In this work, we\npropose a feature-space video coding network (FVC) by performing all major\noperations (i.e., motion estimation, motion compression, motion compensation\nand residual compression) in the feature space. Specifi",
          "link": "http://arxiv.org/abs/2105.09600",
          "publishedOn": "2021-05-22T03:02:49.296Z",
          "wordCount": 635,
          "title": "FVC: A New Framework towards Deep Video Compression in Feature Space. (arXiv:2105.09600v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09645",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yukai Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Jinghui Qin</a>",
          "description": "Deep convolutional networks have attracted great attention in image\nrestoration and enhancement. Generally, restoration quality has been improved\nby building more and more convolutional block. However, these methods mostly\nlearn a specific model to handle all images and ignore difficulty diversity. In\nother words, an area in the image with high frequency tend to lose more\ninformation during compressing while an area with low frequency tends to lose\nless. In this article, we adrress the efficiency issue in i",
          "link": "http://arxiv.org/abs/2105.09645",
          "publishedOn": "2021-05-22T03:02:49.199Z",
          "wordCount": 572,
          "title": "Content-adaptive Representation Learning for Fast Image Super-resolution. (arXiv:2105.09645v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09658",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kowalczyk_M/0/1/0/all/0/1\">Marcin Kowalczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kryjak_T/0/1/0/all/0/1\">Tomasz Kryjak</a>",
          "description": "This work describes the hardware implementation of a connected component\nlabelling (CCL) module in reprogammable logic. The main novelty of the design\nis the \"full\", i.e. without any simplifications, support of a 4 pixel per clock\nformat (4 ppc) and real-time processing of a 4K/UltraHD video stream (3840 x\n2160 pixels) at 60 frames per second. To achieve this, a special labelling\nmethod was designed and a functionality that stops the input data stream in\norder to process pixel groups which require writing m",
          "link": "http://arxiv.org/abs/2105.09658",
          "publishedOn": "2021-05-22T03:02:49.189Z",
          "wordCount": 559,
          "title": "A Connected Component Labelling algorithm for multi-pixel per clock cycle video strea. (arXiv:2105.09658v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09447",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1\">Heming Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Liang Zheng</a>",
          "description": "Object goal navigation aims to steer an agent towards a target object based\non observations of the agent. It is of pivotal importance to design effective\nvisual representations of the observed scene in determining navigation actions.\nIn this paper, we introduce a Visual Transformer Network (VTNet) for learning\ninformative visual representation in navigation. VTNet is a highly effective\nstructure that embodies two key properties for visual representations: First,\nthe relationships among all the object instan",
          "link": "http://arxiv.org/abs/2105.09447",
          "publishedOn": "2021-05-22T03:02:49.177Z",
          "wordCount": 642,
          "title": "VTNet: Visual Transformer Network for Object Goal Navigation. (arXiv:2105.09447v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09596",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Li Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_W/0/1/0/all/0/1\">Wei Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_R/0/1/0/all/0/1\">Ruhui Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_K/0/1/0/all/0/1\">Kaida Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Laili Zhu</a>",
          "description": "Recently, the anchor-free object detection model has shown great potential\nfor accuracy and speed to exceed anchor-based object detection. Therefore, two\nissues are mainly studied in this article: (1) How to let the backbone network\nin the anchor-free object detection model learn feature extraction? (2) How to\nmake better use of the feature pyramid network? In order to solve the above\nproblems, Experiments show that our model has a certain improvement in accuracy\ncompared with the current popular detection ",
          "link": "http://arxiv.org/abs/2105.09596",
          "publishedOn": "2021-05-22T03:02:49.170Z",
          "wordCount": 596,
          "title": "AGSFCOS: Based on attention mechanism and Scale-Equalizing pyramid network of object detection. (arXiv:2105.09596v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09511",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shaohua Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sui_X/0/1/0/all/0/1\">Xiuchao Sui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Luo_X/0/1/0/all/0/1\">Xiangde Luo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_X/0/1/0/all/0/1\">Xinxing Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goh_R/0/1/0/all/0/1\">Rick Siow Mong Goh</a>",
          "description": "Medical image segmentation is important for computer-aided diagnosis. Good\nsegmentation demands the model to see the big picture and fine details\nsimultaneously, i.e., to learn image features that incorporate large context\nwhile keep high spatial resolutions. To approach this goal, the most widely\nused methods -- U-Net and variants, extract and fuse multi-scale features.\nHowever, the fused features still have small \"effective receptive fields\" with\na focus on local image cues, limiting their performance. In",
          "link": "http://arxiv.org/abs/2105.09511",
          "publishedOn": "2021-05-22T03:02:49.153Z",
          "wordCount": 638,
          "title": "Medical Image Segmentation using Squeeze-and-Expansion Transformers. (arXiv:2105.09511v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09803",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kothari_R/0/1/0/all/0/1\">Rakshit Kothari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mello_S/0/1/0/all/0/1\">Shalini De Mello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_U/0/1/0/all/0/1\">Umar Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byeon_W/0/1/0/all/0/1\">Wonmin Byeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Seonwook Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1\">Jan Kautz</a>",
          "description": "A major challenge for physically unconstrained gaze estimation is acquiring\ntraining data with 3D gaze annotations for in-the-wild and outdoor scenarios.\nIn contrast, videos of human interactions in unconstrained environments are\nabundantly available and can be much more easily annotated with frame-level\nactivity labels. In this work, we tackle the previously unexplored problem of\nweakly-supervised gaze estimation from videos of human interactions. We\nleverage the insight that strong gaze-related geometric ",
          "link": "http://arxiv.org/abs/2105.09803",
          "publishedOn": "2021-05-22T03:02:49.145Z",
          "wordCount": 588,
          "title": "Weakly-Supervised Physically Unconstrained Gaze Estimation. (arXiv:2105.09803v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09624",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Grohl_J/0/1/0/all/0/1\">Janek Gr&#xf6;hl</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schellenberg_M/0/1/0/all/0/1\">Melanie Schellenberg</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dreher_K/0/1/0/all/0/1\">Kris Dreher</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Holzwarth_N/0/1/0/all/0/1\">Niklas Holzwarth</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tizabi_M/0/1/0/all/0/1\">Minu D. Tizabi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Seitel_A/0/1/0/all/0/1\">Alexander Seitel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maier_Hein_L/0/1/0/all/0/1\">Lena Maier-Hein</a>",
          "description": "Photoacoustic imaging has the potential to revolutionise healthcare due to\nthe valuable information on tissue physiology that is contained in\nmultispectral photoacoustic measurements. Clinical translation of the\ntechnology requires conversion of the high-dimensional acquired data into\nclinically relevant and interpretable information. In this work, we present a\ndeep learning-based approach to semantic segmentation of multispectral\nphotoacoustic images to facilitate the interpretability of recorded images.\nM",
          "link": "http://arxiv.org/abs/2105.09624",
          "publishedOn": "2021-05-22T03:02:49.136Z",
          "wordCount": 608,
          "title": "Semantic segmentation of multispectral photoacoustic images using deep learning. (arXiv:2105.09624v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09711",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1\">Pengxiang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jianqin Yin</a>",
          "description": "Joint relation modeling is a curial component in human motion prediction.\nMost existing methods tend to design skeletal-based graphs to build the\nrelations among joints, where local interactions between joint pairs are well\nlearned. However, the global coordination of all joints, which reflects human\nmotion's balance property, is usually weakened because it is learned from part\nto whole progressively and asynchronously. Thus, the final predicted motions\nare sometimes unnatural. To tackle this issue, we lear",
          "link": "http://arxiv.org/abs/2105.09711",
          "publishedOn": "2021-05-22T03:02:49.104Z",
          "wordCount": 642,
          "title": "An Attractor-Guided Neural Networks for Skeleton-Based Human Motion Prediction. (arXiv:2105.09711v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09847",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fonder_M/0/1/0/all/0/1\">Micha&#xeb;l Fonder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ernst_D/0/1/0/all/0/1\">Damien Ernst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Droogenbroeck_M/0/1/0/all/0/1\">Marc Van Droogenbroeck</a>",
          "description": "Getting the distance to objects is crucial for autonomous vehicles. In\ninstances where depth sensors cannot be used, this distance has to be estimated\nfrom RGB cameras. As opposed to cars, the task of estimating depth from\non-board mounted cameras is made complex on drones because of the lack of\nconstrains on motion during flights. %In the case of drones, this task is even\nmore complex than for car-mounted cameras since the camera motion is\nunconstrained. In this paper, we present a method to estimate the d",
          "link": "http://arxiv.org/abs/2105.09847",
          "publishedOn": "2021-05-22T03:02:49.096Z",
          "wordCount": 705,
          "title": "M4Depth: A motion-based approach for monocular depth estimation on video sequences. (arXiv:2105.09847v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09437",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gangeh_M/0/1/0/all/0/1\">Mehrdad J Gangeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plata_M/0/1/0/all/0/1\">Marcin Plata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Motahari_H/0/1/0/all/0/1\">Hamid Motahari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duffy_N/0/1/0/all/0/1\">Nigel P Duffy</a>",
          "description": "Removing noise from scanned pages is a vital step before their submission to\noptical character recognition (OCR) system. Most available image denoising\nmethods are supervised where the pairs of noisy/clean pages are required.\nHowever, this assumption is rarely met in real settings. Besides, there is no\nsingle model that can remove various noise types from documents. Here, we\npropose a unified end-to-end unsupervised deep learning model, for the first\ntime, that can effectively remove multiple types of noise",
          "link": "http://arxiv.org/abs/2105.09437",
          "publishedOn": "2021-05-22T03:02:49.078Z",
          "wordCount": 551,
          "title": "End-to-End Unsupervised Document Image Blind Denoising. (arXiv:2105.09437v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09374",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Halperin_T/0/1/0/all/0/1\">Tavi Halperin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakim_H/0/1/0/all/0/1\">Hanit Hakim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vantzos_O/0/1/0/all/0/1\">Orestis Vantzos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hochman_G/0/1/0/all/0/1\">Gershon Hochman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benaim_N/0/1/0/all/0/1\">Netai Benaim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sassy_L/0/1/0/all/0/1\">Lior Sassy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kupchik_M/0/1/0/all/0/1\">Michael Kupchik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bibi_O/0/1/0/all/0/1\">Ofir Bibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fried_O/0/1/0/all/0/1\">Ohad Fried</a>",
          "description": "We present an algorithm for producing a seamless animated loop from a single\nimage. The algorithm detects periodic structures, such as the windows of a\nbuilding or the steps of a staircase, and generates a non-trivial displacement\nvector field that maps each segment of the structure onto a neighboring segment\nalong a user- or auto-selected main direction of motion. This displacement\nfield is used, together with suitable temporal and spatial smoothing, to warp\nthe image and produce the frames of a continuous",
          "link": "http://arxiv.org/abs/2105.09374",
          "publishedOn": "2021-05-22T03:02:49.069Z",
          "wordCount": 608,
          "title": "Endless Loops: Detecting and Animating Periodic Patterns in Still Images. (arXiv:2105.09374v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_S/0/1/0/all/0/1\">Seyed Saeed Changiz Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1\">Fred X. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1\">Di Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salameh_M/0/1/0/all/0/1\">Mohammad Salameh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1\">Keith Mills</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_S/0/1/0/all/0/1\">Shuo Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jui_S/0/1/0/all/0/1\">Shangling Jui</a>",
          "description": "Despite the empirical success of neural architecture search (NAS) in deep\nlearning applications, the optimality, reproducibility and cost of NAS schemes\nremain hard to assess. In this paper, we propose Generative Adversarial NAS\n(GA-NAS) with theoretically provable convergence guarantees, promoting\nstability and reproducibility in neural architecture search. Inspired by\nimportance sampling, GA-NAS iteratively fits a generator to previously\ndiscovered top architectures, thus increasingly focusing on importan",
          "link": "http://arxiv.org/abs/2105.09356",
          "publishedOn": "2021-05-22T03:02:49.049Z",
          "wordCount": 621,
          "title": "Generative Adversarial Neural Architecture Search. (arXiv:2105.09356v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09405",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Barakat_B/0/1/0/all/0/1\">Berat Kurar Barakat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Droby_A/0/1/0/all/0/1\">Ahmad Droby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saabni_R/0/1/0/all/0/1\">Raid Saabni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Sana_J/0/1/0/all/0/1\">Jihad El-Sana</a>",
          "description": "Despite recent advances in the field of supervised deep learning for text\nline segmentation, unsupervised deep learning solutions are beginning to gain\npopularity. In this paper, we present an unsupervised deep learning method that\nembeds document image patches to a compact Euclidean space where distances\ncorrespond to a coarse text line pattern similarity. Once this space has been\nproduced, text line segmentation can be easily implemented using standard\ntechniques with the embedded feature vectors. To trai",
          "link": "http://arxiv.org/abs/2105.09405",
          "publishedOn": "2021-05-22T03:02:49.035Z",
          "wordCount": 596,
          "title": "Unsupervised learning of text line segmentationby differentiating coarse patterns. (arXiv:2105.09405v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lecheng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yada Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jingrui He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jinjun Xiong</a>",
          "description": "With the advent of big data across multiple high-impact applications, we are\noften facing the challenge of complex heterogeneity. The newly collected data\nusually consist of multiple modalities and characterized with multiple labels,\nthus exhibiting the co-existence of multiple types of heterogeneity. Although\nstate-of-the-art techniques are good at modeling the complex heterogeneity with\nsufficient label information, such label information can be quite expensive to\nobtain in real applications, leading to s",
          "link": "http://arxiv.org/abs/2105.09401",
          "publishedOn": "2021-05-22T03:02:49.016Z",
          "wordCount": 613,
          "title": "Heterogeneous Contrastive Learning. (arXiv:2105.09401v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09365",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Uysal_E/0/1/0/all/0/1\">Enes Sadi Uysal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bilici_M/0/1/0/all/0/1\">M.&#x15e;afak Bilici</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zaza_B/0/1/0/all/0/1\">B. Selin Zaza</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ozgenc_M/0/1/0/all/0/1\">M. Yi&#x11f;it &#xd6;zgen&#xe7;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boyar_O/0/1/0/all/0/1\">Onur Boyar</a>",
          "description": "Retinal Vessel Segmentation is important for diagnosis of various diseases.\nThe research on retinal vessel segmentation focuses mainly on improvement of\nthe segmentation model which is usually based on U-Net architecture. In our\nstudy we use the U-Net architecture and we rely on heavy data augmentation in\norder to achieve better performance. The success of the data augmentation\nrelies on successfully addressing the problem of input images. By analyzing\ninput images and performing the augmentation accordingl",
          "link": "http://arxiv.org/abs/2105.09365",
          "publishedOn": "2021-05-22T03:02:49.005Z",
          "wordCount": 564,
          "title": "Exploring The Limits Of Data Augmentation For Retinal Vessel Segmentation. (arXiv:2105.09365v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09378",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gadjimuradov_F/0/1/0/all/0/1\">Fasil Gadjimuradov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Benkert_T/0/1/0/all/0/1\">Thomas Benkert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Nickel_M/0/1/0/all/0/1\">Marcel Dominik Nickel</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>",
          "description": "Purpose: To develop an algorithm for robust partial Fourier (PF)\nreconstruction applicable to diffusion-weighted (DW) images with non-smooth\nphase variations.\n\nMethods: Based on an unrolled proximal splitting algorithm, a neural network\narchitecture is derived which alternates between data consistency operations\nand regularization implemented by recurrent convolutions. In order to exploit\ncorrelations, multiple repetitions of the same slice are jointly reconstructed\nunder consideration of permutation-equiva",
          "link": "http://arxiv.org/abs/2105.09378",
          "publishedOn": "2021-05-22T03:02:48.995Z",
          "wordCount": 705,
          "title": "Robust partial Fourier reconstruction for diffusion-weighted imaging using a recurrent convolutional neural network. (arXiv:2105.09378v1 [eess.IV])"
        }
      ]
    },
    {
      "title": "cs.LG updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.LG",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2010.14925",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jiancheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1\">Rui Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bingbing Ni</a>",
          "description": "We present MedMNIST, a collection of 10 pre-processed medical open datasets.\nMedMNIST is standardized to perform classification tasks on lightweight 28x28\nimages, which requires no background knowledge. Covering the primary data\nmodalities in medical image analysis, it is diverse on data scale (from 100 to\n100,000) and tasks (binary/multi-class, ordinal regression and multi-label).\nMedMNIST could be used for educational purpose, rapid prototyping, multi-modal\nmachine learning or AutoML in medical image analysis. Moreover, MedMNIST\nClassification Decathlon is designed to benchmark AutoML algorithms on all 10\ndatasets; We have compared several baseline methods, including open-source or\ncommercial AutoML tools. The datasets, evaluation code and baseline methods for\nMedMNIST are publicly available at https://medmnist.github.io/.",
          "link": "http://arxiv.org/abs/2010.14925",
          "publishedOn": "2021-05-24T07:23:08.820Z",
          "wordCount": 612,
          "title": "MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis. (arXiv:2010.14925v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10011",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berrada_L/0/1/0/all/0/1\">Leonard Berrada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1\">Andrew Zisserman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1\">M. Pawan Kumar</a>",
          "description": "This is a short note on the performance of the ALI-G algorithm (Berrada et\nal., 2020) as reported in (Loizou et al., 2021). ALI-G (Berrada et al., 2020)\nand SPS (Loizou et al., 2021) are both adaptations of the Polyak step-size to\noptimize machine learning models that can interpolate the training data. The\nmain algorithmic differences are that (1) SPS employs a multiplicative constant\nin the denominator of the learning-rate while ALI-G uses an additive constant,\nand (2) SPS uses an iteration-dependent maximal learning-rate while ALI-G uses\na constant one. There are also differences in the analysis provided by the two\nworks, with less restrictive assumptions proposed in (Loizou et al., 2021). In\ntheir experiments, (Loizou et al., 2021) did not use momentum for ALI-G (which\nis a standard part of the algorithm) or standard hyper-parameter tuning (for\ne.g. learning-rate and regularization). Hence this note as a reference for the\nimproved performance that ALI-G can obtain with well-chosen hyper-parameters.\nIn particular, we show that when training a ResNet-34 on CIFAR-10 and\nCIFAR-100, the performance of ALI-G can reach respectively 93.5% (+6%) and 76%\n(+8%) with a very small amount of tuning. Thus ALI-G remains a very competitive\nmethod for training interpolating neural networks.",
          "link": "http://arxiv.org/abs/2105.10011",
          "publishedOn": "2021-05-24T07:23:08.804Z",
          "wordCount": 627,
          "title": "Comment on Stochastic Polyak Step-Size: Performance of ALI-G. (arXiv:2105.10011v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ishtiaq_A/0/1/0/all/0/1\">Arhum Ishtiaq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_S/0/1/0/all/0/1\">Sara Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anees_M/0/1/0/all/0/1\">Maheen Anees</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mumtaz_N/0/1/0/all/0/1\">Neha Mumtaz</a>",
          "description": "With time, machine learning models have increased in their scope,\nfunctionality and size. Consequently, the increased functionality and size of\nsuch models requires high-end hardware to both train and provide inference\nafter the fact. This paper aims to explore the possibilities within the domain\nof model compression and discuss the efficiency of each of the possible\napproaches while comparing model size and performance with respect to pre- and\npost-compression.",
          "link": "http://arxiv.org/abs/2105.10059",
          "publishedOn": "2021-05-24T07:23:08.740Z",
          "wordCount": 480,
          "title": "Model Compression. (arXiv:2105.10059v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06784",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ronca_A/0/1/0/all/0/1\">Alessandro Ronca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giacomo_G/0/1/0/all/0/1\">Giuseppe De Giacomo</a>",
          "description": "Recently regular decision processes have been proposed as a well-behaved form\nof non-Markov decision process. Regular decision processes are characterised by\na transition function and a reward function that depend on the whole history,\nthough regularly (as in regular languages). In practice both the transition and\nthe reward functions can be seen as finite transducers. We study reinforcement\nlearning in regular decision processes. Our main contribution is to show that a\nnear-optimal policy can be PAC-learned in polynomial time in a set of\nparameters that describe the underlying decision process. We argue that the\nidentified set of parameters is minimal and it reasonably captures the\ndifficulty of a regular decision process.",
          "link": "http://arxiv.org/abs/2105.06784",
          "publishedOn": "2021-05-24T07:23:08.735Z",
          "wordCount": 563,
          "title": "Efficient PAC Reinforcement Learning in Regular Decision Processes. (arXiv:2105.06784v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10197",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Morik_K/0/1/0/all/0/1\">Katharina Morik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotthaus_H/0/1/0/all/0/1\">Helena Kotthaus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heppe_L/0/1/0/all/0/1\">Lukas Heppe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinrich_D/0/1/0/all/0/1\">Danny Heinrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_R/0/1/0/all/0/1\">Raphael Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mucke_S/0/1/0/all/0/1\">Sascha M&#xfc;cke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauly_A/0/1/0/all/0/1\">Andreas Pauly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakobs_M/0/1/0/all/0/1\">Matthias Jakobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piatkowski_N/0/1/0/all/0/1\">Nico Piatkowski</a>",
          "description": "Machine learning applications have become ubiquitous. Their applications from\nmachine embedded control in production over process optimization in diverse\nareas (e.g., traffic, finance, sciences) to direct user interactions like\nadvertising and recommendations. This has led to an increased effort of making\nmachine learning trustworthy. Explainable and fair AI have already matured.\nThey address knowledgeable users and application engineers. However, there are\nusers that want to deploy a learned model in a similar way as their washing\nmachine. These stakeholders do not want to spend time understanding the model.\nInstead, they want to rely on guaranteed properties. What are the relevant\nproperties? How can they be expressed to stakeholders without presupposing\nmachine learning knowledge? How can they be guaranteed for a certain\nimplementation of a model? These questions move far beyond the current\nstate-of-the-art and we want to address them here. We propose a unified\nframework that certifies learning methods via care labels. They are easy to\nunderstand and draw inspiration from well-known certificates like textile\nlabels or property cards of electronic devices. Our framework considers both,\nthe machine learning theory and a given implementation. We test the\nimplementation's compliance with theoretical properties and bounds. In this\npaper, we illustrate care labels by a prototype implementation of a\ncertification suite for a selection of probabilistic graphical models.",
          "link": "http://arxiv.org/abs/2105.10197",
          "publishedOn": "2021-05-24T07:23:08.724Z",
          "wordCount": 666,
          "title": "Yes We Care! -- Certification for Machine Learning Methods through the Care Label Framework. (arXiv:2105.10197v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.12099",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seyedi_S/0/1/0/all/0/1\">Salman Seyedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Li Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nemati_S/0/1/0/all/0/1\">Shamim Nemati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifford_G/0/1/0/all/0/1\">Gari D. Clifford</a>",
          "description": "The increasing complexity of algorithms for analyzing medical data, including\nde-identification tasks, raises the possibility that complex algorithms are\nlearning not just the general representation of the problem, but specifics of\ngiven individuals within the data. Modern legal frameworks specifically\nprohibit the intentional or accidental distribution of patient data, but have\nnot addressed this potential avenue for leakage of such protected health\ninformation. Modern deep learning algorithms have the highest potential of such\nleakage due to complexity of the models. Recent research in the field has\nhighlighted such issues in non-medical data, but all analysis is likely to be\ndata and algorithm specific. We, therefore, chose to analyze a state-of-the-art\nfree-text de-identification algorithm based on LSTM (Long Short-Term Memory)\nand its potential in encoding any individual in the training set. Using the\ni2b2 Challenge Data, we trained, then analyzed the model to assess whether the\noutput of the LSTM, before the compression layer of the classifier, could be\nused to estimate the membership of the training data. Furthermore, we used\ndifferent attacks including membership inference attack method to attack the\nmodel. Results indicate that the attacks could not identify whether members of\nthe training data were distinguishable from non-members based on the model\noutput. This indicates that the model does not provide any strong evidence into\nthe identification of the individuals in the training data set and there is not\nyet empirical evidence it is unsafe to distribute the model for general use.",
          "link": "http://arxiv.org/abs/2101.12099",
          "publishedOn": "2021-05-24T07:23:08.718Z",
          "wordCount": 716,
          "title": "An Analysis Of Protected Health Information Leakage In Deep-Learning Based De-Identification Algorithms. (arXiv:2101.12099v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Akoglu_L/0/1/0/all/0/1\">Leman Akoglu</a>",
          "description": "Anomaly mining is an important problem that finds numerous applications in\nvarious real world domains such as environmental monitoring, cybersecurity,\nfinance, healthcare and medicine, to name a few. In this article, I focus on\ntwo areas, (1) point-cloud and (2) graph-based anomaly mining. I aim to present\na broad view of each area, and discuss classes of main research problems,\nrecent trends and future directions. I conclude with key take-aways and\noverarching open problems.",
          "link": "http://arxiv.org/abs/2105.10077",
          "publishedOn": "2021-05-24T07:23:08.702Z",
          "wordCount": 499,
          "title": "Anomaly Mining -- Past, Present and Future. (arXiv:2105.10077v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10272",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karande_H/0/1/0/all/0/1\">Hema Karande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walambe_R/0/1/0/all/0/1\">Rahee Walambe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benjamin_V/0/1/0/all/0/1\">Victor Benjamin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotecha_K/0/1/0/all/0/1\">Ketan Kotecha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghu_T/0/1/0/all/0/1\">T. S. Raghu</a>",
          "description": "The evolution of electronic media is a mixed blessing. Due to the easy\naccess, low cost, and faster reach of the information, people search out and\ndevour news from online social networks. In contrast, the increasing acceptance\nof social media reporting leads to the spread of fake news. This is a minacious\nproblem that causes disputes and endangers societal stability and harmony. Fake\nnews spread has gained attention from researchers due to its vicious nature.\nproliferation of misinformation in all media, from the internet to cable news,\npaid advertising and local news outlets, has made it essential for people to\nidentify the misinformation and sort through the facts. Researchers are trying\nto analyze the credibility of information and curtail false information on such\nplatforms. Credibility is the believability of the piece of information at\nhand. Analyzing the credibility of fake news is challenging due to the intent\nof its creation and the polychromatic nature of the news. In this work, we\npropose a model for detecting fake news. Our method investigates the content of\nthe news at the early stage i.e. when the news is published but is yet to be\ndisseminated through social media. Our work interprets the content with\nautomatic feature extraction and the relevance of the text pieces. In summary,\nwe introduce stance as one of the features along with the content of the\narticle and employ the pre-trained contextualized word embeddings BERT to\nobtain the state-of-art results for fake news detection. The experiment\nconducted on the real-world dataset indicates that our model outperforms the\nprevious work and enables fake news detection with an accuracy of 95.32%.",
          "link": "http://arxiv.org/abs/2105.10272",
          "publishedOn": "2021-05-24T07:23:08.696Z",
          "wordCount": 711,
          "title": "Stance Detection with BERT Embeddings for Credibility Analysis of Information on Social Media. (arXiv:2105.10272v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10102",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">He Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harlim_J/0/1/0/all/0/1\">John Harlim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiantao Li</a>",
          "description": "This paper studies the theoretical underpinnings of machine learning of\nergodic It\\^o diffusions. The objective is to understand the convergence\nproperties of the invariant statistics when the underlying system of stochastic\ndifferential equations (SDEs) is empirically estimated with a supervised\nregression framework. Using the perturbation theory of ergodic Markov chains\nand the linear response theory, we deduce a linear dependence of the errors of\none-point and two-point invariant statistics on the error in the learning of\nthe drift and diffusion coefficients. More importantly, our study shows that\nthe usual $L^2$-norm characterization of the learning generalization error is\ninsufficient for achieving this linear dependence result. We find that\nsufficient conditions for such a linear dependence result are through learning\nalgorithms that produce a uniformly Lipschitz and consistent estimator in the\nhypothesis space that retains certain characteristics of the drift\ncoefficients, such as the usual linear growth condition that guarantees the\nexistence of solutions of the underlying SDEs. We examine these conditions on\ntwo well-understood learning algorithms: the kernel-based spectral regression\nmethod and the shallow random neural networks with the ReLU activation\nfunction.",
          "link": "http://arxiv.org/abs/2105.10102",
          "publishedOn": "2021-05-24T07:23:08.690Z",
          "wordCount": 633,
          "title": "Error Bounds of the Invariant Statistics in Machine Learning of Ergodic It\\^o Diffusions. (arXiv:2105.10102v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10005",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">C.-H. Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhabra_M/0/1/0/all/0/1\">Mohit Chhabra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Y.-C. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1\">Quan Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshinaga_T/0/1/0/all/0/1\">Tomoaki Yoshinaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murakam_T/0/1/0/all/0/1\">Tomokazu Murakam</a>",
          "description": "Camera movement and unpredictable environmental conditions like dust and wind\ninduce noise into video feeds. We observe that popular unsupervised MOT methods\nare dependent on noise-free conditions. We show that the addition of a small\namount of artificial random noise causes a sharp degradation in model\nperformance on benchmark metrics. We resolve this problem by introducing a\nrobust unsupervised multi-object tracking (MOT) model: AttU-Net. The proposed\nsingle-head attention model helps limit the negative impact of noise by\nlearning visual representations at different segment scales. AttU-Net shows\nbetter unsupervised MOT tracking performance over variational inference-based\nstate-of-the-art baselines. We evaluate our method in the MNIST and the Atari\ngame video benchmark. We also provide two extended video datasets consisting of\ncomplex visual patterns that include Kuzushiji characters and fashion images to\nvalidate the effectiveness of the proposed method.",
          "link": "http://arxiv.org/abs/2105.10005",
          "publishedOn": "2021-05-24T07:23:08.685Z",
          "wordCount": 592,
          "title": "Robust Unsupervised Multi-Object Tracking in Noisy Environments. (arXiv:2105.10005v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10373",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sifaou_H/0/1/0/all/0/1\">Houssem Sifaou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+kammoun_A/0/1/0/all/0/1\">Abla kammoun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alouini_M/0/1/0/all/0/1\">Mohamed-Slim Alouini</a>",
          "description": "In this paper, we study the hard and soft support vector regression\ntechniques applied to a set of $n$ linear measurements of the form\n$y_i=\\boldsymbol{\\beta}_\\star^{T}{\\bf x}_i +n_i$ where\n$\\boldsymbol{\\beta}_\\star$ is an unknown vector, $\\left\\{{\\bf\nx}_i\\right\\}_{i=1}^n$ are the feature vectors and\n$\\left\\{{n}_i\\right\\}_{i=1}^n$ model the noise. Particularly, under some\nplausible assumptions on the statistical distribution of the data, we\ncharacterize the feasibility condition for the hard support vector regression\nin the regime of high dimensions and, when feasible, derive an asymptotic\napproximation for its risk. Similarly, we study the test risk for the soft\nsupport vector regression as a function of its parameters. Our results are then\nused to optimally tune the parameters intervening in the design of hard and\nsoft support vector regression algorithms. Based on our analysis, we illustrate\nthat adding more samples may be harmful to the test performance of support\nvector regression, while it is always beneficial when the parameters are\noptimally selected. Such a result reminds a similar phenomenon observed in\nmodern learning architectures according to which optimally tuned architectures\npresent a decreasing test performance curve with respect to the number of\nsamples.",
          "link": "http://arxiv.org/abs/2105.10373",
          "publishedOn": "2021-05-24T07:23:08.679Z",
          "wordCount": 615,
          "title": "A Precise Performance Analysis of Support Vector Regression. (arXiv:2105.10373v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.08059",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Korkmaz_Y/0/1/0/all/0/1\">Yilmaz Korkmaz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dar_S/0/1/0/all/0/1\">Salman UH Dar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yurt_M/0/1/0/all/0/1\">Mahmut Yurt</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ozbey_M/0/1/0/all/0/1\">Muzaffer &#xd6;zbey</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cukur_T/0/1/0/all/0/1\">Tolga &#xc7;ukur</a>",
          "description": "Supervised deep learning has swiftly become a workhorse for accelerated MRI\nin recent years, offering state-of-the-art performance in image reconstruction\nfrom undersampled acquisitions. Training deep supervised models requires large\ndatasets of undersampled and fully-sampled acquisitions typically from a\nmatching set of subjects. Given scarce access to large medical datasets, this\nlimitation has sparked interest in unsupervised methods that reduce reliance on\nfully-sampled ground-truth data. A common framework is based on the deep image\nprior, where network-driven regularization is enforced directly during\ninference on undersampled acquisitions. Yet, canonical convolutional\narchitectures are suboptimal in capturing long-range relationships, and\nrandomly initialized networks may hamper convergence. To address these\nlimitations, here we introduce a novel unsupervised MRI reconstruction method\nbased on zero-Shot Learned Adversarial TransformERs (SLATER). SLATER embodies a\ndeep adversarial network with cross-attention transformer blocks to map noise\nand latent variables onto MR images. This unconditional network learns a\nhigh-quality MRI prior in a self-supervised encoding task. A zero-shot\nreconstruction is performed on undersampled test data, where inference is\nperformed by optimizing network parameters, latent and noise variables to\nensure maximal consistency to multi-coil MRI data. Comprehensive experiments on\nbrain MRI datasets clearly demonstrate the superior performance of SLATER\nagainst several state-of-the-art unsupervised methods.",
          "link": "http://arxiv.org/abs/2105.08059",
          "publishedOn": "2021-05-24T07:23:08.653Z",
          "wordCount": 666,
          "title": "Unsupervised MRI Reconstruction via Zero-Shot Learned Adversarial Transformers. (arXiv:2105.08059v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ozyegen_O/0/1/0/all/0/1\">Ozan Ozyegen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabe_D/0/1/0/all/0/1\">Devika Kabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cevik_M/0/1/0/all/0/1\">Mucahit Cevik</a>",
          "description": "The medical domain is often subject to information overload. The digitization\nof healthcare, constant updates to online medical repositories, and increasing\navailability of biomedical datasets make it challenging to effectively analyze\nthe data. This creates additional work for medical professionals who are\nheavily dependent on medical data to complete their research and consult their\npatients. This paper aims to show how different text highlighting techniques\ncan capture relevant medical context. This would reduce the doctors' cognitive\nload and response time to patients by facilitating them in making faster\ndecisions, thus improving the overall quality of online medical services. Three\ndifferent word-level text highlighting methodologies are implemented and\nevaluated. The first method uses TF-IDF scores directly to highlight important\nparts of the text. The second method is a combination of TF-IDF scores and the\napplication of Local Interpretable Model-Agnostic Explanations to\nclassification models. The third method uses neural networks directly to make\npredictions on whether or not a word should be highlighted. The results of our\nexperiments show that the neural network approach is successful in highlighting\nmedically-relevant terms and its performance is improved as the size of the\ninput segment increases.",
          "link": "http://arxiv.org/abs/2105.10400",
          "publishedOn": "2021-05-24T07:23:08.639Z",
          "wordCount": 620,
          "title": "Word-level Text Highlighting of Medical Texts forTelehealth Services. (arXiv:2105.10400v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Seurin_M/0/1/0/all/0/1\">Mathieu Seurin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strub_F/0/1/0/all/0/1\">Florian Strub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preux_P/0/1/0/all/0/1\">Philippe Preux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1\">Olivier Pietquin</a>",
          "description": "Sparse rewards are double-edged training signals in reinforcement learning:\neasy to design but hard to optimize. Intrinsic motivation guidances have thus\nbeen developed toward alleviating the resulting exploration problem. They\nusually incentivize agents to look for new states through novelty signals. Yet,\nsuch methods encourage exhaustive exploration of the state space rather than\nfocusing on the environment's salient interaction opportunities. We propose a\nnew exploration method, called Don't Do What Doesn't Matter (DoWhaM), shifting\nthe emphasis from state novelty to state with relevant actions. While most\nactions consistently change the state when used, \\textit{e.g.} moving the\nagent, some actions are only effective in specific states, \\textit{e.g.},\n\\emph{opening} a door, \\emph{grabbing} an object. DoWhaM detects and rewards\nactions that seldom affect the environment. We evaluate DoWhaM on the\nprocedurally-generated environment MiniGrid, against state-of-the-art methods\nand show that DoWhaM greatly reduces sample complexity.",
          "link": "http://arxiv.org/abs/2105.09992",
          "publishedOn": "2021-05-24T07:23:08.633Z",
          "wordCount": 573,
          "title": "Don't Do What Doesn't Matter: Intrinsic Motivation with Action Usefulness. (arXiv:2105.09992v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2101.00265",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaopeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tiancheng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyusong Lee</a>",
          "description": "Text-to-image retrieval is an essential task in cross-modal information\nretrieval, i.e., retrieving relevant images from a large and unlabelled dataset\ngiven textual queries. In this paper, we propose VisualSparta, a novel\n(Visual-text Sparse Transformer Matching) model that shows significant\nimprovement in terms of both accuracy and efficiency. VisualSparta is capable\nof outperforming previous state-of-the-art scalable methods in MSCOCO and\nFlickr30K. We also show that it achieves substantial retrieving speed\nadvantages, i.e., for a 1 million image index, VisualSparta using CPU gets\n~391X speedup compared to CPU vector search and ~5.4X speedup compared to\nvector search with GPU acceleration. Experiments show that this speed advantage\neven gets bigger for larger datasets because VisualSparta can be efficiently\nimplemented as an inverted index. To the best of our knowledge, VisualSparta is\nthe first transformer-based text-to-image retrieval model that can achieve\nreal-time searching for large-scale datasets, with significant accuracy\nimprovement compared to previous state-of-the-art methods.",
          "link": "http://arxiv.org/abs/2101.00265",
          "publishedOn": "2021-05-24T07:23:08.616Z",
          "wordCount": 629,
          "title": "VisualSparta: An Embarrassingly Simple Approach to Large-scale Text-to-Image Search with Weighted Bag-of-words. (arXiv:2101.00265v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10019",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Poh_D/0/1/0/all/0/1\">Daniel Poh</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Lim_B/0/1/0/all/0/1\">Bryan Lim</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Zohren_S/0/1/0/all/0/1\">Stefan Zohren</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>",
          "description": "The performance of a cross-sectional currency strategy depends crucially on\naccurately ranking instruments prior to portfolio construction. While this\nranking step is traditionally performed using heuristics, or by sorting outputs\nproduced by pointwise regression or classification models, Learning to Rank\nalgorithms have recently presented themselves as competitive and viable\nalternatives. Despite improving ranking accuracy on average however, these\ntechniques do not account for the possibility that assets positioned at the\nextreme ends of the ranked list -- which are ultimately used to construct the\nlong/short portfolios -- can assume different distributions in the input space,\nand thus lead to sub-optimal strategy performance. Drawing from research in\nInformation Retrieval that demonstrates the utility of contextual information\nembedded within top-ranked documents to learn the query's characteristics to\nimprove ranking, we propose an analogous approach: exploiting the features of\nboth out- and under-performing instruments to learn a model for refining the\noriginal ranked list. Under a re-ranking framework, we adapt the Transformer\narchitecture to encode the features of extreme assets for refining our\nselection of long/short instruments obtained with an initial retrieval.\nBacktesting on a set of 31 currencies, our proposed methodology significantly\nboosts Sharpe ratios -- by approximately 20% over the original LTR algorithms\nand double that of traditional baselines.",
          "link": "http://arxiv.org/abs/2105.10019",
          "publishedOn": "2021-05-24T07:23:08.607Z",
          "wordCount": 655,
          "title": "Enhancing Cross-Sectional Currency Strategies by Ranking Refinement with Transformer-based Architectures. (arXiv:2105.10019v1 [q-fin.PM])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09974",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Duran_Lopez_L/0/1/0/all/0/1\">Lourdes Duran-Lopez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dominguez_Morales_J/0/1/0/all/0/1\">Juan P. Dominguez-Morales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_Galan_D/0/1/0/all/0/1\">Daniel Gutierrez-Galan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rios_Navarro_A/0/1/0/all/0/1\">Antonio Rios-Navarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jimenez_Fernandez_A/0/1/0/all/0/1\">Angel Jimenez-Fernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vicente_Diaz_S/0/1/0/all/0/1\">Saturnino Vicente-Diaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linares_Barranco_A/0/1/0/all/0/1\">Alejandro Linares-Barranco</a>",
          "description": "Prostate cancer (PCa) is one of the most commonly diagnosed cancer and one of\nthe leading causes of death among men, with almost 1.41 million new cases and\naround 375,000 deaths in 2020. Artificial Intelligence algorithms have had a\nhuge impact in medical image analysis, including digital histopathology, where\nConvolutional Neural Networks (CNNs) are used to provide a fast and accurate\ndiagnosis, supporting experts in this task. To perform an automatic diagnosis,\nprostate tissue samples are first digitized into gigapixel-resolution\nwhole-slide images. Due to the size of these images, neural networks cannot use\nthem as input and, therefore, small subimages called patches are extracted and\npredicted, obtaining a patch-level classification. In this work, a novel patch\naggregation method based on a custom Wide & Deep neural network model is\npresented, which performs a slide-level classification using the patch-level\nclasses obtained from a CNN. The malignant tissue ratio, a 10-bin malignant\nprobability histogram, the least squares regression line of the histogram, and\nthe number of malignant connected components are used by the proposed model to\nperform the classification. An accuracy of 94.24% and a sensitivity of 98.87%\nwere achieved, proving that the proposed system could aid pathologists by\nspeeding up the screening process and, thus, contribute to the fight against\nPCa.",
          "link": "http://arxiv.org/abs/2105.09974",
          "publishedOn": "2021-05-24T07:23:08.583Z",
          "wordCount": 660,
          "title": "Wide & Deep neural network model for patch aggregation in CNN-based prostate cancer detection systems. (arXiv:2105.09974v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.14066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Slade_E/0/1/0/all/0/1\">Emma Slade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farina_F/0/1/0/all/0/1\">Francesco Farina</a>",
          "description": "In this draft paper, we introduce a novel architecture for graph networks\nwhich is equivariant to the Euclidean group in $n$-dimensions. The model is\ndesigned to work with graph networks in their general form and can be shown to\ninclude particular variants as special cases. Thanks to its equivariance\nproperties, we expect the proposed model to be more data efficient with respect\nto classical graph architectures and also intrinsically equipped with a better\ninductive bias. We defer investigating this matter to future work.",
          "link": "http://arxiv.org/abs/2103.14066",
          "publishedOn": "2021-05-24T07:23:08.577Z",
          "wordCount": 534,
          "title": "Beyond permutation equivariance in graph networks. (arXiv:2103.14066v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09994",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Korba_A/0/1/0/all/0/1\">Anna Korba</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Aubin_Frankowski_P/0/1/0/all/0/1\">Pierre-Cyril Aubin-Frankowski</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Majewski_S/0/1/0/all/0/1\">Szymon Majewski</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ablin_P/0/1/0/all/0/1\">Pierre Ablin</a>",
          "description": "Among dissimilarities between probability distributions, the Kernel Stein\nDiscrepancy (KSD) has received much interest recently. We investigate the\nproperties of its Wasserstein gradient flow to approximate a target probability\ndistribution $\\pi$ on $\\mathbb{R}^d$, known up to a normalization constant.\nThis leads to a straightforwardly implementable, deterministic score-based\nmethod to sample from $\\pi$, named KSD Descent, which uses a set of particles\nto approximate $\\pi$. Remarkably, owing to a tractable loss function, KSD\nDescent can leverage robust parameter-free optimization schemes such as L-BFGS;\nthis contrasts with other popular particle-based schemes such as the Stein\nVariational Gradient Descent algorithm. We study the convergence properties of\nKSD Descent and demonstrate its practical relevance. However, we also highlight\nfailure cases by showing that the algorithm can get stuck in spurious local\nminima.",
          "link": "http://arxiv.org/abs/2105.09994",
          "publishedOn": "2021-05-24T07:23:08.562Z",
          "wordCount": 547,
          "title": "Kernel Stein Discrepancy Descent. (arXiv:2105.09994v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10100",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1\">Muhan Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_J/0/1/0/all/0/1\">Jiajia Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wen_C/0/1/0/all/0/1\">Chao-Kai Wen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jin_S/0/1/0/all/0/1\">Shi Jin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_G/0/1/0/all/0/1\">Geoffrey Ye Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_A/0/1/0/all/0/1\">Ang Yang</a>",
          "description": "Massive multiple-input multiple-output can obtain more performance gain by\nexploiting the downlink channel state information (CSI) at the base station\n(BS). Therefore, studying CSI feedback with limited communication resources in\nfrequency-division duplexing systems is of great importance. Recently, deep\nlearning (DL)-based CSI feedback has shown considerable potential. However, the\nexisting DL-based explicit feedback schemes are difficult to deploy because\ncurrent fifth-generation mobile communication protocols and systems are\ndesigned based on an implicit feedback mechanism. In this paper, we propose a\nDL-based implicit feedback architecture to inherit the low-overhead\ncharacteristic, which uses neural networks (NNs) to replace the precoding\nmatrix indicator (PMI) encoding and decoding modules. By using environment\ninformation, the NNs can achieve a more refined mapping between the precoding\nmatrix and the PMI compared with codebooks. The correlation between subbands is\nalso used to further improve the feedback performance. Simulation results show\nthat, for a single resource block (RB), the proposed architecture can save\n25.0% and 40.0% of overhead compared with Type I codebook under two antenna\nconfigurations, respectively. For a wideband system with 52 RBs, overhead can\nbe saved by 30.7% and 48.0% compared with Type II codebook when ignoring and\nconsidering extracting subband correlation, respectively.",
          "link": "http://arxiv.org/abs/2105.10100",
          "publishedOn": "2021-05-24T07:23:08.556Z",
          "wordCount": 668,
          "title": "Deep Learning-based Implicit CSI Feedback in Massive MIMO. (arXiv:2105.10100v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10325",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kierdorf_J/0/1/0/all/0/1\">Jana Kierdorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_I/0/1/0/all/0/1\">Immanuel Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kicherer_A/0/1/0/all/0/1\">Anna Kicherer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabawa_L/0/1/0/all/0/1\">Laura Zabawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drees_L/0/1/0/all/0/1\">Lukas Drees</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roscher_R/0/1/0/all/0/1\">Ribana Roscher</a>",
          "description": "The need for accurate yield estimates for viticulture is becoming more\nimportant due to increasing competition in the wine market worldwide. One of\nthe most promising methods to estimate the harvest is berry counting, as it can\nbe approached non-destructively, and its process can be automated. In this\narticle, we present a method that addresses the challenge of occluded berries\nwith leaves to obtain a more accurate estimate of the number of berries that\nwill enable a better estimate of the harvest. We use generative adversarial\nnetworks, a deep learning-based approach that generates a likely scenario\nbehind the leaves exploiting learned patterns from images with non-occluded\nberries. Our experiments show that the estimate of the number of berries after\napplying our method is closer to the manually counted reference. In contrast to\napplying a factor to the berry count, our approach better adapts to local\nconditions by directly involving the appearance of the visible berries.\nFurthermore, we show that our approach can identify which areas in the image\nshould be changed by adding new berries without explicitly requiring\ninformation about hidden areas.",
          "link": "http://arxiv.org/abs/2105.10325",
          "publishedOn": "2021-05-24T07:23:08.528Z",
          "wordCount": 644,
          "title": "Behind the leaves -- Estimation of occluded grapevine berries with conditional generative adversarial networks. (arXiv:2105.10325v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10056",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhuangdi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Junyuan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiayu Zhou</a>",
          "description": "Federated Learning (FL) is a decentralized machine-learning paradigm, in\nwhich a global server iteratively averages the model parameters of local users\nwithout accessing their data. User heterogeneity has imposed significant\nchallenges to FL, which can incur drifted global models that are slow to\nconverge. Knowledge Distillation has recently emerged to tackle this issue, by\nrefining the server model using aggregated knowledge from heterogeneous users,\nother than directly averaging their model parameters. This approach, however,\ndepends on a proxy dataset, making it impractical unless such a prerequisite is\nsatisfied. Moreover, the ensemble knowledge is not fully utilized to guide\nlocal model learning, which may in turn affect the quality of the aggregated\nmodel. Inspired by the prior art, we propose a data-free knowledge\ndistillation} approach to address heterogeneous FL, where the server learns a\nlightweight generator to ensemble user information in a data-free manner, which\nis then broadcasted to users, regulating local training using the learned\nknowledge as an inductive bias. Empirical studies powered by theoretical\nimplications show that, our approach facilitates FL with better generalization\nperformance using fewer communication rounds, compared with the\nstate-of-the-art.",
          "link": "http://arxiv.org/abs/2105.10056",
          "publishedOn": "2021-05-24T07:23:08.469Z",
          "wordCount": 610,
          "title": "Data-Free Knowledge Distillation for Heterogeneous Federated Learning. (arXiv:2105.10056v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2006.03659",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giorgi_J/0/1/0/all/0/1\">John Giorgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nitski_O/0/1/0/all/0/1\">Osvald Nitski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bader_G/0/1/0/all/0/1\">Gary Bader</a>",
          "description": "Sentence embeddings are an important component of many natural language\nprocessing (NLP) systems. Like word embeddings, sentence embeddings are\ntypically learned on large text corpora and then transferred to various\ndownstream tasks, such as clustering and retrieval. Unlike word embeddings, the\nhighest performing solutions for learning sentence embeddings require labelled\ndata, limiting their usefulness to languages and domains where labelled data is\nabundant. In this paper, we present DeCLUTR: Deep Contrastive Learning for\nUnsupervised Textual Representations. Inspired by recent advances in deep\nmetric learning (DML), we carefully design a self-supervised objective for\nlearning universal sentence embeddings that does not require labelled training\ndata. When used to extend the pretraining of transformer-based language models,\nour approach closes the performance gap between unsupervised and supervised\npretraining for universal sentence encoders. Importantly, our experiments\nsuggest that the quality of the learned embeddings scale with both the number\nof trainable parameters and the amount of unlabelled training data, making\nfurther improvements straightforward. Our code and pretrained models are\npublicly available and can be easily adapted to new domains or used to embed\nunseen text.",
          "link": "http://arxiv.org/abs/2006.03659",
          "publishedOn": "2021-05-24T07:23:05.872Z",
          "wordCount": 649,
          "title": "DeCLUTR: Deep Contrastive Learning for Unsupervised Textual Representations. (arXiv:2006.03659v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06977",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1\">Kayo Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandes_P/0/1/0/all/0/1\">Patrick Fernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pruthi_D/0/1/0/all/0/1\">Danish Pruthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1\">Aditi Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>",
          "description": "Context-aware machine translation models are designed to leverage contextual\ninformation, but often fail to do so. As a result, they inaccurately\ndisambiguate pronouns and polysemous words that require context for resolution.\nIn this paper, we ask several questions: What contexts do human translators use\nto resolve ambiguous words? Are models paying large amounts of attention to the\nsame context? What if we explicitly train them to do so? To answer these\nquestions, we introduce SCAT (Supporting Context for Ambiguous Translations), a\nnew English-French dataset comprising supporting context words for 14K\ntranslations that professional translators found useful for pronoun\ndisambiguation. Using SCAT, we perform an in-depth analysis of the context used\nto disambiguate, examining positional and lexical characteristics of the\nsupporting words. Furthermore, we measure the degree of alignment between the\nmodel's attention scores and the supporting context from SCAT, and apply a\nguided attention strategy to encourage agreement between the two.",
          "link": "http://arxiv.org/abs/2105.06977",
          "publishedOn": "2021-05-24T07:23:05.863Z",
          "wordCount": 613,
          "title": "Do Context-Aware Translation Models Pay the Right Attention?. (arXiv:2105.06977v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08966",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sigrist_F/0/1/0/all/0/1\">Fabio Sigrist</a>",
          "description": "Latent Gaussian models and boosting are widely used techniques in statistics\nand machine learning. Tree-boosting shows excellent predictive accuracy on many\ndata sets, but potential drawbacks are that it assumes conditional independence\nof samples, produces discontinuous predictions for, e.g., spatial data, and it\ncan have difficulty with high-cardinality categorical variables. Latent\nGaussian models, such as Gaussian process and grouped random effects models,\nare flexible prior models that allow for making probabilistic predictions.\nHowever, existing latent Gaussian models usually assume either a zero or a\nlinear prior mean function which can be an unrealistic assumption. This article\nintroduces a novel approach that combines boosting and latent Gaussian models\nin order to remedy the above-mentioned drawbacks and to leverage the advantages\nof both techniques. We obtain increased predictive accuracy compared to\nexisting approaches in both simulated and real-world data experiments.",
          "link": "http://arxiv.org/abs/2105.08966",
          "publishedOn": "2021-05-24T07:23:05.845Z",
          "wordCount": 580,
          "title": "Latent Gaussian Model Boosting. (arXiv:2105.08966v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09989",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rothblum_G/0/1/0/all/0/1\">Guy N Rothblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yona_G/0/1/0/all/0/1\">Gal Yona</a>",
          "description": "An agnostic PAC learning algorithm finds a predictor that is competitive with\nthe best predictor in a benchmark hypothesis class, where competitiveness is\nmeasured with respect to a given loss function. However, its predictions might\nbe quite sub-optimal for structured subgroups of individuals, such as protected\ndemographic groups. Motivated by such fairness concerns, we study \"multi-group\nagnostic PAC learnability\": fixing a measure of loss, a benchmark class $\\H$\nand a (potentially) rich collection of subgroups $\\G$, the objective is to\nlearn a single predictor such that the loss experienced by every group $g \\in\n\\G$ is not much larger than the best possible loss for this group within $\\H$.\nUnder natural conditions, we provide a characterization of the loss functions\nfor which such a predictor is guaranteed to exist. For any such loss function\nwe construct a learning algorithm whose sample complexity is logarithmic in the\nsize of the collection $\\G$. Our results unify and extend previous positive and\nnegative results from the multi-group fairness literature, which applied for\nspecific loss functions.",
          "link": "http://arxiv.org/abs/2105.09989",
          "publishedOn": "2021-05-24T07:23:05.782Z",
          "wordCount": 591,
          "title": "Multi-group Agnostic PAC Learnability. (arXiv:2105.09989v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10360",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhou_D/0/1/0/all/0/1\">Doudou Zhou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cai_T/0/1/0/all/0/1\">Tianxi Cai</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lu_J/0/1/0/all/0/1\">Junwei Lu</a>",
          "description": "Matrix completion has attracted a lot of attention in many fields including\nstatistics, applied mathematics and electrical engineering. Most of works focus\non the independent sampling models under which the individual observed entries\nare sampled independently. Motivated by applications in the integration of\nmultiple (point-wise mutual information) PMI matrices, we propose the model\n{\\bf B}lockwise missing {\\bf E}mbedding {\\bf L}earning {\\bf T}ransformer (BELT)\nto treat row-wise/column-wise missingness. Specifically, our proposed method\naims at efficient matrix recovery when every pair of matrices from multiple\nsources has an overlap. We provide theoretical justification for the proposed\nBELT method. Simulation studies show that the method performs well in finite\nsample under a variety of configurations. The method is applied to integrate\nseveral PMI matrices built by EHR data and Chinese medical text data, which\nenables us to construct a comprehensive embedding set for CUI and Chinese with\nhigh quality.",
          "link": "http://arxiv.org/abs/2105.10360",
          "publishedOn": "2021-05-24T07:23:05.776Z",
          "wordCount": null,
          "title": "BELT: Blockwise Missing Embedding Learning Transfomer. (arXiv:2105.10360v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10347",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Sekkat_I/0/1/0/all/0/1\">Inass Sekkat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stoltz_G/0/1/0/all/0/1\">Gabriel Stoltz</a>",
          "description": "The computational cost of usual Monte Carlo methods for sampling a posteriori\nlaws in Bayesian inference scales linearly with the number of data points. One\noption to reduce it to a fraction of this cost is to resort to mini-batching in\nconjunction with unadjusted discretizations of Langevin dynamics, in which case\nonly a random fraction of the data is used to estimate the gradient. However,\nthis leads to an additional noise in the dynamics and hence a bias on the\ninvariant measure which is sampled by the Markov chain. We advocate using the\nso-called Adaptive Langevin dynamics, which is a modification of standard\ninertial Langevin dynamics with a dynamical friction which automatically\ncorrects for the increased noise arising from mini-batching. We investigate the\npractical relevance of the assumptions underpinning Adaptive Langevin (constant\ncovariance for the estimation of the gradient), which are not satisfied in\ntypical models of Bayesian inference; and show how to extend the approach to\nmore general situations.",
          "link": "http://arxiv.org/abs/2105.10347",
          "publishedOn": "2021-05-24T07:23:05.775Z",
          "wordCount": null,
          "title": "Removing the mini-batching error in Bayesian inference using Adaptive Langevin dynamics. (arXiv:2105.10347v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2009.09590",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lirong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zang_Z/0/1/0/all/0/1\">Zelin Zang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1\">Jun Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Siyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Stan. Z Li</a>",
          "description": "In this paper, we propose a novel framework for Deep Clustering and\nmulti-manifold Representation Learning (DCRL) that preserves the geometric\nstructure of data. In the proposed framework, manifold clustering is done in\nthe latent space guided by a clustering loss. To overcome the problem that\nclustering-oriented losses may deteriorate the geometric structure of\nembeddings in the latent space, an isometric loss is proposed for preserving\nintra-manifold structure locally and a ranking loss for inter-manifold\nstructure globally. Experimental results on various datasets show that DCRL\nleads to performances comparable to current state-of-the-art deep clustering\nalgorithms, yet exhibits superior performance for manifold representation. Our\nresults also demonstrate the importance and effectiveness of the proposed\nlosses in preserving geometric structure in terms of visualization and\nperformance metrics.",
          "link": "http://arxiv.org/abs/2009.09590",
          "publishedOn": "2021-05-24T07:23:05.757Z",
          "wordCount": null,
          "title": "Deep Clustering and Representation Learning with Geometric Structure Preservation. (arXiv:2009.09590v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10381",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Assaad_K/0/1/0/all/0/1\">Karim Assaad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devijver_E/0/1/0/all/0/1\">Emilie Devijver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaussier_E/0/1/0/all/0/1\">Eric Gaussier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ait_Bachir_A/0/1/0/all/0/1\">Ali Ait-Bachir</a>",
          "description": "We address in this study the problem of learning a summary causal graph on\ntime series with potentially different sampling rates. To do so, we first\npropose a new temporal mutual information measure defined on a window-based\nrepresentation of time series. We then show how this measure relates to an\nentropy reduction principle that can be seen as a special case of the\nProbabilistic Raising Principle. We finally combine these two ingredients in a\nPC-like algorithm to construct the summary causal graph. This algorithm is\nevaluated on several datasets that shows both its efficacy and efficiency.",
          "link": "http://arxiv.org/abs/2105.10381",
          "publishedOn": "2021-05-24T07:23:05.756Z",
          "wordCount": null,
          "title": "Entropy-based Discovery of Summary Causal Graphs in Time Series. (arXiv:2105.10381v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10414",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1\">Henry Kvinge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jefferson_B/0/1/0/all/0/1\">Brett Jefferson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joslyn_C/0/1/0/all/0/1\">Cliff Joslyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purvine_E/0/1/0/all/0/1\">Emilie Purvine</a>",
          "description": "As data grows in size and complexity, finding frameworks which aid in\ninterpretation and analysis has become critical. This is particularly true when\ndata comes from complex systems where extensive structure is available, but\nmust be drawn from peripheral sources. In this paper we argue that in such\nsituations, sheaves can provide a natural framework to analyze how well a\nstatistical model fits at the local level (that is, on subsets of related\ndatapoints) vs the global level (on all the data). The sheaf-based approach\nthat we propose is suitably general enough to be useful in a range of\napplications, from analyzing sensor networks to understanding the feature space\nof a deep learning model.",
          "link": "http://arxiv.org/abs/2105.10414",
          "publishedOn": "2021-05-24T07:23:05.756Z",
          "wordCount": null,
          "title": "Sheaves as a Framework for Understanding and Interpreting Model Fit. (arXiv:2105.10414v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.08179",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuening Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhengzhang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1\">Daochen Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Mengnan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Denghui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>",
          "description": "Time-series representation learning is a fundamental task for time-series\nanalysis. While significant progress has been made to achieve accurate\nrepresentations for downstream applications, the learned representations often\nlack interpretability and do not expose semantic meanings. Different from\nprevious efforts on the entangled feature space, we aim to extract the\nsemantic-rich temporal correlations in the latent interpretable factorized\nrepresentation of the data. Motivated by the success of disentangled\nrepresentation learning in computer vision, we study the possibility of\nlearning semantic-rich time-series representations, which remains unexplored\ndue to three main challenges: 1) sequential data structure introduces complex\ntemporal correlations and makes the latent representations hard to interpret,\n2) sequential models suffer from KL vanishing problem, and 3) interpretable\nsemantic concepts for time-series often rely on multiple factors instead of\nindividuals. To bridge the gap, we propose Disentangle Time Series (DTS), a\nnovel disentanglement enhancement framework for sequential data. Specifically,\nto generate hierarchical semantic concepts as the interpretable and\ndisentangled representation of time-series, DTS introduces multi-level\ndisentanglement strategies by covering both individual latent factors and group\nsemantic segments. We further theoretically show how to alleviate the KL\nvanishing problem: DTS introduces a mutual information maximization term, while\npreserving a heavier penalty on the total correlation and the dimension-wise KL\nto keep the disentanglement property. Experimental results on various\nreal-world benchmark datasets demonstrate that the representations learned by\nDTS achieve superior performance in downstream applications, with high\ninterpretability of semantic concepts.",
          "link": "http://arxiv.org/abs/2105.08179",
          "publishedOn": "2021-05-24T07:23:05.755Z",
          "wordCount": 683,
          "title": "Learning Disentangled Representations for Time Series. (arXiv:2105.08179v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09261",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+dAndrimont_R/0/1/0/all/0/1\">Rapha&#xeb;l d&#x27;Andrimont</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Verhegghen_A/0/1/0/all/0/1\">Astrid Verhegghen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lemoine_G/0/1/0/all/0/1\">Guido Lemoine</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kempeneers_P/0/1/0/all/0/1\">Pieter Kempeneers</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Meroni_M/0/1/0/all/0/1\">Michele Meroni</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Velde_M/0/1/0/all/0/1\">Marijn van der Velde</a>",
          "description": "Detailed parcel-level crop type mapping for the whole European Union (EU) is\nnecessary for the evaluation of agricultural policies. The Copernicus program,\nand Sentinel-1 (S1) in particular, offers the opportunity to monitor\nagricultural land at a continental scale and in a timely manner. However, so\nfar the potential of S1 has not been explored at such a scale. Capitalizing on\nthe unique LUCAS 2018 Copernicus in-situ survey, we present the first\ncontinental crop type map at 10-m spatial resolution for the EU based on S1A\nand S1B Synthetic Aperture Radar observations for the year 2018. Random forest\nclassification algorithms are tuned to detect 19 different crop types. We\nassess the accuracy of this EU crop map with three approaches. First, the\naccuracy is assessed with independent LUCAS core in-situ observations over the\ncontinent. Second, an accuracy assessment is done specifically for main crop\ntypes from farmers declarations from 6 EU member countries or regions totaling\n>3M parcels and 8.21 Mha. Finally, the crop areas derived by classification are\ncompared to the subnational (NUTS 2) area statistics reported by Eurostat. The\noverall accuracy for the map is reported as 80.3% when grouping main crop\nclasses and 76% when considering all 19 crop type classes separately. Highest\naccuracies are obtained for rape and turnip rape with user and produced\naccuracies higher than 96%. The correlation between the remotely sensed\nestimated and Eurostat reported crop area ranges from 0.93 (potatoes) to 0.99\n(rape and turnip rape). Finally, we discuss how the framework presented here\ncan underpin the operational delivery of in-season high-resolution based crop\nmapping.",
          "link": "http://arxiv.org/abs/2105.09261",
          "publishedOn": "2021-05-24T07:23:05.747Z",
          "wordCount": 748,
          "title": "From parcel to continental scale -- A first European crop type map based on Sentinel-1 and LUCAS Copernicus in-situ observations. (arXiv:2105.09261v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03625",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Wang_Z/0/1/0/all/0/1\">Zhishun Wang</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Zhang_K/0/1/0/all/0/1\">Kaixin Zhang</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Li_T/0/1/0/all/0/1\">Tianhao Li</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Zhao_Z/0/1/0/all/0/1\">Zixi Zhao</a>",
          "description": "It is a difficult task for both professional investors and individual traders\ncontinuously making profit in stock market. With the development of computer\nscience and deep reinforcement learning, Buy\\&Hold (B\\&H) has been oversteped\nby many artificial intelligence trading algorithms. However, the information\nand process are not enough, which limit the performance of reinforcement\nlearning algorithms. Thus, we propose a parallel-network continuous\nquantitative trading model with GARCH and PPO to enrich the basical deep\nreinforcement learning model, where the deep learning parallel network layers\ndeal with 3 different frequencies data (including GARCH information) and\nproximal policy optimization (PPO) algorithm interacts actions and rewards with\nstock trading environment. Experiments in 5 stocks from Chinese stock market\nshow our method achieves more extra profit comparing with basical reinforcement\nlearning methods and bench models.",
          "link": "http://arxiv.org/abs/2105.03625",
          "publishedOn": "2021-05-24T07:23:05.741Z",
          "wordCount": 586,
          "title": "A parallel-network continuous quantitative trading model with GARCH and PPO. (arXiv:2105.03625v2 [q-fin.TR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10457",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Diallo_A/0/1/0/all/0/1\">A&#xef;ssatou Diallo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furnkranz_J/0/1/0/all/0/1\">Johannes F&#xfc;rnkranz</a>",
          "description": "Ordinal embedding aims at finding a low dimensional representation of objects\nfrom a set of constraints of the form \"item $j$ is closer to item $i$ than item\n$k$\". Typically, each object is mapped onto a point vector in a low dimensional\nmetric space. We argue that mapping to a density instead of a point vector\nprovides some interesting advantages, including an inherent reflection of the\nuncertainty about the representation itself and its relative location in the\nspace. Indeed, in this paper, we propose to embed each object as a Gaussian\ndistribution. We investigate the ability of these embeddings to capture the\nunderlying structure of the data while satisfying the constraints, and explore\nproperties of the representation. Experiments on synthetic and real-world\ndatasets showcase the advantages of our approach. In addition, we illustrate\nthe merit of modelling uncertainty, which enriches the visual perception of the\nmapped objects in the space.",
          "link": "http://arxiv.org/abs/2105.10457",
          "publishedOn": "2021-05-24T07:23:05.732Z",
          "wordCount": null,
          "title": "Elliptical Ordinal Embedding. (arXiv:2105.10457v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10267",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ennen_P/0/1/0/all/0/1\">Philipp Ennen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yen-Ting Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozbay_A/0/1/0/all/0/1\">Ali Girayhan Ozbay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Insalata_F/0/1/0/all/0/1\">Ferdinando Insalata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Ye Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jalali_S/0/1/0/all/0/1\">Sepehr Jalali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>",
          "description": "In a dialogue system pipeline, a natural language generation (NLG) unit\nconverts the dialogue direction and content to a corresponding natural language\nrealization. A recent trend for dialogue systems is to first pre-train on large\ndatasets and then fine-tune in a supervised manner using datasets annotated\nwith application-specific features. Though novel behaviours can be learned from\ncustom annotation, the required effort severely bounds the quantity of the\ntraining set, and the application-specific nature limits the reuse. In light of\nthe recent success of data-driven approaches, we propose the novel future\nbridging NLG (FBNLG) concept for dialogue systems and simulators. The critical\nstep is for an FBNLG to accept a future user or system utterance to bridge the\npresent context towards. Future bridging enables self supervised training over\nannotation-free datasets, decoupled the training of NLG from the rest of the\nsystem. An FBNLG, pre-trained with massive datasets, is expected to apply in\nclassical or new dialogue scenarios with minimal adaptation effort. We evaluate\na prototype FBNLG to show that future bridging can be a viable approach to a\nuniversal few-shot NLG for task-oriented and chit-chat dialogues.",
          "link": "http://arxiv.org/abs/2105.10267",
          "publishedOn": "2021-05-24T07:23:05.731Z",
          "wordCount": null,
          "title": "Towards a Universal NLG for Dialogue Systems and Simulators with Future Bridging. (arXiv:2105.10267v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09966",
          "author": "<a href=\"http://arxiv.org/find/astro-ph/1/au:+Sandford_E/0/1/0/all/0/1\">Emily Sandford</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Kipping_D/0/1/0/all/0/1\">David Kipping</a>, <a href=\"http://arxiv.org/find/astro-ph/1/au:+Collins_M/0/1/0/all/0/1\">Michael Collins</a>",
          "description": "A planetary system consists of a host star and one or more planets, arranged\ninto a particular configuration. Here, we consider what information belongs to\nthe configuration, or ordering, of 4286 Kepler planets in their 3277 planetary\nsystems. First, we train a neural network model to predict the radius and\nperiod of a planet based on the properties of its host star and the radii and\nperiod of its neighbors. The mean absolute error of the predictions of the\ntrained model is a factor of 2.1 better than the MAE of the predictions of a\nnaive model which draws randomly from dynamically allowable periods and radii.\nSecond, we adapt a model used for unsupervised part-of-speech tagging in\ncomputational linguistics to investigate whether planets or planetary systems\nfall into natural categories with physically interpretable \"grammatical rules.\"\nThe model identifies two robust groups of planetary systems: (1) compact\nmulti-planet systems and (2) systems around giant stars ($\\log{g} \\lesssim\n4.0$), although the latter group is strongly sculpted by the selection bias of\nthe transit method. These results reinforce the idea that planetary systems are\nnot random sequences -- instead, as a population, they contain predictable\npatterns that can provide insight into the formation and evolution of planetary\nsystems.",
          "link": "http://arxiv.org/abs/2105.09966",
          "publishedOn": "2021-05-24T07:23:05.730Z",
          "wordCount": 639,
          "title": "On planetary systems as ordered sequences. (arXiv:2105.09966v1 [astro-ph.EP])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10315",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_R/0/1/0/all/0/1\">Ruiqi Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yuan_M/0/1/0/all/0/1\">Mingao Yuan</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shang_Z/0/1/0/all/0/1\">Zuofeng Shang</a>",
          "description": "Stochastic gradient descent (SGD) and projected stochastic gradient descent\n(PSGD) are scalable algorithms to compute model parameters in unconstrained and\nconstrained optimization problems. In comparison with stochastic gradient\ndescent (SGD), PSGD forces its iterative values into the constrained parameter\nspace via projection. The convergence rate of PSGD-type estimates has been\nexhaustedly studied, while statistical properties such as asymptotic\ndistribution remain less explored. From a purely statistical point of view,\nthis paper studies the limiting distribution of PSGD-based estimate when the\ntrue parameters satisfying some linear-equality constraints. Our theoretical\nfindings reveal the role of projection played in the uncertainty of the PSGD\nestimate. As a byproduct, we propose an online hypothesis testing procedure to\ntest the linear-equality constraints. Simulation studies on synthetic data and\nan application to a real-world dataset confirm our theory.",
          "link": "http://arxiv.org/abs/2105.10315",
          "publishedOn": "2021-05-24T07:23:05.724Z",
          "wordCount": null,
          "title": "Online Statistical Inference for Parameters Estimation with Linear-Equality Constraints. (arXiv:2105.10315v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10148",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yutian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulcehre_C/0/1/0/all/0/1\">Caglar Gulcehre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paine_T/0/1/0/all/0/1\">Tom Le Paine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gretton_A/0/1/0/all/0/1\">Arthur Gretton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_N/0/1/0/all/0/1\">Nando de Freitas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>",
          "description": "We show that the popular reinforcement learning (RL) strategy of estimating\nthe state-action value (Q-function) by minimizing the mean squared Bellman\nerror leads to a regression problem with confounding, the inputs and output\nnoise being correlated. Hence, direct minimization of the Bellman error can\nresult in significantly biased Q-function estimates. We explain why fixing the\ntarget Q-network in Deep Q-Networks and Fitted Q Evaluation provides a way of\novercoming this confounding, thus shedding new light on this popular but not\nwell understood trick in the deep RL literature. An alternative approach to\naddress confounding is to leverage techniques developed in the causality\nliterature, notably instrumental variables (IV). We bring together here the\nliterature on IV and RL by investigating whether IV approaches can lead to\nimproved Q-function estimates. This paper analyzes and compares a wide range of\nrecent IV methods in the context of offline policy evaluation (OPE), where the\ngoal is to estimate the value of a policy using logged data only. By applying\ndifferent IV techniques to OPE, we are not only able to recover previously\nproposed OPE methods such as model-based techniques but also to obtain\ncompetitive new techniques. We find empirically that state-of-the-art OPE\nmethods are closely matched in performance by some IV methods such as AGMM,\nwhich were not developed for OPE. We open-source all our code and datasets at\nhttps://github.com/liyuan9988/IVOPEwithACME.",
          "link": "http://arxiv.org/abs/2105.10148",
          "publishedOn": "2021-05-24T07:23:05.723Z",
          "wordCount": null,
          "title": "On Instrumental Variable Regression for Deep Offline Policy Evaluation. (arXiv:2105.10148v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10266",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hoel_C/0/1/0/all/0/1\">Carl-Johan Hoel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolff_K/0/1/0/all/0/1\">Krister Wolff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laine_L/0/1/0/all/0/1\">Leo Laine</a>",
          "description": "Reinforcement learning (RL) can be used to create a decision-making agent for\nautonomous driving. However, previous approaches provide only black-box\nsolutions, which do not offer information on how confident the agent is about\nits decisions. An estimate of both the aleatoric and epistemic uncertainty of\nthe agent's decisions is fundamental for real-world applications of autonomous\ndriving. Therefore, this paper introduces the Ensemble Quantile Networks (EQN)\nmethod, which combines distributional RL with an ensemble approach, to obtain a\ncomplete uncertainty estimate. The distribution over returns is estimated by\nlearning its quantile function implicitly, which gives the aleatoric\nuncertainty, whereas an ensemble of agents is trained on bootstrapped data to\nprovide a Bayesian estimation of the epistemic uncertainty. A criterion for\nclassifying which decisions that have an unacceptable uncertainty is also\nintroduced. The results show that the EQN method can balance risk and time\nefficiency in different occluded intersection scenarios, by considering the\nestimated aleatoric uncertainty. Furthermore, it is shown that the trained\nagent can use the epistemic uncertainty information to identify situations that\nthe agent has not been trained for and thereby avoid making unfounded,\npotentially dangerous, decisions outside of the training distribution.",
          "link": "http://arxiv.org/abs/2105.10266",
          "publishedOn": "2021-05-24T07:23:05.722Z",
          "wordCount": null,
          "title": "Ensemble Quantile Networks: Uncertainty-Aware Reinforcement Learning with Applications in Autonomous Driving. (arXiv:2105.10266v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10341",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Bragilevsky_L/0/1/0/all/0/1\">Lior Bragilevsky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bajic_I/0/1/0/all/0/1\">Ivan V. Baji&#x107;</a>",
          "description": "In the race to bring Artificial Intelligence (AI) to the edge, collaborative\nintelligence has emerged as a promising way to lighten the computation load on\nedge devices that run applications based on Deep Neural Networks (DNNs).\nTypically, a deep model is split at a certain layer into edge and cloud\nsub-models. The deep feature tensor produced by the edge sub-model is\ntransmitted to the cloud, where the remaining computationally intensive\nworkload is performed by the cloud sub-model. The communication channel between\nthe edge and cloud is imperfect, which will result in missing data in the deep\nfeature tensor received at the cloud side. In this study, we examine the\neffectiveness of four low-rank tensor completion methods in recovering missing\ndata in the deep feature tensor. We consider both sparse tensors, such as those\nproduced by the VGG16 model, as well as non-sparse tensors, such as those\nproduced by ResNet34 model. We study tensor completion effectiveness in both\nconplexity-constrained and unconstrained scenario.",
          "link": "http://arxiv.org/abs/2105.10341",
          "publishedOn": "2021-05-24T07:23:05.721Z",
          "wordCount": null,
          "title": "Error Resilient Collaborative Intelligence via Low-Rank Tensor Completion. (arXiv:2105.10341v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10368",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moreno_Sanchez_P/0/1/0/all/0/1\">Pedro A. Moreno-Sanchez</a>",
          "description": "Currently, Chronic Kidney Disease (CKD) is experiencing a globally increasing\nincidence and high cost to health systems. A delayed recognition leads to\npremature mortality due to progressive loss of kidney function. The employment\nof data mining to discover subtle patterns in CKD indicators would contribute\nto an early diagnosis. This work develops a classifier model that would support\nhealthcare professionals in the early diagnosis of CKD patients. Through a data\npipeline, an exhaustive search is performed to find the best data mining\nclassifier with different parameters of the data preparation's sub-stages like\ndata missing or feature selection. Therefore, Extra Trees is selected as the\nbest classifier with a 100% and 99% of accuracy with, respectively,\ncross-validation technique and with new unseen data. Moreover, the 8 features\nselected are employed to assess the explainability of the model's results\ndenoting which features are more relevant in the model's output.",
          "link": "http://arxiv.org/abs/2105.10368",
          "publishedOn": "2021-05-24T07:23:05.720Z",
          "wordCount": null,
          "title": "An Explainable Classification Model for Chronic Kidney Disease Patients. (arXiv:2105.10368v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10014",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carton_F/0/1/0/all/0/1\">Florence Carton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filliat_D/0/1/0/all/0/1\">David Filliat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabarisoa_J/0/1/0/all/0/1\">Jaonary Rabarisoa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_Q/0/1/0/all/0/1\">Quoc Cuong Pham</a>",
          "description": "In recent years, we have witnessed increasingly high performance in the field\nof autonomous end-to-end driving. In particular, more and more research is\nbeing done on driving in urban environments, where the car has to follow high\nlevel commands to navigate. However, few evaluations are made on the ability of\nthese agents to react in an unexpected situation. Specifically, no evaluations\nare conducted on the robustness of driving agents in the event of a bad\nhigh-level command. We propose here an evaluation method, namely a benchmark\nthat allows to assess the robustness of an agent, and to appreciate its\nunderstanding of the environment through its ability to keep a safe behavior,\nregardless of the instruction.",
          "link": "http://arxiv.org/abs/2105.10014",
          "publishedOn": "2021-05-24T07:23:05.718Z",
          "wordCount": null,
          "title": "Evaluating Robustness over High Level Driving Instruction for Autonomous Driving. (arXiv:2105.10014v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09945",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunlong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yiming Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dengzheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mai_Y/0/1/0/all/0/1\">Yingan Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruan_Z/0/1/0/all/0/1\">Zhengrong Ruan</a>",
          "description": "The energy consumption of the HVAC system accounts for a significant portion\nof the energy consumption of the public building system, and using an efficient\nenergy consumption prediction model can assist it in carrying out effective\nenergy-saving transformation. Unlike the traditional energy consumption\nprediction model, this paper extracts features from large data sets using\nXGBoost, trains them separately to obtain multiple models, then fuses them with\nLightGBM's independent prediction results using MAE, infers energy consumption\nrelated variables, and successfully applies this model to the self-developed\nInternet of Things platform.",
          "link": "http://arxiv.org/abs/2105.09945",
          "publishedOn": "2021-05-24T07:23:05.717Z",
          "wordCount": 522,
          "title": "XGBoost energy consumption prediction based on multi-system data HVAC. (arXiv:2105.09945v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.11574",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Helmy_M/0/1/0/all/0/1\">Maged Helmy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dykyy_A/0/1/0/all/0/1\">Anastasiya Dykyy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1\">Tuyen Trung Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_P/0/1/0/all/0/1\">Paulo Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jul_E/0/1/0/all/0/1\">Eric Jul</a>",
          "description": "Capillaries are the smallest vessels in the body responsible for the delivery\nof oxygen and nutrients to the surrounding cells. Various diseases have been\nshown to alter the density of nutritive capillaries and the flow velocity of\nerythrocytes. In previous studies, capillary density and flow velocity have\nbeen assessed manually by trained specialists. Manual analysis of a 20-second\nlong microvascular video takes on average 20 minutes and requires extensive\ntraining. Several studies have reported that manual analysis hinders the\napplication of microvascular microscopy in a clinical setting. In this paper,\nwe present a fully automated system, called CapillaryNet, that can automate\nmicrovascular microscopy analysis so it can be used as a clinical application.\nMoreover, CapillaryNet measures several microvascular parameters that\nresearchers were previously unable to quantify, i.e. capillary hematocrit and\nintra-capillary flow velocity heterogeneity.",
          "link": "http://arxiv.org/abs/2104.11574",
          "publishedOn": "2021-05-24T07:23:05.710Z",
          "wordCount": 607,
          "title": "CapillaryNet: An Automated System to Analyze Microcirculation Videos from Handheld Vital Microscopy. (arXiv:2104.11574v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.15195",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_W/0/1/0/all/0/1\">Wilka Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_A/0/1/0/all/0/1\">Anthony Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kimin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_S/0/1/0/all/0/1\">Sungryull Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_R/0/1/0/all/0/1\">Richard L. Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Satinder Singh</a>",
          "description": "First-person object-interaction tasks in high-fidelity, 3D, simulated\nenvironments such as the AI2Thor virtual home-environment pose significant\nsample-efficiency challenges for reinforcement learning (RL) agents learning\nfrom sparse task rewards. To alleviate these challenges, prior work has\nprovided extensive supervision via a combination of reward-shaping,\nground-truth object-information, and expert demonstrations. In this work, we\nshow that one can learn object-interaction tasks from scratch without\nsupervision by learning an attentive object-model as an auxiliary task during\ntask learning with an object-centric relational RL agent. Our key insight is\nthat learning an object-model that incorporates object-attention into forward\nprediction provides a dense learning signal for unsupervised representation\nlearning of both objects and their relationships. This, in turn, enables faster\npolicy learning for an object-centric relational RL agent. We demonstrate our\nagent by introducing a set of challenging object-interaction tasks in the\nAI2Thor environment where learning with our attentive object-model is key to\nstrong performance. Specifically, we compare our agent and relational RL agents\nwith alternative auxiliary tasks to a relational RL agent equipped with\nground-truth object-information, and show that learning with our object-model\nbest closes the performance gap in terms of both learning speed and maximum\nsuccess rate. Additionally, we find that incorporating object-attention into an\nobject-model's forward predictions is key to learning representations which\ncapture object-category and object-state.",
          "link": "http://arxiv.org/abs/2010.15195",
          "publishedOn": "2021-05-24T07:23:05.685Z",
          "wordCount": 695,
          "title": "Reinforcement Learning for Sparse-Reward Object-Interaction Tasks in a First-person Simulated 3D Environment. (arXiv:2010.15195v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10066",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Pei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karamouzas_I/0/1/0/all/0/1\">Ioannis Karamouzas</a>",
          "description": "We present a simple and intuitive approach for interactive control of\nphysically simulated characters. Our work builds upon generative adversarial\nnetworks (GAN) and reinforcement learning, and introduces an imitation learning\nframework where an ensemble of classifiers and an imitation policy are trained\nin tandem given pre-processed reference clips. The classifiers are trained to\ndiscriminate the reference motion from the motion generated by the imitation\npolicy, while the policy is rewarded for fooling the discriminators. Using our\nGAN-based approach, multiple motor control policies can be trained separately\nto imitate different behaviors. In runtime, our system can respond to external\ncontrol signal provided by the user and interactively switch between different\npolicies. Compared to existing methods, our proposed approach has the following\nattractive properties: 1) achieves state-of-the-art imitation performance\nwithout manually designing and fine tuning a reward function; 2) directly\ncontrols the character without having to track any target reference pose\nexplicitly or implicitly through a phase state; and 3) supports interactive\npolicy switching without requiring any motion generation or motion matching\nmechanism. We highlight the applicability of our approach in a range of\nimitation and interactive control tasks, while also demonstrating its ability\nto withstand external perturbations as well as to recover balance. Overall, our\napproach generates high-fidelity motion, has low runtime cost, and can be\neasily integrated into interactive applications and games.",
          "link": "http://arxiv.org/abs/2105.10066",
          "publishedOn": "2021-05-24T07:23:05.676Z",
          "wordCount": null,
          "title": "A GAN-Like Approach for Physics-Based Imitation Learning and Interactive Character Control. (arXiv:2105.10066v1 [cs.GR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.03075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Steven Y. Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1\">Varun Gangal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jason Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1\">Soroush Vosoughi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitamura_T/0/1/0/all/0/1\">Teruko Mitamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>",
          "description": "Data augmentation has recently seen increased interest in NLP due to more\nwork in low-resource domains, new tasks, and the popularity of large-scale\nneural networks that require large amounts of training data. Despite this\nrecent upsurge, this area is still relatively underexplored, perhaps due to the\nchallenges posed by the discrete nature of language data. In this paper, we\npresent a comprehensive and unifying survey of data augmentation for NLP by\nsummarizing the literature in a structured manner. We first introduce and\nmotivate data augmentation for NLP, and then discuss major methodologically\nrepresentative approaches. Next, we highlight techniques that are used for\npopular NLP applications and tasks. We conclude by outlining current challenges\nand directions for future research. Overall, our paper aims to clarify the\nlandscape of existing literature in data augmentation for NLP and motivate\nadditional work in this area. We also present a GitHub repository with a paper\nlist that will be continuously updated at\nhttps://github.com/styfeng/DataAug4NLP",
          "link": "http://arxiv.org/abs/2105.03075",
          "publishedOn": "2021-05-24T07:23:05.640Z",
          "wordCount": 634,
          "title": "A Survey of Data Augmentation Approaches for NLP. (arXiv:2105.03075v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10238",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Zapaishchykova_A/0/1/0/all/0/1\">Anna Zapaishchykova</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dreizin_D/0/1/0/all/0/1\">David Dreizin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1\">Zhaoshuo Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1\">Jie Ying Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Roohi_S/0/1/0/all/0/1\">Shahrooz Faghih Roohi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Unberath_M/0/1/0/all/0/1\">Mathias Unberath</a>",
          "description": "Pelvic ring disruptions result from blunt injury mechanisms and are often\nfound in patients with multi-system trauma. To grade pelvic fracture severity\nin trauma victims based on whole-body CT, the Tile AO/OTA classification is\nfrequently used. Due to the high volume of whole-body trauma CTs generated in\nbusy trauma centers, an automated approach to Tile classification would provide\nsubstantial value, e.,g., to prioritize the reading queue of the attending\ntrauma radiologist. In such scenario, an automated method should perform\ngrading based on a transparent process and based on interpretable features to\nenable interaction with human readers and lower their workload by offering\ninsights from a first automated read of the scan. This paper introduces an\nautomated yet interpretable pelvic trauma decision support system to assist\nradiologists in fracture detection and Tile grade classification. The method\noperates similarly to human interpretation of CT scans and first detects\ndistinct pelvic fractures on CT with high specificity using a Faster-RCNN model\nthat are then interpreted using a structural causal model based on clinical\nbest practices to infer an initial Tile grade. The Bayesian causal model and\nfinally, the object detector are then queried for likely co-occurring fractures\nthat may have been rejected initially due to the highly specific operating\npoint of the detector, resulting in an updated list of detected fractures and\ncorresponding final Tile grade. Our method is transparent in that it provides\nfinding location and type using the object detector, as well as information on\nimportant counterfactuals that would invalidate the system's recommendation and\nachieves an AUC of 83.3%/85.1% for translational/rotational instability.\nDespite being designed for human-machine teaming, our approach does not\ncompromise on performance compared to previous black-box approaches.",
          "link": "http://arxiv.org/abs/2105.10238",
          "publishedOn": "2021-05-24T07:23:05.633Z",
          "wordCount": null,
          "title": "An Interpretable Approach to Automated Severity Scoring in Pelvic Trauma. (arXiv:2105.10238v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10126",
          "author": "<a href=\"http://arxiv.org/find/hep-ph/1/au:+Kim_D/0/1/0/all/0/1\">Doojin Kim</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Kong_K/0/1/0/all/0/1\">Kyoungchul Kong</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Matchev_K/0/1/0/all/0/1\">Konstantin T. Matchev</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Park_M/0/1/0/all/0/1\">Myeonghun Park</a>, <a href=\"http://arxiv.org/find/hep-ph/1/au:+Shyamsundar_P/0/1/0/all/0/1\">Prasanth Shyamsundar</a>",
          "description": "The choice of optimal event variables is crucial for achieving the maximal\nsensitivity of experimental analyses. Over time, physicists have derived\nsuitable kinematic variables for many typical event topologies in collider\nphysics. Here we introduce a deep learning technique to design good event\nvariables, which are sensitive over a wide range of values for the unknown\nmodel parameters. We demonstrate that the neural networks trained with our\ntechnique on some simple event topologies are able to reproduce standard event\nvariables like invariant mass, transverse mass, and stransverse mass. The\nmethod is automatable, completely general, and can be used to derive sensitive,\npreviously unknown, event variables for other, more complex event topologies.",
          "link": "http://arxiv.org/abs/2105.10126",
          "publishedOn": "2021-05-24T07:23:05.630Z",
          "wordCount": null,
          "title": "Deep-Learned Event Variables for Collider Phenomenology. (arXiv:2105.10126v1 [hep-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2102.01733",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wentai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Ligang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weiwei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_R/0/1/0/all/0/1\">Rui Mao</a>",
          "description": "Federated Learning (FL) has shown great potential as a privacy-preserving\nsolution to learning from decentralized data which are only accessible locally\non end devices (i.e., clients). In many scenarios, however, a large proportion\nof the clients are probably in possession of low-quality data that are biased,\nnoisy or even irrelevant. As a result, they could significantly slow down the\nconvergence of the global model we aim to build and also compromise its\nquality. In light of this, we propose FedProf, a novel protocol for optimizing\nFL under such circumstances without breaching data privacy. The key of our\napproach is using the global model to dynamically profile the latent\nrepresentations of data (termed representation footprints) on the clients. By\nmatching local footprints on clients against a baseline footprint on the\nserver, we adaptively score each client and adjust its probability of being\nselected each round so as to mitigate the impact of the clients with\nlow-quality data on the training process. We have conducted extensive\nexperiments on public data sets using various FL settings. The results show\nthat FedProf effectively reduces the number of communication rounds and overall\ntime (providing up to 4.5x speedup) for the global model to converge while\nimproving the accuracy of the final global model.",
          "link": "http://arxiv.org/abs/2102.01733",
          "publishedOn": "2021-05-24T07:23:05.628Z",
          "wordCount": 694,
          "title": "FedProf: Efficient Federated Learning with Data Representation Profiling. (arXiv:2102.01733v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10142",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Chih-Hong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knoll_A/0/1/0/all/0/1\">Alois Knoll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_H/0/1/0/all/0/1\">Hsuan-Cheng Liao</a>",
          "description": "Within the context of autonomous driving, safety-related metrics for deep\nneural networks have been widely studied for image classification and object\ndetection. In this paper, we further consider safety-aware correctness and\nrobustness metrics specialized for semantic segmentation. The novelty of our\nproposal is to move beyond pixel-level metrics: Given two images with each\nhaving N pixels being class-flipped, the designed metrics should, depending on\nthe clustering of pixels being class-flipped or the location of occurrence,\nreflect a different level of safety criticality. The result evaluated on an\nautonomous driving dataset demonstrates the validity and practicality of our\nproposed methodology.",
          "link": "http://arxiv.org/abs/2105.10142",
          "publishedOn": "2021-05-24T07:23:05.618Z",
          "wordCount": null,
          "title": "Safety Metrics for Semantic Segmentation in Autonomous Driving. (arXiv:2105.10142v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2101.08954",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yao_Y/0/1/0/all/0/1\">Yuling Yao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pirs_G/0/1/0/all/0/1\">Gregor Pir&#x161;</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Vehtari_A/0/1/0/all/0/1\">Aki Vehtari</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Gelman_A/0/1/0/all/0/1\">Andrew Gelman</a>",
          "description": "Stacking is a widely used model averaging technique that asymptotically\nyields optimal predictions among linear averages. We show that stacking is most\neffective when model predictive performance is heterogeneous in inputs, and we\ncan further improve the stacked mixture with a hierarchical model. We\ngeneralize stacking to Bayesian hierarchical stacking. The model weights are\nvarying as a function of data, partially-pooled, and inferred using Bayesian\ninference. We further incorporate discrete and continuous inputs, other\nstructured priors, and time series and longitudinal data. To verify the\nperformance gain of the proposed method, we derive theory bounds, and\ndemonstrate on several applied problems.",
          "link": "http://arxiv.org/abs/2101.08954",
          "publishedOn": "2021-05-24T07:23:05.610Z",
          "wordCount": null,
          "title": "Bayesian hierarchical stacking: Some models are (somewhere) useful. (arXiv:2101.08954v2 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14431",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1\">Zihui Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Sucheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhengqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hang Zhao</a>",
          "description": "The popularity of multimodal sensors and the accessibility of the Internet\nhave brought us a massive amount of unlabeled multimodal data. Since existing\ndatasets and well-trained models are primarily unimodal, the modality gap\nbetween a unimodal network and unlabeled multimodal data poses an interesting\nproblem: how to transfer a pre-trained unimodal network to perform the same\ntask on unlabeled multimodal data? In this work, we propose multimodal\nknowledge expansion (MKE), a knowledge distillation-based framework to\neffectively utilize multimodal data without requiring labels. Opposite to\ntraditional knowledge distillation, where the student is designed to be\nlightweight and inferior to the teacher, we observe that a multimodal student\nmodel consistently denoises pseudo labels and generalizes better than its\nteacher. Extensive experiments on four tasks and different modalities verify\nthis finding. Furthermore, we connect the mechanism of MKE to semi-supervised\nlearning and offer both empirical and theoretical explanations to understand\nthe denoising capability of a multimodal student.",
          "link": "http://arxiv.org/abs/2103.14431",
          "publishedOn": "2021-05-24T07:23:05.609Z",
          "wordCount": 607,
          "title": "Multimodal Knowledge Expansion. (arXiv:2103.14431v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10113",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Min Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_Q/0/1/0/all/0/1\">Qiuxia Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yannan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiang Xu</a>",
          "description": "Deep learning (DL) has achieved unprecedented success in a variety of tasks.\nHowever, DL systems are notoriously difficult to test and debug due to the lack\nof explainability of DL models and the huge test input space to cover.\nGenerally speaking, it is relatively easy to collect a massive amount of test\ndata, but the labeling cost can be quite high. Consequently, it is essential to\nconduct test selection and label only those selected \"high quality\"\nbug-revealing test inputs for test cost reduction.\n\nIn this paper, we propose a novel test prioritization technique that brings\norder into the unlabeled test instances according to their bug-revealing\ncapabilities, namely TestRank. Different from existing solutions, TestRank\nleverages both intrinsic attributes and contextual attributes of test instances\nwhen prioritizing them. To be specific, we first build a similarity graph on\ntest instances and training samples, and we conduct graph-based semi-supervised\nlearning to extract contextual features. Then, for a particular test instance,\nthe contextual features extracted from the graph neural network (GNN) and the\nintrinsic features obtained with the DL model itself are combined to predict\nits bug-revealing probability. Finally, TestRank prioritizes unlabeled test\ninstances in descending order of the above probability value. We evaluate the\nperformance of TestRank on a variety of image classification datasets.\nExperimental results show that the debugging efficiency of our method\nsignificantly outperforms existing test prioritization techniques.",
          "link": "http://arxiv.org/abs/2105.10113",
          "publishedOn": "2021-05-24T07:23:05.601Z",
          "wordCount": null,
          "title": "TestRank: Bringing Order into Unlabeled Test Instances for Deep Learning Tasks. (arXiv:2105.10113v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.11128",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Gong_S/0/1/0/all/0/1\">Shu Gong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xing_K/0/1/0/all/0/1\">Kaibo Xing</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cichocki_A/0/1/0/all/0/1\">Andrzej Cichocki</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Junhua Li</a>",
          "description": "Deep learning has achieved excellent performance in a wide range of domains,\nespecially in speech recognition and computer vision. Relatively less work has\nbeen done for EEG, but there is still significant progress attained in the last\ndecade. Due to the lack of a comprehensive and topic widely covered survey for\ndeep learning in EEG, we attempt to summarize recent progress to provide an\noverview, as well as perspectives for future developments. We first briefly\nmention the artifacts removal for EEG signal and then introduce deep learning\nmodels that have been utilized in EEG processing and classification.\nSubsequently, the applications of deep learning in EEG are reviewed by\ncategorizing them into groups such as brain-computer interface, disease\ndetection, and emotion recognition. They are followed by the discussion, in\nwhich the pros and cons of deep learning are presented and future directions\nand challenges for deep learning in EEG are proposed. We hope that this paper\ncould serve as a summary of past work for deep learning in EEG and the\nbeginning of further developments and achievements of EEG studies based on deep\nlearning.",
          "link": "http://arxiv.org/abs/2011.11128",
          "publishedOn": "2021-05-24T07:23:05.600Z",
          "wordCount": 677,
          "title": "Deep Learning in EEG: Advance of the Last Ten-Year Critical Period. (arXiv:2011.11128v3 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08330",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chi_H/0/1/0/all/0/1\">Huixuan Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuying Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Q/0/1/0/all/0/1\">Qinfen Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Hong Xia</a>",
          "description": "Graph Convolutional Networks (GCNs) and subsequent variants have been\nproposed to solve tasks on graphs, especially node classification tasks. In the\nliterature, however, most tricks or techniques are either briefly mentioned as\nimplementation details or only visible in source code. In this paper, we first\nsummarize some existing effective tricks used in GCNs mini-batch training.\nBased on this, two novel tricks named GCN_res Framework and Embedding Usage are\nproposed by leveraging residual network and pre-trained embedding to improve\nbaseline's test accuracy in different datasets. Experiments on Open Graph\nBenchmark (OGB) show that, by combining these techniques, the test accuracy of\nvarious GCNs increases by 1.21%~2.84%. We open source our implementation at\nhttps://github.com/ytchx1999/PyG-OGB-Tricks.",
          "link": "http://arxiv.org/abs/2105.08330",
          "publishedOn": "2021-05-24T07:23:05.594Z",
          "wordCount": 579,
          "title": "Residual Network and Embedding Usage: New Tricks of Node Classification with Graph Convolutional Networks. (arXiv:2105.08330v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10049",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Whitman_J/0/1/0/all/0/1\">Julian Whitman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Travers_M/0/1/0/all/0/1\">Matthew Travers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choset_H/0/1/0/all/0/1\">Howie Choset</a>",
          "description": "To make a modular robotic system both capable and scalable, the controller\nmust be equally as modular as the mechanism. Given the large number of designs\nthat can be generated from even a small set of modules, it becomes impractical\nto create a new system-wide controller for each design. Instead, we construct a\nmodular control policy that handles a broad class of designs. We take the view\nthat a module is both form and function, i.e. both mechanism and controller. As\nthe modules are physically re-configured, the policy automatically\nre-configures to match the kinematic structure. This novel policy is trained\nwith a new model-based reinforcement learning algorithm, which interleaves\nmodel learning and trajectory optimization to guide policy learning for\nmultiple designs simultaneously. Training the policy on a varied set of designs\nteaches it how to adapt its behavior to the design. We show that the policy can\nthen generalize to a larger set of designs not seen during training. We\ndemonstrate one policy controlling many designs with different combinations of\nlegs and wheels to locomote both in simulation and on real robots.",
          "link": "http://arxiv.org/abs/2105.10049",
          "publishedOn": "2021-05-24T07:23:05.581Z",
          "wordCount": null,
          "title": "Learning Modular Robot Control Policies. (arXiv:2105.10049v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09980",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahmani_B/0/1/0/all/0/1\">Bahador Bahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlassis_N/0/1/0/all/0/1\">Nikolaos N. Vlassis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">WaiChing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yanxun Xu</a>",
          "description": "This paper presents a computational framework that generates ensemble\npredictive mechanics models with uncertainty quantification (UQ). We first\ndevelop a causal discovery algorithm to infer causal relations among\ntime-history data measured during each representative volume element (RVE)\nsimulation through a directed acyclic graph (DAG). With multiple plausible sets\nof causal relationships estimated from multiple RVE simulations, the\npredictions are propagated in the derived causal graph while using a deep\nneural network equipped with dropout layers as a Bayesian approximation for\nuncertainty quantification. We select two representative numerical examples\n(traction-separation laws for frictional interfaces, elastoplasticity models\nfor granular assembles) to examine the accuracy and robustness of the proposed\ncausal discovery method for the common material law predictions in civil\nengineering applications.",
          "link": "http://arxiv.org/abs/2105.09980",
          "publishedOn": "2021-05-24T07:23:05.571Z",
          "wordCount": null,
          "title": "Data-driven discovery of interpretable causal relations for deep learning material laws with uncertainty propagation. (arXiv:2105.09980v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2011.09999",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Anwar_U/0/1/0/all/0/1\">Usman Anwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_S/0/1/0/all/0/1\">Shehryar Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghasi_A/0/1/0/all/0/1\">Alireza Aghasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1\">Ali Ahmed</a>",
          "description": "In real world settings, numerous constraints are present which are hard to\nspecify mathematically. However, for the real world deployment of reinforcement\nlearning (RL), it is critical that RL agents are aware of these constraints, so\nthat they can act safely. In this work, we consider the problem of learning\nconstraints from demonstrations of a constraint-abiding agent's behavior. We\nexperimentally validate our approach and show that our framework can\nsuccessfully learn the most likely constraints that the agent respects. We\nfurther show that these learned constraints are \\textit{transferable} to new\nagents that may have different morphologies and/or reward functions. Previous\nworks in this regard have either mainly been restricted to tabular (discrete)\nsettings, specific types of constraints or assume the environment's transition\ndynamics. In contrast, our framework is able to learn arbitrary\n\\textit{Markovian} constraints in high-dimensions in a completely model-free\nsetting. The code can be found it:\n\\url{https://github.com/shehryar-malik/icrl}.",
          "link": "http://arxiv.org/abs/2011.09999",
          "publishedOn": "2021-05-24T07:23:05.570Z",
          "wordCount": 618,
          "title": "Inverse Constrained Reinforcement Learning. (arXiv:2011.09999v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10037",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Raychaudhuri_D/0/1/0/all/0/1\">Dripta S. Raychaudhuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1\">Sujoy Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baar_J/0/1/0/all/0/1\">Jeroen van Baar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_Chowdhury_A/0/1/0/all/0/1\">Amit K. Roy-Chowdhury</a>",
          "description": "Imitation learning seeks to circumvent the difficulty in designing proper\nreward functions for training agents by utilizing expert behavior. With\nenvironments modeled as Markov Decision Processes (MDP), most of the existing\nimitation algorithms are contingent on the availability of expert\ndemonstrations in the same MDP as the one in which a new imitation policy is to\nbe learned. In this paper, we study the problem of how to imitate tasks when\nthere exist discrepancies between the expert and agent MDP. These discrepancies\nacross domains could include differing dynamics, viewpoint, or morphology; we\npresent a novel framework to learn correspondences across such domains.\nImportantly, in contrast to prior works, we use unpaired and unaligned\ntrajectories containing only states in the expert domain, to learn this\ncorrespondence. We utilize a cycle-consistency constraint on both the state\nspace and a domain agnostic latent space to do this. In addition, we enforce\nconsistency on the temporal position of states via a normalized position\nestimator function, to align the trajectories across the two domains. Once this\ncorrespondence is found, we can directly transfer the demonstrations on one\ndomain to the other and use it for imitation. Experiments across a wide variety\nof challenging domains demonstrate the efficacy of our approach.",
          "link": "http://arxiv.org/abs/2105.10037",
          "publishedOn": "2021-05-24T07:23:05.555Z",
          "wordCount": null,
          "title": "Cross-domain Imitation from Observations. (arXiv:2105.10037v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10118",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1\">Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khosravi_P/0/1/0/all/0/1\">Pasha Khosravi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1\">Guy Van den Broeck</a>",
          "description": "Understanding the behavior of learned classifiers is an important task, and\nvarious black-box explanations, logical reasoning approaches, and\nmodel-specific methods have been proposed. In this paper, we introduce\nprobabilistic sufficient explanations, which formulate explaining an instance\nof classification as choosing the \"simplest\" subset of features such that only\nobserving those features is \"sufficient\" to explain the classification. That\nis, sufficient to give us strong probabilistic guarantees that the model will\nbehave similarly when all features are observed under the data distribution. In\naddition, we leverage tractable probabilistic reasoning tools such as\nprobabilistic circuits and expected predictions to design a scalable algorithm\nfor finding the desired explanations while keeping the guarantees intact. Our\nexperiments demonstrate the effectiveness of our algorithm in finding\nsufficient explanations, and showcase its advantages compared to Anchors and\nlogical explanations.",
          "link": "http://arxiv.org/abs/2105.10118",
          "publishedOn": "2021-05-24T07:23:05.554Z",
          "wordCount": null,
          "title": "Probabilistic Sufficient Explanations. (arXiv:2105.10118v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09987",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Amelard_R/0/1/0/all/0/1\">Robert Amelard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hedge_E/0/1/0/all/0/1\">Eric T Hedge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hughson_R/0/1/0/all/0/1\">Richard L Hughson</a>",
          "description": "Oxygen consumption (VO$_2$) provides established clinical and physiological\nindicators of cardiorespiratory function and exercise capacity. However, VO$_2$\nmonitoring is largely limited to specialized laboratory settings, making its\nwidespread monitoring elusive. Here, we investigate temporal prediction of\nVO$_2$ from wearable sensors during cycle ergometer exercise using a temporal\nconvolutional network (TCN). Cardiorespiratory signals were acquired from a\nsmart shirt with integrated textile sensors alongside ground-truth VO$_2$ from\na metabolic system on twenty-two young healthy adults. Participants performed\none ramp-incremental and three pseudorandom binary sequence exercise protocols\nto assess a range of VO$_2$ dynamics. A TCN model was developed using causal\nconvolutions across an effective history length to model the time-dependent\nnature of VO$_2$. Optimal history length was determined through minimum\nvalidation loss across hyperparameter values. The best performing model encoded\n218 s history length (TCN-VO$_2$ A), with 187 s, 97 s, and 76 s yielding less\nthan 3% deviation from the optimal validation loss. TCN-VO$_2$ A showed strong\nprediction accuracy (mean, 95% CI) across all exercise intensities (-22\nml.min$^{-1}$, [-262, 218]), spanning transitions from low-moderate (-23\nml.min$^{-1}$, [-250, 204]), low-heavy (14 ml.min$^{-1}$, [-252, 280]),\nventilatory threshold-heavy (-49 ml.min$^{-1}$, [-274, 176]), and maximal (-32\nml.min$^{-1}$, [-261, 197]) exercise. Second-by-second classification of\nphysical activity across 16090 s of predicted VO$_2$ was able to discern\nbetween vigorous, moderate, and light activity with high accuracy (94.1%). This\nsystem enables quantitative aerobic activity monitoring in non-laboratory\nsettings across a range of exercise intensities using wearable sensors for\nmonitoring exercise prescription adherence and personal fitness.",
          "link": "http://arxiv.org/abs/2105.09987",
          "publishedOn": "2021-05-24T07:23:05.543Z",
          "wordCount": null,
          "title": "Temporal prediction of oxygen uptake dynamics from wearable sensors during low-, moderate-, and heavy-intensity exercise. (arXiv:2105.09987v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10090",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Avdiukhin_D/0/1/0/all/0/1\">Dmitrii Avdiukhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yaroslavtsev_G/0/1/0/all/0/1\">Grigory Yaroslavtsev</a>",
          "description": "Stochastic gradient descent (SGD) is a prevalent optimization technique for\nlarge-scale distributed machine learning. While SGD computation can be\nefficiently divided between multiple machines, communication typically becomes\na bottleneck in the distributed setting. Gradient compression methods can be\nused to alleviate this problem, and a recent line of work shows that SGD\naugmented with gradient compression converges to an $\\varepsilon$-first-order\nstationary point. In this paper we extend these results to convergence to an\n$\\varepsilon$-second-order stationary point ($\\varepsilon$-SOSP), which is to\nthe best of our knowledge the first result of this type. In addition, we show\nthat, when the stochastic gradient is not Lipschitz, compressed SGD with\nRandomK compressor converges to an $\\varepsilon$-SOSP with the same number of\niterations as uncompressed SGD [Jin et al.,2021] (JACM), while improving the\ntotal communication by a factor of $\\tilde \\Theta(\\sqrt{d}\n\\varepsilon^{-3/4})$, where $d$ is the dimension of the optimization problem.\nWe present additional results for the cases when the compressor is arbitrary\nand when the stochastic gradient is Lipschitz.",
          "link": "http://arxiv.org/abs/2105.10090",
          "publishedOn": "2021-05-24T07:23:05.542Z",
          "wordCount": null,
          "title": "Escaping Saddle Points with Compressed SGD. (arXiv:2105.10090v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09985",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Prost_F/0/1/0/all/0/1\">Flavien Prost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awasthi_P/0/1/0/all/0/1\">Pranjal Awasthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blumm_N/0/1/0/all/0/1\">Nick Blumm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumthekar_A/0/1/0/all/0/1\">Aditee Kumthekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potter_T/0/1/0/all/0/1\">Trevor Potter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Li Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1\">Alex Beutel</a>",
          "description": "In this work we study the problem of measuring the fairness of a machine\nlearning model under noisy information. Focusing on group fairness metrics, we\ninvestigate the particular but common situation when the evaluation requires\ncontrolling for the confounding effect of covariate variables. In a practical\nsetting, we might not be able to jointly observe the covariate and group\ninformation, and a standard workaround is to then use proxies for one or more\nof these variables. Prior works have demonstrated the challenges with using a\nproxy for sensitive attributes, and strong independence assumptions are needed\nto provide guarantees on the accuracy of the noisy estimates. In contrast, in\nthis work we study using a proxy for the covariate variable and present a\ntheoretical analysis that aims to characterize weaker conditions under which\naccurate fairness evaluation is possible.\n\nFurthermore, our theory identifies potential sources of errors and decouples\nthem into two interpretable parts $\\gamma$ and $\\epsilon$. The first part\n$\\gamma$ depends solely on the performance of the proxy such as precision and\nrecall, whereas the second part $\\epsilon$ captures correlations between all\nthe variables of interest. We show that in many scenarios the error in the\nestimates is dominated by $\\gamma$ via a linear dependence, whereas the\ndependence on the correlations $\\epsilon$ only constitutes a lower order term.\nAs a result we expand the understanding of scenarios where measuring model\nfairness via proxies can be an effective approach. Finally, we compare, via\nsimulations, the theoretical upper-bounds to the distribution of simulated\nestimation errors and show that assuming some structure on the data, even weak,\nis key to significantly improve both theoretical guarantees and empirical\nresults.",
          "link": "http://arxiv.org/abs/2105.09985",
          "publishedOn": "2021-05-24T07:23:05.540Z",
          "wordCount": null,
          "title": "Measuring Model Fairness under Noisy Covariates: A Theoretical Perspective. (arXiv:2105.09985v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.06029",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1\">Ming Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>",
          "description": "This work studies the statistical limits of uniform convergence for offline\npolicy evaluation (OPE) problems with model-based methods (for finite horizon\nMDP) and provides a unified view towards optimal learning for several\nwell-motivated offline tasks. Uniform OPE\n$\\sup_\\Pi|Q^\\pi-\\hat{Q}^\\pi|<\\epsilon$ (initiated by \\citet{yin2021near}) is a\nstronger measure than the point-wise (fixed policy) OPE and ensures offline\npolicy learning when $\\Pi$ contains all policies (global policy class). In this\npaper, we establish an $\\Omega(H^2 S/d_m\\epsilon^2)$ lower bound (over\nmodel-based family) for the global uniform OPE, where $d_m$ is the minimal\nstate-action probability induced by the behavior policy. Next, our main result\nestablishes an episode complexity of $\\tilde{O}(H^2/d_m\\epsilon^2)$ for\n\\emph{local} uniform convergence that applies to all \\emph{near-empirically\noptimal} policies for the MDPs with \\emph{stationary} transition. This result\nimplies the optimal sample complexity for offline learning and separates the\nlocal uniform OPE from the global case due to the extra $S$ factor.\nParamountly, the model-based method combining with our new analysis technique\n(singleton absorbing MDP) can be adapted to the new settings: offline\ntask-agnostic and the offline reward-free with optimal complexity\n$\\tilde{O}(H^2\\log(K)/d_m\\epsilon^2)$ ($K$ is the number of tasks) and\n$\\tilde{O}(H^2S/d_m\\epsilon^2)$ respectively, which provides a unified\nframework for simultaneously solving different offline RL problems.",
          "link": "http://arxiv.org/abs/2105.06029",
          "publishedOn": "2021-05-24T07:23:05.540Z",
          "wordCount": 657,
          "title": "Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings. (arXiv:2105.06029v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.14928",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Brochard_A/0/1/0/all/0/1\">Antoine Brochard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Blaszczyszyn_B/0/1/0/all/0/1\">Bart&#x142;omiej B&#x142;aszczyszyn</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mallat_S/0/1/0/all/0/1\">St&#xe9;phane Mallat</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1\">Sixin Zhang</a>",
          "description": "This paper introduces a generative model for planar point processes in a\nsquare window, built upon a single realization of a stationary, ergodic point\nprocess observed in this window. Inspired by recent advances in gradient\ndescent methods for maximum entropy models, we propose a method to generate\nsimilar point patterns by jointly moving particles of an initial Poisson\nconfiguration towards a target counting measure. The target measure is\ngenerated via a deterministic gradient descent algorithm, so as to match a set\nof statistics of the given, observed realization. Our statistics are estimators\nof the multi-scale wavelet phase harmonic covariance, recently proposed in\nimage modeling. They allow one to capture geometric structures through\nmulti-scale interactions between wavelet coefficients. Both our statistics and\nthe gradient descent algorithm scale better with the number of observed points\nthan the classical k-nearest neighbour distances previously used in generative\nmodels for point processes, based on the rejection sampling or\nsimulated-annealing. The overall quality of our model is evaluated on point\nprocesses with various geometric structures through spectral and topological\ndata analysis.",
          "link": "http://arxiv.org/abs/2010.14928",
          "publishedOn": "2021-05-24T07:23:05.520Z",
          "wordCount": 629,
          "title": "Particle gradient descent model for point process generation. (arXiv:2010.14928v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05883",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fraboni_Y/0/1/0/all/0/1\">Yann Fraboni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1\">Richard Vidal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kameni_L/0/1/0/all/0/1\">Laetitia Kameni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenzi_M/0/1/0/all/0/1\">Marco Lorenzi</a>",
          "description": "This work addresses the problem of optimizing communications between server\nand clients in federated learning (FL). Current sampling approaches in FL are\neither biased, or non optimal in terms of server-clients communications and\ntraining stability. To overcome this issue, we introduce \\textit{clustered\nsampling} for clients selection. We prove that clustered sampling leads to\nbetter clients representatitivity and to reduced variance of the clients\nstochastic aggregation weights in FL. Compatibly with our theory, we provide\ntwo different clustering approaches enabling clients aggregation based on 1)\nsample size, and 2) models similarity. Through a series of experiments in\nnon-iid and unbalanced scenarios, we demonstrate that model aggregation through\nclustered sampling consistently leads to better training convergence and\nvariability when compared to standard sampling approaches. Our approach does\nnot require any additional operation on the clients side, and can be seamlessly\nintegrated in standard FL implementations. Finally, clustered sampling is\ncompatible with existing methods and technologies for privacy enhancement, and\nfor communication reduction through model compression.",
          "link": "http://arxiv.org/abs/2105.05883",
          "publishedOn": "2021-05-24T07:23:05.464Z",
          "wordCount": 616,
          "title": "Clustered Sampling: Low-Variance and Improved Representativity for Clients Selection in Federated Learning. (arXiv:2105.05883v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.08712",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Khoshsirat_A/0/1/0/all/0/1\">Aria Khoshsirat</a>",
          "description": "Quantifying uncertainty in a model's predictions is important as it enables\nthe safety of an AI system to be increased by acting on the model's output in\nan informed manner. This is crucial for applications where the cost of an error\nis high, such as in autonomous vehicle control, medical image analysis,\nfinancial estimations or legal fields. Deep Neural Networks are powerful\npredictors that have recently achieved state-of-the-art performance on a wide\nspectrum of tasks. Quantifying predictive uncertainty in DNNs is a challenging\nand yet on-going problem. In this paper we propose a complete framework to\ncapture and quantify all of these three types of uncertainties in DNNs for\nimage classification. This framework includes an ensemble of CNNs for model\nuncertainty, a supervised reconstruction auto-encoder to capture distributional\nuncertainty and using the output of activation functions in the last layer of\nthe network, to capture data uncertainty. Finally we demonstrate the efficiency\nof our method on popular image datasets for classification.",
          "link": "http://arxiv.org/abs/2011.08712",
          "publishedOn": "2021-05-24T07:23:05.458Z",
          "wordCount": 651,
          "title": "Quantifying Uncertainty from Different Sources in Deep Neural Networks for Image Classification. (arXiv:2011.08712v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.10315",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Singh_R/0/1/0/all/0/1\">Rahul Singh</a>",
          "description": "Negative control is a strategy for learning the causal relationship between\ntreatment and outcome in the presence of unmeasured confounding. The treatment\neffect can nonetheless be identified if two auxiliary variables are available:\na negative control treatment (which has no effect on the actual outcome), and a\nnegative control outcome (which is not affected by the actual treatment). These\nauxiliary variables can also be viewed as proxies for a traditional set of\ncontrol variables, and they bear resemblance to instrumental variables. I\npropose a family of algorithms based on kernel ridge regression for learning\nnonparametric treatment effects with negative controls. Examples include dose\nresponse curves, dose response curves with distribution shift, and\nheterogeneous treatment effects. Data may be discrete or continuous, and low,\nhigh, or infinite dimensional. I prove uniform consistency and provide finite\nsample rates of convergence. I estimate the dose response curve of cigarette\nsmoking on infant birth weight adjusting for unobserved confounding due to\nhousehold income, using a data set of singleton births in the state of\nPennsylvania between 1989 and 1991.",
          "link": "http://arxiv.org/abs/2012.10315",
          "publishedOn": "2021-05-24T07:23:05.443Z",
          "wordCount": 632,
          "title": "Kernel Methods for Unobserved Confounding: Negative Controls, Proxies, and Instruments. (arXiv:2012.10315v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09983",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Korani_W/0/1/0/all/0/1\">Wael Korani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mouhoub_M/0/1/0/all/0/1\">Malek Mouhoub</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadaoui_S/0/1/0/all/0/1\">Samira Sadaoui</a>",
          "description": "This study aims to optimize Deep Feedforward Neural Networks (DFNNs) training\nusing nature-inspired optimization algorithms, such as PSO, MTO, and its\nvariant called MTOCL. We show how these algorithms efficiently update the\nweights of DFNNs when learning from data. We evaluate the performance of DFNN\nfused with optimization algorithms using three Wisconsin breast cancer\ndatasets, Original, Diagnostic, and Prognosis, under different experimental\nscenarios. The empirical analysis demonstrates that MTOCL is the most\nperforming in most scenarios across the three datasets. Also, MTOCL is\ncomparable to past weight optimization algorithms for the original dataset, and\nsuperior for the other datasets, especially for the challenging Prognostic\ndataset.",
          "link": "http://arxiv.org/abs/2105.09983",
          "publishedOn": "2021-05-24T07:23:05.413Z",
          "wordCount": null,
          "title": "Optimizing Neural Network Weights using Nature-Inspired Algorithms. (arXiv:2105.09983v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2103.00950",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kenfack_P/0/1/0/all/0/1\">Patrik Joslin Kenfack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arapov_D/0/1/0/all/0/1\">Daniil Dmitrievich Arapov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussain_R/0/1/0/all/0/1\">Rasheed Hussain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazmi_S/0/1/0/all/0/1\">S.M. Ahsan Kazmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Adil Mehmood Khan</a>",
          "description": "Generative adversarial networks (GANs) are one of the greatest advances in AI\nin recent years. With their ability to directly learn the probability\ndistribution of data, and then sample synthetic realistic data. Many\napplications have emerged, using GANs to solve classical problems in machine\nlearning, such as data augmentation, class unbalance problems, and fair\nrepresentation learning. In this paper, we analyze and highlight fairness\nconcerns of GANs model. In this regard, we show empirically that GANs models\nmay inherently prefer certain groups during the training process and therefore\nthey're not able to homogeneously generate data from different groups during\nthe testing phase. Furthermore, we propose solutions to solve this issue by\nconditioning the GAN model towards samples' group or using ensemble method\n(boosting) to allow the GAN model to leverage distributed structure of data\nduring the training phase and generate groups at equal rate during the testing\nphase.",
          "link": "http://arxiv.org/abs/2103.00950",
          "publishedOn": "2021-05-24T07:23:05.406Z",
          "wordCount": 624,
          "title": "On the Fairness of Generative Adversarial Networks (GANs). (arXiv:2103.00950v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09967",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Shmueli_B/0/1/0/all/0/1\">Boaz Shmueli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_S/0/1/0/all/0/1\">Soumya Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ku_L/0/1/0/all/0/1\">Lun-Wei Ku</a>",
          "description": "Datasets with induced emotion labels are scarce but of utmost importance for\nmany NLP tasks. We present a new, automated method for collecting texts along\nwith their induced reaction labels. The method exploits the online use of\nreaction GIFs, which capture complex affective states. We show how to augment\nthe data with induced emotion and induced sentiment labels. We use our method\nto create and publish ReactionGIF, a first-of-its-kind affective dataset of 30K\ntweets. We provide baselines for three new tasks, including induced sentiment\nprediction and multilabel classification of induced emotions. Our method and\ndataset open new research opportunities in emotion detection and affective\ncomputing.",
          "link": "http://arxiv.org/abs/2105.09967",
          "publishedOn": "2021-05-24T07:23:05.390Z",
          "wordCount": null,
          "title": "Happy Dance, Slow Clap: Using Reaction GIFs to Predict Induced Affect on Twitter. (arXiv:2105.09967v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.00884",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Milan_G/0/1/0/all/0/1\">Giulia Milan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vassio_L/0/1/0/all/0/1\">Luca Vassio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drago_I/0/1/0/all/0/1\">Idilio Drago</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mellia_M/0/1/0/all/0/1\">Marco Mellia</a>",
          "description": "Our life is getting filled by Internet of Things (IoT) devices. These devices\noften rely on closed or poorly documented protocols, with unknown formats and\nsemantics. Learning how to interact with such devices in an autonomous manner\nis the key for interoperability and automatic verification of their\ncapabilities. In this paper, we propose RL-IoT, a system that explores how to\nautomatically interact with possibly unknown IoT devices. We leverage\nreinforcement learning (RL) to recover the semantics of protocol messages and\nto take control of the device to reach a given goal, while minimizing the\nnumber of interactions. We assume to know only a database of possible IoT\nprotocol messages, whose semantics are however unknown. RL-IoT exchanges\nmessages with the target IoT device, learning those commands that are useful to\nreach the given goal. Our results show that RL-IoT is able to solve both simple\nand complex tasks. With properly tuned parameters, RL-IoT learns how to perform\nactions with the target device, a Yeelight smart bulb in our case study,\ncompleting non-trivial patterns with as few as 400 interactions. RL-IoT paves\nthe road for automatic interactions with poorly documented IoT protocols, thus\nenabling interoperable systems.",
          "link": "http://arxiv.org/abs/2105.00884",
          "publishedOn": "2021-05-24T07:23:05.384Z",
          "wordCount": 655,
          "title": "RL-IoT: Reinforcement Learning to Interact with IoT Devices. (arXiv:2105.00884v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.00358",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1\">Benjamin Moseley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pruhs_K/0/1/0/all/0/1\">Kirk Pruhs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samadian_A/0/1/0/all/0/1\">Alireza Samadian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyan Wang</a>",
          "description": "This paper gives a k-means approximation algorithm that is efficient in the\nrelational algorithms model. This is an algorithm that operates directly on a\nrelational database without performing a join to convert it to a matrix whose\nrows represent the data points. The running time is potentially exponentially\nsmaller than $N$, the number of data points to be clustered that the relational\ndatabase represents.\n\nFew relational algorithms are known and this paper offers techniques for\ndesigning relational algorithms as well as characterizing their limitations. We\nshow that given two data points as cluster centers, if we cluster points\naccording to their closest centers, it is NP-Hard to approximate the number of\npoints in the clusters on a general relational input. This is trivial for\nconventional data inputs and this result exemplifies that standard algorithmic\ntechniques may not be directly applied when designing an efficient relational\nalgorithm. This paper then introduces a new method that leverages rejection\nsampling and the $k$-means++ algorithm to construct an O(1)-approximate k-means\nsolution.",
          "link": "http://arxiv.org/abs/2008.00358",
          "publishedOn": "2021-05-24T07:23:05.268Z",
          "wordCount": 624,
          "title": "Relational Algorithms for k-means Clustering. (arXiv:2008.00358v2 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.08798",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guan_Y/0/1/0/all/0/1\">Yu Guan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_J/0/1/0/all/0/1\">Jian-Qing Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Du_X/0/1/0/all/0/1\">Xiu-Li Du</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Eyre_J/0/1/0/all/0/1\">Janet Eyre</a>",
          "description": "Stroke is known as a major global health problem, and for stroke survivors it\nis key to monitor the recovery levels. However, traditional stroke\nrehabilitation assessment methods (such as the popular clinical assessment) can\nbe subjective and expensive, and it is also less convenient for patients to\nvisit clinics in a high frequency. To address this issue, in this work based on\nwearable sensing and machine learning techniques, we developed an automated\nsystem that can predict the assessment score in an objective manner. With\nwrist-worn sensors, accelerometer data was collected from 59 stroke survivors\nin free-living environments for a duration of 8 weeks, and we aim to map the\nweek-wise accelerometer data (3 days per week) to the assessment score by\ndeveloping signal processing and predictive model pipeline. To achieve this, we\nproposed two types of new features, which can encode the rehabilitation\ninformation from both paralysed/non-paralysed sides while suppressing the\nhigh-level noises such as irrelevant daily activities. Based on the proposed\nfeatures, we further developed the longitudinal mixed-effects model with\nGaussian process prior (LMGP), which can model the random effects caused by\ndifferent subjects and time slots (during the 8 weeks). Comprehensive\nexperiments were conducted to evaluate our system on both acute and chronic\npatients, and the results suggested its effectiveness.",
          "link": "http://arxiv.org/abs/2009.08798",
          "publishedOn": "2021-05-24T07:23:05.259Z",
          "wordCount": 679,
          "title": "Automated Stroke Rehabilitation Assessment using Wearable Accelerometers in Free-Living Environments. (arXiv:2009.08798v2 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.10876",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_K/0/1/0/all/0/1\">Kaleel Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevin_D/0/1/0/all/0/1\">Deniz Gurevin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijk_M/0/1/0/all/0/1\">Marten van Dijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuong Ha Nguyen</a>",
          "description": "Many defenses have recently been proposed at venues like NIPS, ICML, ICLR and\nCVPR. These defenses are mainly focused on mitigating white-box attacks. They\ndo not properly examine black-box attacks. In this paper, we expand upon the\nanalysis of these defenses to include adaptive black-box adversaries. Our\nevaluation is done on nine defenses including Barrage of Random Transforms,\nComDefend, Ensemble Diversity, Feature Distillation, The Odds are Odd, Error\nCorrecting Codes, Distribution Classifier Defense, K-Winner Take All and Buffer\nZones. Our investigation is done using two black-box adversarial models and six\nwidely studied adversarial attacks for CIFAR-10 and Fashion-MNIST datasets. Our\nanalyses show most recent defenses (7 out of 9) provide only marginal\nimprovements in security ($<25\\%$), as compared to undefended networks. For\nevery defense, we also show the relationship between the amount of data the\nadversary has at their disposal, and the effectiveness of adaptive black-box\nattacks. Overall, our results paint a clear picture: defenses need both\nthorough white-box and black-box analyses to be considered secure. We provide\nthis large scale study and analyses to motivate the field to move towards the\ndevelopment of more robust black-box defenses.",
          "link": "http://arxiv.org/abs/2006.10876",
          "publishedOn": "2021-05-24T07:23:05.241Z",
          "wordCount": 656,
          "title": "Beware the Black-Box: on the Robustness of Recent Defenses to Adversarial Examples. (arXiv:2006.10876v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.01783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Tiansheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weiwei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wentai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Ligang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Keqin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zomaya_A/0/1/0/all/0/1\">Albert Y.Zomaya</a>",
          "description": "The issue of potential privacy leakage during centralized AI's model training\nhas drawn intensive concern from the public. A Parallel and Distributed\nComputing (or PDC) scheme, termed Federated Learning (FL), has emerged as a new\nparadigm to cope with the privacy issue by allowing clients to perform model\ntraining locally, without the necessity to upload their personal sensitive\ndata. In FL, the number of clients could be sufficiently large, but the\nbandwidth available for model distribution and re-upload is quite limited,\nmaking it sensible to only involve part of the volunteers to participate in the\ntraining process. The client selection policy is critical to an FL process in\nterms of training efficiency, the final model's quality as well as fairness. In\nthis paper, we will model the fairness guaranteed client selection as a\nLyapunov optimization problem and then a C2MAB-based method is proposed for\nestimation of the model exchange time between each client and the server, based\non which we design a fairness guaranteed algorithm termed RBCS-F for\nproblem-solving. The regret of RBCS-F is strictly bounded by a finite constant,\njustifying its theoretical feasibility. Barring the theoretical results, more\nempirical data can be derived from our real training experiments on public\ndatasets.",
          "link": "http://arxiv.org/abs/2011.01783",
          "publishedOn": "2021-05-24T07:23:05.196Z",
          "wordCount": 699,
          "title": "An Efficiency-boosting Client Selection Scheme for Federated Learning with Fairness Guarantee. (arXiv:2011.01783v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10489",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bilbrey_J/0/1/0/all/0/1\">Jenna Bilbrey</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ward_L/0/1/0/all/0/1\">Logan Ward</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Choudhury_S/0/1/0/all/0/1\">Sutanay Choudhury</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Kumar_N/0/1/0/all/0/1\">Neeraj Kumar</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sivaraman_G/0/1/0/all/0/1\">Ganesh Sivaraman</a>",
          "description": "We examine a pair of graph generative models for the therapeutic design of\nnovel drug candidates targeting SARS-CoV-2 viral proteins. Due to a sense of\nurgency, we chose well-validated models with unique strengths: an autoencoder\nthat generates molecules with similar structures to a dataset of drugs with\nanti-SARS activity and a reinforcement learning algorithm that generates highly\nnovel molecules. During generation, we explore optimization toward several\ndesign targets to balance druglikeness, synthetic accessability, and anti-SARS\nactivity based on \\icfifty. This generative\nframework\\footnote{https://github.com/exalearn/covid-drug-design} will\naccelerate drug discovery in future pandemics through the high-throughput\ngeneration of targeted therapeutic candidates.",
          "link": "http://arxiv.org/abs/2105.10489",
          "publishedOn": "2021-05-24T07:23:04.751Z",
          "wordCount": 608,
          "title": "Evening the Score: Targeting SARS-CoV-2 Protease Inhibition in Graph Generative Models for Therapeutic Candidates. (arXiv:2105.10489v1 [q-bio.BM])"
        },
        {
          "id": "http://arxiv.org/abs/2010.04992",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mokhtarian_E/0/1/0/all/0/1\">Ehsan Mokhtarian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbari_S/0/1/0/all/0/1\">Sina Akbari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassami_A/0/1/0/all/0/1\">AmirEmad Ghassami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiyavash_N/0/1/0/all/0/1\">Negar Kiyavash</a>",
          "description": "Constraint-based methods are one of the main approaches for causal structure\nlearning that are particularly valued as they are asymptotically guaranteed to\nfind a structure that is Markov equivalent to the causal graph of the system.\nOn the other hand, they may require an exponentially large number of\nconditional independence (CI) tests in the number of variables of the system.\nIn this paper, we propose a novel recursive constraint-based method for causal\nstructure learning that significantly reduces the required number of CI tests\ncompared to the existing literature. The idea of the proposed approach is to\nuse Markov boundary information to identify a specific variable that can be\nremoved from the set of variables without affecting the statistical\ndependencies among the other variables. Having identified such a variable, we\ndiscover its neighborhood, remove that variable from the set of variables, and\nrecursively learn the causal structure over the remaining variables. We further\nprovide a lower bound on the number of CI tests required by any\nconstraint-based method. Comparing this lower bound to our achievable bound\ndemonstrates the efficiency of the proposed approach. Our experimental results\nshow that the proposed algorithm outperforms state-of-the-art both on synthetic\nand real-world structures.",
          "link": "http://arxiv.org/abs/2010.04992",
          "publishedOn": "2021-05-24T07:23:04.745Z",
          "wordCount": 676,
          "title": "A Recursive Markov Boundary-Based Approach to Causal Structure Learning. (arXiv:2010.04992v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.05617",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tufano_M/0/1/0/all/0/1\">Michele Tufano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1\">Dawn Drain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svyatkovskiy_A/0/1/0/all/0/1\">Alexey Svyatkovskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shao Kun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1\">Neel Sundaresan</a>",
          "description": "Automated unit test case generation tools facilitate test-driven development\nand support developers by suggesting tests intended to identify flaws in their\ncode. Existing approaches are usually guided by the test coverage criteria,\ngenerating synthetic test cases that are often difficult for developers to read\nor understand. In this paper we propose AthenaTest, an approach that aims to\ngenerate unit test cases by learning from real-world focal methods and\ndeveloper-written testcases. We formulate unit test case generation as a\nsequence-to-sequence learning task, adopting a two-step training procedure\nconsisting of denoising pretraining on a large unsupervised Java corpus, and\nsupervised finetuning for a downstream translation task of generating unit\ntests. We investigate the impact of natural language and source code\npretraining, as well as the focal context information surrounding the focal\nmethod. Both techniques provide improvements in terms of validation loss, with\npretraining yielding 25% relative improvement and focal context providing\nadditional 11.1% improvement. We also introduce Methods2Test, the largest\npublicly available supervised parallel corpus of unit test case methods and\ncorresponding focal methods in Java, which comprises 780K test cases mined from\n91K open-source repositories from GitHub. We evaluate AthenaTest on five\ndefects4j projects, generating 25K passing test cases covering 43.7% of the\nfocal methods with only 30 attempts. We execute the test cases, collect test\ncoverage information, and compare them with test cases generated by EvoSuite\nand GPT-3, finding that our approach outperforms GPT-3 and has comparable\ncoverage w.r.t. EvoSuite. Finally, we survey professional developers on their\npreference in terms of readability, understandability, and testing\neffectiveness of the generated tests, showing overwhelmingly preference towards\nAthenaTest.",
          "link": "http://arxiv.org/abs/2009.05617",
          "publishedOn": "2021-05-24T07:23:04.739Z",
          "wordCount": 731,
          "title": "Unit Test Case Generation with Transformers and Focal Context. (arXiv:2009.05617v2 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1908.06077",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramezani_Kebrya_A/0/1/0/all/0/1\">Ali Ramezani-Kebrya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faghri_F/0/1/0/all/0/1\">Fartash Faghri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1\">Ilya Markov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aksenov_V/0/1/0/all/0/1\">Vitalii Aksenov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1\">Daniel M. Roy</a>",
          "description": "As the size and complexity of models and datasets grow, so does the need for\ncommunication-efficient variants of stochastic gradient descent that can be\ndeployed to perform parallel model training. One popular\ncommunication-compression method for data-parallel SGD is QSGD (Alistarh et\nal., 2017), which quantizes and encodes gradients to reduce communication\ncosts. The baseline variant of QSGD provides strong theoretical guarantees,\nhowever, for practical purposes, the authors proposed a heuristic variant which\nwe call QSGDinf, which demonstrated impressive empirical gains for distributed\ntraining of large neural networks. In this paper, we build on this work to\npropose a new gradient quantization scheme, and show that it has both stronger\ntheoretical guarantees than QSGD, and matches and exceeds the empirical\nperformance of the QSGDinf heuristic and of other compression methods.",
          "link": "http://arxiv.org/abs/1908.06077",
          "publishedOn": "2021-05-24T07:23:04.733Z",
          "wordCount": 607,
          "title": "NUQSGD: Provably Communication-efficient Data-parallel SGD via Nonuniform Quantization. (arXiv:1908.06077v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10424",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hufei Zhu</a>",
          "description": "The existing low-memory BLS implementation proposed recently avoids the need\nfor storing and inverting large matrices, to achieve efficient usage of\nmemories. However, the existing low-memory BLS implementation sacrifices the\ntesting accuracy as a price for efficient usage of memories, since it can no\nlonger obtain the generalized inverse or ridge solution for the output weights\nduring incremental learning, and it cannot work under the very small ridge\nparameter that is utilized in the original BLS. Accordingly, it is required to\ndevelop the low-memory BLS implementations, which can work under very small\nridge parameters and compute the generalized inverse or ridge solution for the\noutput weights in the process of incremental learning. In this paper, firstly\nwe propose the low-memory implementations for the recently proposed recursive\nand square-root BLS algorithms on added inputs and the recently proposed\nsquareroot BLS algorithm on added nodes, by simply processing a batch of inputs\nor nodes in each recursion. Since the recursive BLS implementation includes the\nrecursive updates of the inverse matrix that may introduce numerical\ninstabilities after a large number of iterations, and needs the extra\ncomputational load to decompose the inverse matrix into the Cholesky factor\nwhen cooperating with the proposed low-memory implementation of the square-root\nBLS algorithm on added nodes, we only improve the low-memory implementations of\nthe square-root BLS algorithms on added inputs and nodes, to propose the full\nlowmemory implementation of the square-root BLS algorithm. All the proposed\nlow-memory BLS implementations compute the ridge solution for the output\nweights in the process of incremental learning, and most of them can work under\nvery small ridge parameters.",
          "link": "http://arxiv.org/abs/2105.10424",
          "publishedOn": "2021-05-24T07:23:04.714Z",
          "wordCount": 694,
          "title": "Low-Memory Implementations of Ridge Solutions for Broad Learning System with Incremental Learning. (arXiv:2105.10424v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10350",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drton_M/0/1/0/all/0/1\">Mathias Drton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shojaie_A/0/1/0/all/0/1\">Ali Shojaie</a>",
          "description": "In causal graphical models based on directed acyclic graphs (DAGs), directed\npaths represent causal pathways between the corresponding variables. The\nvariable at the beginning of such a path is referred to as an ancestor of the\nvariable at the end of the path. Ancestral relations between variables play an\nimportant role in causal modeling. In existing literature on structure\nlearning, these relations are usually deduced from learned structures and used\nfor orienting edges or formulating constraints of the space of possible DAGs.\nHowever, they are usually not posed as immediate target of inference. In this\nwork we investigate the graphical characterization of ancestral relations via\nCPDAGs and d-separation relations. We propose a framework that can learn\ndefinite non-ancestral relations without first learning the skeleton. This\nframe-work yields structural information that can be used in both score- and\nconstraint-based algorithms to learn causal DAGs more efficiently.",
          "link": "http://arxiv.org/abs/2105.10350",
          "publishedOn": "2021-05-24T07:23:04.709Z",
          "wordCount": 567,
          "title": "Definite Non-Ancestral Relations and Structure Learning. (arXiv:2105.10350v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.15789",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1\">Jianwei Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xun Chen</a>",
          "description": "Train machine learning models on sensitive user data has raised increasing\nprivacy concerns in many areas. Federated learning is a popular approach for\nprivacy protection that collects the local gradient information instead of real\ndata. One way to achieve a strict privacy guarantee is to apply local\ndifferential privacy into federated learning. However, previous works do not\ngive a practical solution due to three issues. First, the noisy data is close\nto its original value with high probability, increasing the risk of information\nexposure. Second, a large variance is introduced to the estimated average,\ncausing poor accuracy. Last, the privacy budget explodes due to the high\ndimensionality of weights in deep learning models. In this paper, we proposed a\nnovel design of local differential privacy mechanism for federated learning to\naddress the abovementioned issues. It is capable of making the data more\ndistinct from its original value and introducing lower variance. Moreover, the\nproposed mechanism bypasses the curse of dimensionality by splitting and\nshuffling model updates. A series of empirical evaluations on three commonly\nused datasets, MNIST, Fashion-MNIST and CIFAR-10, demonstrate that our solution\ncan not only achieve superior deep learning performance but also provide a\nstrong privacy guarantee at the same time.",
          "link": "http://arxiv.org/abs/2007.15789",
          "publishedOn": "2021-05-24T07:23:04.703Z",
          "wordCount": 670,
          "title": "LDP-FL: Practical Private Aggregation in Federated Learning with Local Differential Privacy. (arXiv:2007.15789v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.08899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vipul Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhary_D/0/1/0/all/0/1\">Dhruv Choudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_P/0/1/0/all/0/1\">Ping Tak Peter Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiaohan Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuzhen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kejariwal_A/0/1/0/all/0/1\">Arun Kejariwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramchandran_K/0/1/0/all/0/1\">Kannan Ramchandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1\">Michael W. Mahoney</a>",
          "description": "In this paper, we consider hybrid parallelism -- a paradigm that employs both\nData Parallelism (DP) and Model Parallelism (MP) -- to scale distributed\ntraining of large recommendation models. We propose a compression framework\ncalled Dynamic Communication Thresholding (DCT) for communication-efficient\nhybrid training. DCT filters the entities to be communicated across the network\nthrough a simple hard-thresholding function, allowing only the most relevant\ninformation to pass through. For communication efficient DP, DCT compresses the\nparameter gradients sent to the parameter server during model synchronization.\nThe threshold is updated only once every few thousand iterations to reduce the\ncomputational overhead of compression. For communication efficient MP, DCT\nincorporates a novel technique to compress the activations and gradients sent\nacross the network during the forward and backward propagation, respectively.\nThis is done by identifying and updating only the most relevant neurons of the\nneural network for each training sample in the data. We evaluate DCT on\npublicly available natural language processing and recommender models and\ndatasets, as well as recommendation systems used in production at Facebook. DCT\nreduces communication by at least $100\\times$ and $20\\times$ during DP and MP,\nrespectively. The algorithm has been deployed in production, and it improves\nend-to-end training time for a state-of-the-art industrial recommender model by\n37\\%, without any loss in performance.",
          "link": "http://arxiv.org/abs/2010.08899",
          "publishedOn": "2021-05-24T07:23:04.696Z",
          "wordCount": 713,
          "title": "Training Recommender Systems at Scale: Communication-Efficient Model and Data Parallelism. (arXiv:2010.08899v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.10013",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Franci_B/0/1/0/all/0/1\">Barbara Franci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grammatico_S/0/1/0/all/0/1\">Sergio Grammatico</a>",
          "description": "Generative adversarial networks (GANs) are a class of generative models with\ntwo antagonistic neural networks: a generator and a discriminator. These two\nneural networks compete against each other through an adversarial process that\ncan be modeled as a stochastic Nash equilibrium problem. Since the associated\ntraining process is challenging, it is fundamental to design reliable\nalgorithms to compute an equilibrium. In this paper, we propose a stochastic\nrelaxed forward-backward (SRFB) algorithm for GANs and we show convergence to\nan exact solution when an increasing number of data is available. We also show\nconvergence of an averaged variant of the SRFB algorithm to a neighborhood of\nthe solution when only few samples are available. In both cases, convergence is\nguaranteed when the pseudogradient mapping of the game is monotone. This\nassumption is among the weakest known in the literature. Moreover, we apply our\nalgorithm to the image generation problem.",
          "link": "http://arxiv.org/abs/2010.10013",
          "publishedOn": "2021-05-24T07:23:04.685Z",
          "wordCount": 626,
          "title": "Training Generative Adversarial Networks via stochastic Nash games. (arXiv:2010.10013v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10065",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1\">Xin Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1\">Diego Klabjan</a>",
          "description": "Neural network pruning techniques reduce the number of parameters without\ncompromising predicting ability of a network. Many algorithms have been\ndeveloped for pruning both over-parameterized fully-connected networks (FCNs)\nand convolutional neural networks (CNNs), but analytical studies of\ncapabilities and compression ratios of such pruned sub-networks are lacking. We\ntheoretically study the performance of two pruning techniques (random and\nmagnitude-based) on FCNs and CNNs. Given a target network {whose weights are\nindependently sampled from appropriate distributions}, we provide a universal\napproach to bound the gap between a pruned and the target network in a\nprobabilistic sense. The results establish that there exist pruned networks\nwith expressive power within any specified bound from the target network.",
          "link": "http://arxiv.org/abs/2105.10065",
          "publishedOn": "2021-05-24T07:23:04.666Z",
          "wordCount": 531,
          "title": "A Probabilistic Approach to Neural Network Pruning. (arXiv:2105.10065v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2004.08614",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_K/0/1/0/all/0/1\">Kuldeep Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokhale_T/0/1/0/all/0/1\">Tejas Gokhale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rajhans Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turaga_P/0/1/0/all/0/1\">Pavan Turaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankaranarayanan_A/0/1/0/all/0/1\">Aswin Sankaranarayanan</a>",
          "description": "Recently, there has been substantial progress in image synthesis from\nsemantic labelmaps. However, methods used for this task assume the availability\nof complete and unambiguous labelmaps, with instance boundaries of objects, and\nclass labels for each pixel. This reliance on heavily annotated inputs\nrestricts the application of image synthesis techniques to real-world\napplications, especially under uncertainty due to weather, occlusion, or noise.\nOn the other hand, algorithms that can synthesize images from sparse labelmaps\nor sketches are highly desirable as tools that can guide content creators and\nartists to quickly generate scenes by simply specifying locations of a few\nobjects. In this paper, we address the problem of complex scene completion from\nsparse labelmaps. Under this setting, very few details about the scene (30\\% of\nobject instances) are available as input for image synthesis. We propose a\ntwo-stage deep network based method, called `Halluci-Net', that learns\nco-occurence relationships between objects in scenes, and then exploits these\nrelationships to produce a dense and complete labelmap. The generated dense\nlabelmap can then be used as input by state-of-the-art image synthesis\ntechniques like pix2pixHD to obtain the final image. The proposed method is\nevaluated on the Cityscapes dataset and it outperforms two baselines methods on\nperformance metrics like Fr\\'echet Inception Distance (FID), semantic\nsegmentation accuracy, and similarity in object co-occurrences. We also show\nqualitative results on a subset of ADE20K dataset that contains bedroom images.",
          "link": "http://arxiv.org/abs/2004.08614",
          "publishedOn": "2021-05-24T07:23:04.660Z",
          "wordCount": 709,
          "title": "Halluci-Net: Scene Completion by Exploiting Object Co-occurrence Relationships. (arXiv:2004.08614v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2009.05537",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1\">Lingjuan Lyu</a>",
          "description": "Conventional federated learning directly averages model weights, which is\nonly possible for collaboration between models with homogeneous architectures.\nSharing prediction instead of weight removes this obstacle and eliminates the\nrisk of white-box inference attacks in conventional federated learning.\nHowever, the predictions from local models are sensitive and would leak\ntraining data privacy to the public. To address this issue, one naive approach\nis adding the differentially private random noise to the predictions, which\nhowever brings a substantial trade-off between privacy budget and model\nperformance. In this paper, we propose a novel framework called FEDMD-NFDP,\nwhich applies a Noise-Free Differential Privacy (NFDP) mechanism into a\nfederated model distillation framework. Our extensive experimental results on\nvarious datasets validate that FEDMD-NFDP can deliver not only comparable\nutility and communication efficiency but also provide a noise-free differential\nprivacy guarantee. We also demonstrate the feasibility of our FEDMD-NFDP by\nconsidering both IID and non-IID setting, heterogeneous model architectures,\nand unlabelled public datasets from a different distribution.",
          "link": "http://arxiv.org/abs/2009.05537",
          "publishedOn": "2021-05-24T07:23:04.655Z",
          "wordCount": 621,
          "title": "Federated Model Distillation with Noise-Free Differential Privacy. (arXiv:2009.05537v2 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1804.07209",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ciccone_M/0/1/0/all/0/1\">Marco Ciccone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallieri_M/0/1/0/all/0/1\">Marco Gallieri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masci_J/0/1/0/all/0/1\">Jonathan Masci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osendorfer_C/0/1/0/all/0/1\">Christian Osendorfer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_F/0/1/0/all/0/1\">Faustino Gomez</a>",
          "description": "This paper introduces Non-Autonomous Input-Output Stable Network(NAIS-Net), a\nvery deep architecture where each stacked processing block is derived from a\ntime-invariant non-autonomous dynamical system. Non-autonomy is implemented by\nskip connections from the block input to each of the unrolled processing stages\nand allows stability to be enforced so that blocks can be unrolled adaptively\nto a pattern-dependent processing depth. NAIS-Net induces non-trivial,\nLipschitz input-output maps, even for an infinite unroll length. We prove that\nthe network is globally asymptotically stable so that for every initial\ncondition there is exactly one input-dependent equilibrium assuming $tanh$\nunits, and incrementally stable for ReL units. An efficient implementation that\nenforces the stability under derived conditions for both fully-connected and\nconvolutional layers is also presented. Experimental results show how NAIS-Net\nexhibits stability in practice, yielding a significant reduction in\ngeneralization gap compared to ResNets.",
          "link": "http://arxiv.org/abs/1804.07209",
          "publishedOn": "2021-05-24T07:23:04.648Z",
          "wordCount": 642,
          "title": "NAIS-Net: Stable Deep Networks from Non-Autonomous Differential Equations. (arXiv:1804.07209v4 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10288",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ayazoglu_M/0/1/0/all/0/1\">Mustafa Ayazoglu</a>",
          "description": "Single-Image Super Resolution (SISR) is a classical computer vision problem\nand it has been studied for over decades. With the recent success of deep\nlearning methods, recent work on SISR focuses solutions with deep learning\nmethodologies and achieves state-of-the-art results. However most of the\nstate-of-the-art SISR methods contain millions of parameters and layers, which\nlimits their practical applications. In this paper, we propose a hardware\n(Synaptics Dolphin NPU) limitation aware, extremely lightweight quantization\nrobust real-time super resolution network (XLSR). The proposed model's building\nblock is inspired from root modules for Image classification. We successfully\napplied root modules to SISR problem, further more to make the model uint8\nquantization robust we used Clipped ReLU at the last layer of the network and\nachieved great balance between reconstruction quality and runtime. Furthermore,\nalthough the proposed network contains 30x fewer parameters than VDSR its\nperformance surpasses it on Div2K validation set. The network proved itself by\nwinning Mobile AI 2021 Real-Time Single Image Super Resolution Challenge.",
          "link": "http://arxiv.org/abs/2105.10288",
          "publishedOn": "2021-05-24T07:23:04.641Z",
          "wordCount": 619,
          "title": "Extremely Lightweight Quantization Robust Real-Time Single-Image Super Resolution for Mobile Devices. (arXiv:2105.10288v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2005.14605",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Borysenko_O/0/1/0/all/0/1\">Oleksandr Borysenko</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Byshkin_M/0/1/0/all/0/1\">Maksym Byshkin</a>",
          "description": "Deep learning applications require global optimization of non-convex\nobjective functions, which have multiple local minima. The same problem is\noften found in physical simulations and may be resolved by the methods of\nLangevin dynamics with Simulated Annealing, which is a well-established\napproach for minimization of many-particle potentials. This analogy provides\nuseful insights for non-convex stochastic optimization in machine learning.\nHere we find that integration of the discretized Langevin equation gives a\ncoordinate updating rule equivalent to the famous Momentum optimization\nalgorithm. As a main result, we show that a gradual decrease of the momentum\ncoefficient from the initial value close to unity until zero is equivalent to\napplication of Simulated Annealing or slow cooling, in physical terms. Making\nuse of this novel approach, we propose CoolMomentum -- a new stochastic\noptimization method. Applying Coolmomentum to optimization of Resnet-20 on\nCifar-10 dataset and Efficientnet-B0 on Imagenet, we demonstrate that it is\nable to achieve high accuracies.",
          "link": "http://arxiv.org/abs/2005.14605",
          "publishedOn": "2021-05-24T07:23:04.635Z",
          "wordCount": 637,
          "title": "CoolMomentum: A Method for Stochastic Optimization by Langevin Dynamics with Simulated Annealing. (arXiv:2005.14605v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10172",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Beckh_K/0/1/0/all/0/1\">Katharina Beckh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_S/0/1/0/all/0/1\">Sebastian M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakobs_M/0/1/0/all/0/1\">Matthias Jakobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toborek_V/0/1/0/all/0/1\">Vanessa Toborek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1\">Hanxiao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_R/0/1/0/all/0/1\">Raphael Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welke_P/0/1/0/all/0/1\">Pascal Welke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houben_S/0/1/0/all/0/1\">Sebastian Houben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rueden_L/0/1/0/all/0/1\">Laura von Rueden</a>",
          "description": "This survey presents an overview of integrating prior knowledge into machine\nlearning systems in order to improve explainability. The complexity of machine\nlearning models has elicited research to make them more explainable. However,\nmost explainability methods cannot provide insight beyond the given data,\nrequiring additional information about the context. We propose to harness prior\nknowledge to improve upon the explanation capabilities of machine learning\nmodels. In this paper, we present a categorization of current research into\nthree main categories which either integrate knowledge into the machine\nlearning pipeline, into the explainability method or derive knowledge from\nexplanations. To classify the papers, we build upon the existing taxonomy of\ninformed machine learning and extend it from the perspective of explainability.\nWe conclude with open challenges and research directions.",
          "link": "http://arxiv.org/abs/2105.10172",
          "publishedOn": "2021-05-24T07:23:04.617Z",
          "wordCount": 562,
          "title": "Explainable Machine Learning with Prior Knowledge: An Overview. (arXiv:2105.10172v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10302",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tabanelli_E/0/1/0/all/0/1\">Enrico Tabanelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunelli_D/0/1/0/all/0/1\">Davide Brunelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acquaviva_A/0/1/0/all/0/1\">Andrea Acquaviva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1\">Luca Benini</a>",
          "description": "Non-Intrusive Load Monitoring (NILM) enables the disaggregation of the global\npower consumption of multiple loads, taken from a single smart electrical\nmeter, into appliance-level details. State-of-the-Art approaches are based on\nMachine Learning methods and exploit the fusion of time- and frequency-domain\nfeatures from current and voltage sensors. Unfortunately, these methods are\ncompute-demanding and memory-intensive. Therefore, running low-latency NILM on\nlow-cost, resource-constrained MCU-based meters is currently an open challenge.\nThis paper addresses the optimization of the feature spaces as well as the\ncomputational and storage cost reduction needed for executing State-of-the-Art\n(SoA) NILM algorithms on memory- and compute-limited MCUs. We compare four\nsupervised learning techniques on different classification scenarios and\ncharacterize the overall NILM pipeline's implementation on a MCU-based Smart\nMeasurement Node. Experimental results demonstrate that optimizing the feature\nspace enables edge MCU-based NILM with 95.15% accuracy, resulting in a small\ndrop compared to the most-accurate feature vector deployment (96.19%) while\nachieving up to 5.45x speed-up and 80.56% storage reduction. Furthermore, we\nshow that low-latency NILM relying only on current measurements reaches almost\n80% accuracy, allowing a major cost reduction by removing voltage sensors from\nthe hardware design.",
          "link": "http://arxiv.org/abs/2105.10302",
          "publishedOn": "2021-05-24T07:23:04.611Z",
          "wordCount": 628,
          "title": "Trimming Feature Extraction and Inference for MCU-based Edge NILM: a Systematic Approach. (arXiv:2105.10302v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10439",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Lin_A/0/1/0/all/0/1\">Alexander Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_A/0/1/0/all/0/1\">Andrew H. Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bilgic_B/0/1/0/all/0/1\">Berkin Bilgic</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ba_D/0/1/0/all/0/1\">Demba Ba</a>",
          "description": "Sparse Bayesian learning (SBL) is a powerful framework for tackling the\nsparse coding problem while also providing uncertainty quantification. However,\nthe most popular inference algorithms for SBL become too expensive for\nhigh-dimensional problems due to the need to maintain a large covariance\nmatrix. To resolve this issue, we introduce a new SBL inference algorithm that\navoids explicit computation of the covariance matrix, thereby saving\nsignificant time and space. Instead of performing costly matrix inversions, our\ncovariance-free method solves multiple linear systems to obtain provably\nunbiased estimates of the posterior statistics needed by SBL. These systems can\nbe solved in parallel, enabling further acceleration of the algorithm via\ngraphics processing units. In practice, our method can be up to thousands of\ntimes faster than existing baselines, reducing hours of computation time to\nseconds. We showcase how our new algorithm enables SBL to tractably tackle\nhigh-dimensional signal recovery problems, such as deconvolution of calcium\nimaging data and multi-contrast reconstruction of magnetic resonance images.\nFinally, we open-source a toolbox containing all of our implementations to\ndrive future research in SBL.",
          "link": "http://arxiv.org/abs/2105.10439",
          "publishedOn": "2021-05-24T07:23:04.604Z",
          "wordCount": 609,
          "title": "Covariance-Free Sparse Bayesian Learning. (arXiv:2105.10439v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1\">Kwan Ho Ryan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chong You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Haozhi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1\">John Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>",
          "description": "This work attempts to provide a plausible theoretical framework that aims to\ninterpret modern deep (convolutional) networks from the principles of data\ncompression and discriminative representation. We show that for\nhigh-dimensional multi-class data, the optimal linear discriminative\nrepresentation maximizes the coding rate difference between the whole dataset\nand the average of all the subsets. We show that the basic iterative gradient\nascent scheme for optimizing the rate reduction objective naturally leads to a\nmulti-layer deep network, named ReduNet, that shares common characteristics of\nmodern deep networks. The deep layered architectures, linear and nonlinear\noperators, and even parameters of the network are all explicitly constructed\nlayer-by-layer via forward propagation, instead of learned via back\npropagation. All components of so-obtained \"white-box\" network have precise\noptimization, statistical, and geometric interpretation. Moreover, all linear\noperators of the so-derived network naturally become multi-channel convolutions\nwhen we enforce classification to be rigorously shift-invariant. The derivation\nalso indicates that such a deep convolution network is significantly more\nefficient to construct and learn in the spectral domain. Our preliminary\nsimulations and experiments clearly verify the effectiveness of both the rate\nreduction objective and the associated ReduNet. All code and data are available\nat https://github.com/Ma-Lab-Berkeley.",
          "link": "http://arxiv.org/abs/2105.10446",
          "publishedOn": "2021-05-24T07:23:04.598Z",
          "wordCount": 672,
          "title": "ReduNet: A White-box Deep Network from the Principle of Maximizing Rate Reduction. (arXiv:2105.10446v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Real_R/0/1/0/all/0/1\">Ric Real</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopsill_J/0/1/0/all/0/1\">James Gopsill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_D/0/1/0/all/0/1\">David Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snider_C/0/1/0/all/0/1\">Chris Snider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hicks_B/0/1/0/all/0/1\">Ben Hicks</a>",
          "description": "Prior work has shown Convolutional Neural Networks (CNNs) trained on\nsurrogate Computer Aided Design (CAD) models are able to detect and classify\nreal-world artefacts from photographs. The applications of which support\ntwinning of digital and physical assets in design, including rapid extraction\nof part geometry from model repositories, information search \\& retrieval and\nidentifying components in the field for maintenance, repair, and recording. The\nperformance of CNNs in classification tasks have been shown dependent on\ntraining data set size and number of classes. Where prior works have used\nrelatively small surrogate model data sets ($<100$ models), the question\nremains as to the ability of a CNN to differentiate between models in\nincreasingly large model repositories. This paper presents a method for\ngenerating synthetic image data sets from online CAD model repositories, and\nfurther investigates the capacity of an off-the-shelf CNN architecture trained\non synthetic data to classify models as class size increases. 1,000 CAD models\nwere curated and processed to generate large scale surrogate data sets,\nfeaturing model coverage at steps of 10$^{\\circ}$, 30$^{\\circ}$, 60$^{\\circ}$,\nand 120$^{\\circ}$ degrees. The findings demonstrate the capability of computer\nvision algorithms to classify artefacts in model repositories of up to 200,\nbeyond this point the CNN's performance is observed to deteriorate\nsignificantly, limiting its present ability for automated twinning of physical\nto digital artefacts. Although, a match is more often found in the top-5\nresults showing potential for information search and retrieval on large\nrepositories of surrogate models.",
          "link": "http://arxiv.org/abs/2105.10448",
          "publishedOn": "2021-05-24T07:23:04.556Z",
          "wordCount": 704,
          "title": "Distinguishing artefacts: evaluating the saturation point of convolutional neural networks. (arXiv:2105.10448v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10497",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1\">Muzammal Naseer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1\">Kanchana Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Salman Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1\">Munawar Hayat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahad Shahbaz Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Ming-Hsuan Yang</a>",
          "description": "Vision transformers (ViT) have demonstrated impressive performance across\nvarious machine vision problems. These models are based on multi-head\nself-attention mechanisms that can flexibly attend to a sequence of image\npatches to encode contextual cues. An important question is how such\nflexibility in attending image-wide context conditioned on a given patch can\nfacilitate handling nuisances in natural images e.g., severe occlusions, domain\nshifts, spatial permutations, adversarial and natural perturbations. We\nsystematically study this question via an extensive set of experiments\nencompassing three ViT families and comparisons with a high-performing\nconvolutional neural network (CNN). We show and analyze the following\nintriguing properties of ViT: (a) Transformers are highly robust to severe\nocclusions, perturbations and domain shifts, e.g., retain as high as 60% top-1\naccuracy on ImageNet even after randomly occluding 80% of the image content.\n(b) The robust performance to occlusions is not due to a bias towards local\ntextures, and ViTs are significantly less biased towards textures compared to\nCNNs. When properly trained to encode shape-based features, ViTs demonstrate\nshape recognition capability comparable to that of human visual system,\npreviously unmatched in the literature. (c) Using ViTs to encode shape\nrepresentation leads to an interesting consequence of accurate semantic\nsegmentation without pixel-level supervision. (d) Off-the-shelf features from a\nsingle ViT model can be combined to create a feature ensemble, leading to high\naccuracy rates across a range of classification datasets in both traditional\nand few-shot learning paradigms. We show effective features of ViTs are due to\nflexible and dynamic receptive fields possible via the self-attention\nmechanism.",
          "link": "http://arxiv.org/abs/2105.10497",
          "publishedOn": "2021-05-24T07:23:04.545Z",
          "wordCount": 698,
          "title": "Intriguing Properties of Vision Transformers. (arXiv:2105.10497v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2006.14709",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Goldt_S/0/1/0/all/0/1\">Sebastian Goldt</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Loureiro_B/0/1/0/all/0/1\">Bruno Loureiro</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Reeves_G/0/1/0/all/0/1\">Galen Reeves</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krzakala_F/0/1/0/all/0/1\">Florent Krzakala</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Mezard_M/0/1/0/all/0/1\">Marc M&#xe9;zard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zdeborova_L/0/1/0/all/0/1\">Lenka Zdeborov&#xe1;</a>",
          "description": "Understanding the impact of data structure on the computational tractability\nof learning is a key challenge for the theory of neural networks. Many\ntheoretical works do not explicitly model training data, or assume that inputs\nare drawn component-wise independently from some simple probability\ndistribution. Here, we go beyond this simple paradigm by studying the\nperformance of neural networks trained on data drawn from pre-trained\ngenerative models. This is possible due to a Gaussian equivalence stating that\nthe key metrics of interest, such as the training and test errors, can be fully\ncaptured by an appropriately chosen Gaussian model. We provide three strands of\nrigorous, analytical and numerical evidence corroborating this equivalence.\nFirst, we establish rigorous conditions for the Gaussian equivalence to hold in\nthe case of single-layer generative models, as well as deterministic rates for\nconvergence in distribution. Second, we leverage this equivalence to derive a\nclosed set of equations describing the generalisation performance of two widely\nstudied machine learning problems: two-layer neural networks trained using\none-pass stochastic gradient descent, and full-batch pre-learned features or\nkernel methods. Finally, we perform experiments demonstrating how our theory\napplies to deep, pre-trained generative models. These results open a viable\npath to the theoretical study of machine learning models with realistic data.",
          "link": "http://arxiv.org/abs/2006.14709",
          "publishedOn": "2021-05-24T07:23:04.539Z",
          "wordCount": 699,
          "title": "The Gaussian equivalence of generative models for learning with shallow neural networks. (arXiv:2006.14709v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2005.14708",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Raut_P/0/1/0/all/0/1\">Prasanna Sanjay Raut</a>, <a href=\"http://arxiv.org/find/math/1/au:+Sadeghi_O/0/1/0/all/0/1\">Omid Sadeghi</a>, <a href=\"http://arxiv.org/find/math/1/au:+Fazel_M/0/1/0/all/0/1\">Maryam Fazel</a>",
          "description": "In this paper, we consider online continuous DR-submodular maximization with\nlinear stochastic long-term constraints. Compared to the prior work on online\nsubmodular maximization, our setting introduces the extra complication of\nstochastic linear constraint functions that are i.i.d. generated at each round.\nTo be precise, at step $t\\in\\{1,\\dots,T\\}$, a DR-submodular utility function\n$f_t(\\cdot)$ and a constraint vector $p_t$, i.i.d. generated from an unknown\ndistribution with mean $p$, are revealed after committing to an action $x_t$\nand we aim to maximize the overall utility while the expected cumulative\nresource consumption $\\sum_{t=1}^T \\langle p,x_t\\rangle$ is below a fixed\nbudget $B_T$. Stochastic long-term constraints arise naturally in applications\nwhere there is a limited budget or resource available and resource consumption\nat each step is governed by stochastically time-varying environments. We\npropose the Online Lagrangian Frank-Wolfe (OLFW) algorithm to solve this class\nof online problems. We analyze the performance of the OLFW algorithm and we\nobtain sub-linear regret bounds as well as sub-linear cumulative constraint\nviolation bounds, both in expectation and with high probability.",
          "link": "http://arxiv.org/abs/2005.14708",
          "publishedOn": "2021-05-24T07:23:04.531Z",
          "wordCount": 636,
          "title": "Online DR-Submodular Maximization with Stochastic Cumulative Constraints. (arXiv:2005.14708v3 [math.OC] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.13300",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Thapa_C/0/1/0/all/0/1\">Chandra Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jun Wen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abuadbba_A/0/1/0/all/0/1\">Alsharif Abuadbba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yansong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camtepe_S/0/1/0/all/0/1\">Seyit Camtepe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nepal_S/0/1/0/all/0/1\">Surya Nepal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almashor_M/0/1/0/all/0/1\">Mahathir Almashor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yifeng Zheng</a>",
          "description": "The use of Artificial Intelligence (AI) to detect phishing emails is\nprimarily dependent on large-scale centralized datasets, which opens it up to a\nmyriad of privacy, trust, and legal issues. Moreover, organizations are loathed\nto share emails, given the risk of leakage of commercially sensitive\ninformation. So, it is uncommon to obtain sufficient emails to train a global\nAI model efficiently. Accordingly, privacy-preserving distributed and\ncollaborative machine learning, particularly Federated Learning (FL), is a\ndesideratum. Already prevalent in the healthcare sector, questions remain\nregarding the effectiveness and efficacy of FL-based phishing detection within\nthe context of multi-organization collaborations. To the best of our knowledge,\nthe work herein is the first to investigate the use of FL in email\nanti-phishing. This paper builds upon a deep neural network model, particularly\nRNN and BERT for phishing email detection. It analyzes the FL-entangled\nlearning performance under various settings, including balanced and\nasymmetrical data distribution. Our results corroborate comparable performance\nstatistics of FL in phishing email detection to centralized learning for\nbalanced datasets, and low organization counts. Moreover, we observe a\nvariation in performance when increasing organizational counts. For a fixed\ntotal email dataset, the global RNN based model suffers by a 1.8% accuracy drop\nwhen increasing organizational counts from 2 to 10. In contrast, BERT accuracy\nrises by 0.6% when going from 2 to 5 organizations. However, if we allow\nincreasing the overall email dataset with the introduction of new organizations\nin the FL framework, the organizational level performance is improved by\nachieving a faster convergence speed. Besides, FL suffers in its overall global\nmodel performance due to highly unstable outputs if the email dataset\ndistribution is highly asymmetric.",
          "link": "http://arxiv.org/abs/2007.13300",
          "publishedOn": "2021-05-24T07:23:04.522Z",
          "wordCount": 756,
          "title": "Evaluation of Federated Learning in Phishing Email Detection. (arXiv:2007.13300v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10018",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Manjanna_S/0/1/0/all/0/1\">Sandeep Manjanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_A/0/1/0/all/0/1\">Ani Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1\">Gregory Dudek</a>",
          "description": "This paper presents a distributed scalable multi-robot planning algorithm for\nnon-uniform sampling of quasi-static spatial fields. We address the problem of\nefficient data collection using multiple autonomous vehicles. In this paper, we\nare interested in analyzing the effect of communication between multiple\nrobots, acting independently, on the overall sampling performance of the team.\nOur focus is on distributed sampling problem where the robots are operating\nindependent of their teammates, but have the ability to communicate their\nstates to other neighbors with a constraint on the communication range. We\ndesign and apply an informed non-myopic path planning technique on multiple\nrobotic platforms to efficiently collect measurements from a spatial field. Our\nproposed approach is highly adaptive to challenging environments, growing team\nsize, and runs in real-time, which are the key features for any real-world\nscenario. The results show that our distributed sampling approach is able to\nachieve efficient sampling with minimal communication between the robots. We\nevaluate our approach in simulation over multiple distributions commonly\noccurring in nature and on the real-world data collected during a field trial.",
          "link": "http://arxiv.org/abs/2105.10018",
          "publishedOn": "2021-05-24T07:23:04.505Z",
          "wordCount": 613,
          "title": "Scalable Multi-Robot System for Non-myopic Spatial Sampling. (arXiv:2105.10018v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10377",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Apicella_A/0/1/0/all/0/1\">Andrea Apicella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isgro_F/0/1/0/all/0/1\">Francesco Isgr&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollastro_A/0/1/0/all/0/1\">Andrea Pollastro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prevete_R/0/1/0/all/0/1\">Roberto Prevete</a>",
          "description": "Over the last few years, we have seen increasing data generated from\nnon-Euclidean domains, which are usually represented as graphs with complex\nrelationships, and Graph Neural Networks (GNN) have gained a high interest\nbecause of their potential in processing graph-structured data. In particular,\nthere is a strong interest in exploring the possibilities in performing\nconvolution on graphs using an extension of the GNN architecture, generally\nreferred to as Graph Convolutional Neural Networks (GCNN). Convolution on\ngraphs has been achieved mainly in two forms: spectral and spatial\nconvolutions. Due to the higher flexibility in exploring and exploiting the\ngraph structure of data, recently, there is an increasing interest in\ninvestigating the possibilities that the spatial approach can offer. The idea\nof finding a way to adapt the network behaviour to the inputs they process to\nmaximize the total performances has aroused much interest in the neural\nnetworks literature over the years. This paper presents a novel method to adapt\nthe behaviour of a GCNN to the input proposing two ways to perform spatial\nconvolution on graphs using input-based filters which are dynamically\ngenerated. Our model also investigates the problem of discovering and refining\nrelations among nodes. The experimental assessment confirms the capabilities of\nthe proposed approach, which achieves satisfying results using simple\narchitectures with a low number of filters.",
          "link": "http://arxiv.org/abs/2105.10377",
          "publishedOn": "2021-05-24T07:23:04.495Z",
          "wordCount": 671,
          "title": "Dynamic Filters in Graph Convolutional Neural Networks. (arXiv:2105.10377v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10335",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Debasmit Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhalgat_Y/0/1/0/all/0/1\">Yash Bhalgat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1\">Fatih Porikli</a>",
          "description": "In this work, we propose a data-driven scheme to initialize the parameters of\na deep neural network. This is in contrast to traditional approaches which\nrandomly initialize parameters by sampling from transformed standard\ndistributions. Such methods do not use the training data to produce a more\ninformed initialization. Our method uses a sequential layer-wise approach where\neach layer is initialized using its input activations. The initialization is\ncast as an optimization problem where we minimize a combination of encoding and\ndecoding losses of the input activations, which is further constrained by a\nuser-defined latent code. The optimization problem is then restructured into\nthe well-known Sylvester equation, which has fast and efficient gradient-free\nsolutions. Our data-driven method achieves a boost in performance compared to\nrandom initialization methods, both before start of training and after training\nis over. We show that our proposed method is especially effective in few-shot\nand fine-tuning settings. We conclude this paper with analyses on time\ncomplexity and the effect of different latent codes on the recognition\nperformance.",
          "link": "http://arxiv.org/abs/2105.10335",
          "publishedOn": "2021-05-24T07:23:04.476Z",
          "wordCount": 616,
          "title": "Data-driven Weight Initialization with Sylvester Solvers. (arXiv:2105.10335v1 [cs.NE])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10304",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schwinn_L/0/1/0/all/0/1\">Leo Schwinn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raab_R/0/1/0/all/0/1\">Ren&#xe9; Raab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">An Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanca_D/0/1/0/all/0/1\">Dario Zanca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eskofier_B/0/1/0/all/0/1\">Bjoern Eskofier</a>",
          "description": "Progress in making neural networks more robust against adversarial attacks is\nmostly marginal, despite the great efforts of the research community. Moreover,\nthe robustness evaluation is often imprecise, making it difficult to identify\npromising approaches. We analyze the classification decisions of 19 different\nstate-of-the-art neural networks trained to be robust against adversarial\nattacks. Our findings suggest that current untargeted adversarial attacks\ninduce misclassification towards only a limited amount of different classes.\nAdditionally, we observe that both over- and under-confidence in model\npredictions result in an inaccurate assessment of model robustness. Based on\nthese observations, we propose a novel loss function for adversarial attacks\nthat consistently improves attack success rate compared to prior loss functions\nfor 19 out of 19 analyzed models.",
          "link": "http://arxiv.org/abs/2105.10304",
          "publishedOn": "2021-05-24T07:23:04.459Z",
          "wordCount": 551,
          "title": "Exploring Robust Misclassifications of Neural Networks to Enhance Adversarial Attacks. (arXiv:2105.10304v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10278",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Izza_Y/0/1/0/all/0/1\">Yacine Izza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marques_Silva_J/0/1/0/all/0/1\">Joao Marques-Silva</a>",
          "description": "Random Forest (RFs) are among the most widely used Machine Learning (ML)\nclassifiers. Even though RFs are not interpretable, there are no dedicated\nnon-heuristic approaches for computing explanations of RFs. Moreover, there is\nrecent work on polynomial algorithms for explaining ML models, including naive\nBayes classifiers. Hence, one question is whether finding explanations of RFs\ncan be solved in polynomial time. This paper answers this question negatively,\nby proving that computing one PI-explanation of an RF is D^P-complete.\nFurthermore, the paper proposes a propositional encoding for computing\nexplanations of RFs, thus enabling finding PI-explanations with a SAT solver.\nThis contrasts with earlier work on explaining boosted trees (BTs) and neural\nnetworks (NNs), which requires encodings based on SMT/MILP. Experimental\nresults, obtained on a wide range of publicly available datasets, demontrate\nthat the proposed SAT-based approach scales to RFs of sizes common in practical\napplications. Perhaps more importantly, the experimental results demonstrate\nthat, for the vast majority of examples considered, the SAT-based approach\nproposed in this paper significantly outperforms existing heuristic approaches.",
          "link": "http://arxiv.org/abs/2105.10278",
          "publishedOn": "2021-05-24T07:23:04.454Z",
          "wordCount": 599,
          "title": "On Explaining Random Forests with SAT. (arXiv:2105.10278v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10185",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+White_J/0/1/0/all/0/1\">Jennifer C. White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1\">Naomi Saphra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>",
          "description": "Probes are models devised to investigate the encoding of knowledge -- e.g.\nsyntactic structure -- in contextual representations. Probes are often designed\nfor simplicity, which has led to restrictions on probe design that may not\nallow for the full exploitation of the structure of encoded information; one\nsuch restriction is linearity. We examine the case of a structural probe\n(Hewitt and Manning, 2019), which aims to investigate the encoding of syntactic\nstructure in contextual representations through learning only linear\ntransformations. By observing that the structural probe learns a metric, we are\nable to kernelize it and develop a novel non-linear variant with an identical\nnumber of parameters. We test on 6 languages and find that the radial-basis\nfunction (RBF) kernel, in conjunction with regularization, achieves a\nstatistically significant improvement over the baseline in all languages --\nimplying that at least part of the syntactic knowledge is encoded non-linearly.\nWe conclude by discussing how the RBF kernel resembles BERT's self-attention\nlayers and speculate that this resemblance leads to the RBF-based probe's\nstronger performance.",
          "link": "http://arxiv.org/abs/2105.10185",
          "publishedOn": "2021-05-24T07:23:04.448Z",
          "wordCount": 600,
          "title": "A Non-Linear Structural Probe. (arXiv:2105.10185v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10067",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Searcy_J/0/1/0/all/0/1\">Jacob A. Searcy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sokolowski_S/0/1/0/all/0/1\">Susan L. Sokolowski</a>",
          "description": "Sizing and fitting of Personal Protective Equipment (PPE) is a critical part\nof the product creation process; however, traditional methods to do this type\nof work can be labor intensive and based on limited or non-representative\nanthropomorphic data. In the case of PPE, a poor fit can jeopardize an\nindividual's health and safety. In this paper we present an unsupervised\nmachine learning algorithm that can identify a representative set of exemplars,\nindividuals that can be utilized by designers as idealized sizing models. The\nalgorithm is based around a Variational Autoencoder (VAE) with a Point-Net\ninspired encoder and decoder architecture trained on Human point-cloud data\nobtained from the CEASAR dataset. The learned latent space is then clustered to\nidentify a specified number of sizing groups. We demonstrate this technique on\nscans of human faces to provide designers of masks and facial coverings a\nreference set of individuals to test existing mask styles.",
          "link": "http://arxiv.org/abs/2105.10067",
          "publishedOn": "2021-05-24T07:23:04.441Z",
          "wordCount": 590,
          "title": "Towards Automatic Sizing for PPE with a Point Cloud Based Variational Autoencoder. (arXiv:2105.10067v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bennett_A/0/1/0/all/0/1\">Andrew Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1\">Dipendra Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Than_N/0/1/0/all/0/1\">Nga Than</a>",
          "description": "Topic models are widely used in studying social phenomena. We conduct a\ncomparative study examining state-of-the-art neural versus non-neural topic\nmodels, performing a rigorous quantitative and qualitative assessment on a\ndataset of tweets about the COVID-19 pandemic. Our results show that not only\ndo neural topic models outperform their classical counterparts on standard\nevaluation metrics, but they also produce more coherent topics, which are of\ngreat benefit when studying complex social problems. We also propose a novel\nregularization term for neural topic models, which is designed to address the\nwell-documented problem of mode collapse, and demonstrate its effectiveness.",
          "link": "http://arxiv.org/abs/2105.10165",
          "publishedOn": "2021-05-24T07:23:04.436Z",
          "wordCount": 605,
          "title": "Have you tried Neural Topic Models? Comparative Analysis of Neural and Non-Neural Topic Models with Application to COVID-19 Twitter Data. (arXiv:2105.10165v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chandna_P/0/1/0/all/0/1\">Pritish Chandna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramires_A/0/1/0/all/0/1\">Ant&#xf3;nio Ramires</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serra_X/0/1/0/all/0/1\">Xavier Serra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_E/0/1/0/all/0/1\">Emilia G&#xf3;mez</a>",
          "description": "Loops, seamlessly repeatable musical segments, are a cornerstone of modern\nmusic production. Contemporary artists often mix and match various sampled or\npre-recorded loops based on musical criteria such as rhythm, harmony and\ntimbral texture to create compositions. Taking such criteria into account, we\npresent LoopNet, a feed-forward generative model for creating loops conditioned\non intuitive parameters. We leverage Music Information Retrieval (MIR) models\nas well as a large collection of public loop samples in our study and use the\nWave-U-Net architecture to map control parameters to audio. We also evaluate\nthe quality of the generated audio and propose intuitive controls for composers\nto map the ideas in their minds to an audio loop.",
          "link": "http://arxiv.org/abs/2105.10371",
          "publishedOn": "2021-05-24T07:23:04.428Z",
          "wordCount": 547,
          "title": "LoopNet: Musical Loop Synthesis Conditioned On Intuitive Musical Parameters. (arXiv:2105.10371v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10101",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_D/0/1/0/all/0/1\">David J. Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kesidis_G/0/1/0/all/0/1\">George Kesidis</a>",
          "description": "Deep Neural Networks (DNNs) have been shown vulnerable to adversarial\n(Test-Time Evasion (TTE)) attacks which, by making small changes to the input,\nalter the DNN's decision. We propose an attack detector based on\nclass-conditional Generative Adversarial Networks (GANs). We model the\ndistribution of clean data conditioned on the predicted class label by an\nAuxiliary Classifier GAN (ACGAN). Given a test sample and its predicted class,\nthree detection statistics are calculated using the ACGAN Generator and\nDiscriminator. Experiments on image classification datasets under different TTE\nattack methods show that our method outperforms state-of-the-art detection\nmethods. We also investigate the effectiveness of anomaly detection using\ndifferent DNN layers (input features or internal-layer features) and\ndemonstrate that anomalies are harder to detect using features closer to the\nDNN's output layer.",
          "link": "http://arxiv.org/abs/2105.10101",
          "publishedOn": "2021-05-24T07:23:04.409Z",
          "wordCount": 563,
          "title": "Anomaly Detection of Test-Time Evasion Attacks using Class-conditional Generative Adversarial Networks. (arXiv:2105.10101v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10305",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Collier_M/0/1/0/all/0/1\">Mark Collier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1\">Basil Mustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokiopoulou_E/0/1/0/all/0/1\">Efi Kokiopoulou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1\">Rodolphe Jenatton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berent_J/0/1/0/all/0/1\">Jesse Berent</a>",
          "description": "Large scale image classification datasets often contain noisy labels. We take\na principled probabilistic approach to modelling input-dependent, also known as\nheteroscedastic, label noise in these datasets. We place a multivariate Normal\ndistributed latent variable on the final hidden layer of a neural network\nclassifier. The covariance matrix of this latent variable, models the aleatoric\nuncertainty due to label noise. We demonstrate that the learned covariance\nstructure captures known sources of label noise between semantically similar\nand co-occurring classes. Compared to standard neural network training and\nother baselines, we show significantly improved accuracy on Imagenet ILSVRC\n2012 79.3% (+2.6%), Imagenet-21k 47.0% (+1.1%) and JFT 64.7% (+1.6%). We set a\nnew state-of-the-art result on WebVision 1.0 with 76.6% top-1 accuracy. These\ndatasets range from over 1M to over 300M training examples and from 1k classes\nto more than 21k classes. Our method is simple to use, and we provide an\nimplementation that is a drop-in replacement for the final fully-connected\nlayer in a deep classifier.",
          "link": "http://arxiv.org/abs/2105.10305",
          "publishedOn": "2021-05-24T07:23:04.404Z",
          "wordCount": 609,
          "title": "Correlated Input-Dependent Label Noise in Large-Scale Image Classification. (arXiv:2105.10305v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10358",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Shoji_T/0/1/0/all/0/1\">Taku Shoji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yoshida_N/0/1/0/all/0/1\">Noboru Yoshida</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tanaka_T/0/1/0/all/0/1\">Toshihisa Tanaka</a>",
          "description": "Electroencephalography (EEG) is essential for the diagnosis of epilepsy, but\nit requires expertise and experience to identify abnormalities. It is thus\ncrucial to develop automated models for the detection of abnormal EEGs related\nto epilepsy. This paper describes the development of a novel class of compact\nand efficient convolutional neural networks (CNNs) for detecting abnormal time\nintervals and electrodes in EEGs for epilepsy. The designed model is inspired\nby a CNN developed for brain-computer interfacing called multichannel EEGNet\n(mEEGNet). Unlike the EEGNet, the proposed model, mEEGNet, has the same number\nof electrode inputs and outputs to detect abnormalities. The mEEGNet was\nevaluated with a clinical dataset consisting of 29 cases of juvenile and\nchildhood absence epilepsy labeled by a clinical expert. The labels were given\nto paroxysmal discharges visually observed in both ictal (seizure) and\ninterictal (nonseizure) intervals. Results showed that the mEEGNet detected\nabnormal EEGs with the area under the curve, F1-values, and sensitivity\nequivalent to or higher than those of existing CNNs. Moreover, the number of\nparameters is much smaller than other CNN models. To our knowledge, the dataset\nof absence epilepsy validated with machine learning through this research is\nthe largest in the literature.",
          "link": "http://arxiv.org/abs/2105.10358",
          "publishedOn": "2021-05-24T07:23:04.394Z",
          "wordCount": 639,
          "title": "Automated Detection of Abnormal EEGs in Epilepsy With a Compact and Efficient CNN Model. (arXiv:2105.10358v1 [eess.SP])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10488",
          "author": "<a href=\"http://arxiv.org/find/q-bio/1/au:+Bonner_S/0/1/0/all/0/1\">Stephen Bonner</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Barrett_I/0/1/0/all/0/1\">Ian P Barrett</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Ye_C/0/1/0/all/0/1\">Cheng Ye</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Swiers_R/0/1/0/all/0/1\">Rowan Swiers</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Engkvist_O/0/1/0/all/0/1\">Ola Engkvist</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Hamilton_W/0/1/0/all/0/1\">William L Hamilton</a>",
          "description": "Knowledge Graphs (KG) and associated Knowledge Graph Embedding (KGE) models\nhave recently begun to be explored in the context of drug discovery and have\nthe potential to assist in key challenges such as target identification. In the\ndrug discovery domain, KGs can be employed as part of a process which can\nresult in lab-based experiments being performed, or impact on other decisions,\nincurring significant time and financial costs and most importantly, ultimately\ninfluencing patient healthcare. For KGE models to have impact in this domain, a\nbetter understanding of not only of performance, but also the various factors\nwhich determine it, is required.\n\nIn this study we investigate, over the course of many thousands of\nexperiments, the predictive performance of five KGE models on two public drug\ndiscovery-oriented KGs. Our goal is not to focus on the best overall model or\nconfiguration, instead we take a deeper look at how performance can be affected\nby changes in the training setup, choice of hyperparameters, model parameter\ninitialisation seed and different splits of the datasets. Our results highlight\nthat these factors have significant impact on performance and can even affect\nthe ranking of models. Indeed these factors should be reported along with model\narchitectures to ensure complete reproducibility and fair comparisons of future\nwork, and we argue this is critical for the acceptance of use, and impact of\nKGEs in a biomedical setting. To aid reproducibility of our own work, we\nrelease all experimentation code.",
          "link": "http://arxiv.org/abs/2105.10488",
          "publishedOn": "2021-05-24T07:23:04.388Z",
          "wordCount": 682,
          "title": "Understanding the Performance of Knowledge Graph Embeddings in Drug Discovery. (arXiv:2105.10488v1 [q-bio.BM])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10475",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_A/0/1/0/all/0/1\">Atsushi Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nitanda_A/0/1/0/all/0/1\">Atsushi Nitanda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Linchuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavazza_M/0/1/0/all/0/1\">Marc Cavazza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamanishi_K/0/1/0/all/0/1\">Kenji Yamanishi</a>",
          "description": "Hyperbolic ordinal embedding (HOE) represents entities as points in\nhyperbolic space so that they agree as well as possible with given constraints\nin the form of entity i is more similar to entity j than to entity k. It has\nbeen experimentally shown that HOE can obtain representations of hierarchical\ndata such as a knowledge base and a citation network effectively, owing to\nhyperbolic space's exponential growth property. However, its theoretical\nanalysis has been limited to ideal noiseless settings, and its generalization\nerror in compensation for hyperbolic space's exponential representation ability\nhas not been guaranteed. The difficulty is that existing generalization error\nbound derivations for ordinal embedding based on the Gramian matrix do not work\nin HOE, since hyperbolic space is not inner-product space. In this paper,\nthrough our novel characterization of HOE with decomposed Lorentz Gramian\nmatrices, we provide a generalization error bound of HOE for the first time,\nwhich is at most exponential with respect to the embedding space's radius. Our\ncomparison between the bounds of HOE and Euclidean ordinal embedding shows that\nHOE's generalization error is reasonable as a cost for its exponential\nrepresentation ability.",
          "link": "http://arxiv.org/abs/2105.10475",
          "publishedOn": "2021-05-24T07:23:04.370Z",
          "wordCount": 615,
          "title": "Generalization Error Bound for Hyperbolic Ordinal Embedding. (arXiv:2105.10475v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10389",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xingyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yufei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1\">David Held</a>",
          "description": "Robotic manipulation of cloth remains challenging for robotics due to the\ncomplex dynamics of the cloth, lack of a low-dimensional state representation,\nand self-occlusions. In contrast to previous model-based approaches that learn\na pixel-based dynamics model or a compressed latent vector dynamics, we propose\nto learn a particle-based dynamics model from a partial point cloud\nobservation. To overcome the challenges of partial observability, we infer\nwhich visible points are connected on the underlying cloth mesh. We then learn\na dynamics model over this visible connectivity graph. Compared to previous\nlearning-based approaches, our model poses strong inductive bias with its\nparticle based representation for learning the underlying cloth physics; it is\ninvariant to visual features; and the predictions can be more easily\nvisualized. We show that our method greatly outperforms previous\nstate-of-the-art model-based and model-free reinforcement learning methods in\nsimulation. Furthermore, we demonstrate zero-shot sim-to-real transfer where we\ndeploy the model trained in simulation on a Franka arm and show that the model\ncan successfully smooth different types of cloth from crumpled configurations.\nVideos can be found on our project website.",
          "link": "http://arxiv.org/abs/2105.10389",
          "publishedOn": "2021-05-24T07:23:04.364Z",
          "wordCount": 602,
          "title": "Learning Visible Connectivity Dynamics for Cloth Smoothing. (arXiv:2105.10389v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10478",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zichuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hongbo Jiang</a>",
          "description": "In intelligent transportation system, the key problem of traffic forecasting\nis how to extract the periodic temporal dependencies and complex spatial\ncorrelation. Current state-of-the-art methods for traffic flow prediction are\nbased on graph architectures and sequence learning models, but they do not\nfully exploit spatial-temporal dynamic information in traffic system.\nSpecifically, the temporal dependence of short-range is diluted by recurrent\nneural networks, and existing sequence model ignores local spatial information\nbecause the convolution operation uses global average pooling. Besides, there\nwill be some traffic accidents during the transitions of objects causing\ncongestion in the real world that trigger increased prediction deviation. To\novercome these challenges, we propose the Spatial-Temporal Conv-sequence\nLearning (STCL), in which a focused temporal block uses unidirectional\nconvolution to effectively capture short-term periodic temporal dependence, and\na spatial-temporal fusion module is able to extract the dependencies of both\ninteractions and decrease the feature dimensions. Moreover, the accidents\nfeatures impact on local traffic congestion and position encoding is employed\nto detect anomalies in complex traffic situations. We conduct extensive\nexperiments on large-scale real-world tasks and verify the effectiveness of our\nproposed method.",
          "link": "http://arxiv.org/abs/2105.10478",
          "publishedOn": "2021-05-24T07:23:04.351Z",
          "wordCount": 617,
          "title": "Spatial-Temporal Conv-sequence Learning with Accident Encoding for Traffic Flow Prediction. (arXiv:2105.10478v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10134",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wicker_M/0/1/0/all/0/1\">Matthew Wicker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laurenti_L/0/1/0/all/0/1\">Luca Laurenti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patane_A/0/1/0/all/0/1\">Andrea Patane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paoletti_N/0/1/0/all/0/1\">Nicola Paoletti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abate_A/0/1/0/all/0/1\">Alessandro Abate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwiatkowska_M/0/1/0/all/0/1\">Marta Kwiatkowska</a>",
          "description": "We consider the problem of computing reach-avoid probabilities for iterative\npredictions made with Bayesian neural network (BNN) models. Specifically, we\nleverage bound propagation techniques and backward recursion to compute lower\nbounds for the probability that trajectories of the BNN model reach a given set\nof states while avoiding a set of unsafe states. We use the lower bounds in the\ncontext of control and reinforcement learning to provide safety certification\nfor given control policies, as well as to synthesize control policies that\nimprove the certification bounds. On a set of benchmarks, we demonstrate that\nour framework can be employed to certify policies over BNNs predictions for\nproblems of more than $10$ dimensions, and to effectively synthesize policies\nthat significantly increase the lower bound on the satisfaction probability.",
          "link": "http://arxiv.org/abs/2105.10134",
          "publishedOn": "2021-05-24T07:23:04.343Z",
          "wordCount": 560,
          "title": "Certification of Iterative Predictions in Bayesian Neural Networks. (arXiv:2105.10134v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10190",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">S.K. Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paoletti_M/0/1/0/all/0/1\">M.E. Paoletti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haut_J/0/1/0/all/0/1\">J.M. Haut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_S/0/1/0/all/0/1\">S.R. Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kar_P/0/1/0/all/0/1\">P. Kar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plaza_A/0/1/0/all/0/1\">A. Plaza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_B/0/1/0/all/0/1\">B.B. Chaudhuri</a>",
          "description": "Convolutional neural networks (CNNs) are trained using stochastic gradient\ndescent (SGD)-based optimizers. Recently, the adaptive moment estimation (Adam)\noptimizer has become very popular due to its adaptive momentum, which tackles\nthe dying gradient problem of SGD. Nevertheless, existing optimizers are still\nunable to exploit the optimization curvature information efficiently. This\npaper proposes a new AngularGrad optimizer that considers the behavior of the\ndirection/angle of consecutive gradients. This is the first attempt in the\nliterature to exploit the gradient angular information apart from its\nmagnitude. The proposed AngularGrad generates a score to control the step size\nbased on the gradient angular information of previous iterations. Thus, the\noptimization steps become smoother as a more accurate step size of immediate\npast gradients is captured through the angular information. Two variants of\nAngularGrad are developed based on the use of Tangent or Cosine functions for\ncomputing the gradient angular information. Theoretically, AngularGrad exhibits\nthe same regret bound as Adam for convergence purposes. Nevertheless, extensive\nexperiments conducted on benchmark data sets against state-of-the-art methods\nreveal a superior performance of AngularGrad. The source code will be made\npublicly available at: https://github.com/mhaut/AngularGrad.",
          "link": "http://arxiv.org/abs/2105.10190",
          "publishedOn": "2021-05-24T07:23:04.337Z",
          "wordCount": 641,
          "title": "AngularGrad: A New Optimization Technique for Angular Convergence of Convolutional Neural Networks. (arXiv:2105.10190v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10193",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sahay_A/0/1/0/all/0/1\">Atul Sahay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasery_A/0/1/0/all/0/1\">Anshul Nasery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_A/0/1/0/all/0/1\">Ayush Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>",
          "description": "Recently, unsupervised parsing of syntactic trees has gained considerable\nattention. A prototypical approach to such unsupervised parsing employs\nreinforcement learning and auto-encoders. However, no mechanism ensures that\nthe learnt model leverages the well-understood language grammar. We propose an\napproach that utilizes very generic linguistic knowledge of the language\npresent in the form of syntactic rules, thus inducing better syntactic\nstructures. We introduce a novel formulation that takes advantage of the\nsyntactic grammar rules and is independent of the base system. We achieve new\nstate-of-the-art results on two benchmarks datasets, MNLI and WSJ. The source\ncode of the paper is available at https://github.com/anshuln/Diora_with_rules.",
          "link": "http://arxiv.org/abs/2105.10193",
          "publishedOn": "2021-05-24T07:23:04.316Z",
          "wordCount": 543,
          "title": "Rule Augmented Unsupervised Constituency Parsing. (arXiv:2105.10193v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10277",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Fuhl_W/0/1/0/all/0/1\">Wolfgang Fuhl</a>",
          "description": "In this work, we present an alternative to conventional residual connections,\nwhich is inspired by maxout nets. This means that instead of the addition in\nresidual connections, our approach only propagates the maximum value or, in the\nleaky formulation, propagates a percentage of both. In our evaluation, we show\non different public data sets that the presented approaches are comparable to\nthe residual connections and have other interesting properties, such as better\ngeneralization with a constant batch normalization, faster learning, and also\nthe possibility to generalize without additional activation functions. In\naddition, the proposed approaches work very well if ensembles together with\nresidual networks are formed.",
          "link": "http://arxiv.org/abs/2105.10277",
          "publishedOn": "2021-05-24T07:23:04.305Z",
          "wordCount": 518,
          "title": "Maximum and Leaky Maximum Propagation. (arXiv:2105.10277v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10430",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zihao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zohren_S/0/1/0/all/0/1\">Stefan Zohren</a>",
          "description": "We design multi-horizon forecasting models for limit order book (LOB) data by\nusing deep learning techniques. Unlike standard structures where a single\nprediction is made, we adopt encoder-decoder models with sequence-to-sequence\nand Attention mechanisms, to generate a forecasting path. Our methods achieve\ncomparable performance to state-of-art algorithms at short prediction horizons.\nImportantly, they outperform when generating predictions over long horizons by\nleveraging the multi-horizon setup. Given that encoder-decoder models rely on\nrecurrent neural layers, they generally suffer from a slow training process. To\nremedy this, we experiment with utilising novel hardware, so-called Intelligent\nProcessing Units (IPUs) produced by Graphcore. IPUs are specifically designed\nfor machine intelligence workload with the aim to speed up the computation\nprocess. We show that in our setup this leads to significantly faster training\ntimes when compared to training models with GPUs.",
          "link": "http://arxiv.org/abs/2105.10430",
          "publishedOn": "2021-05-24T07:23:04.288Z",
          "wordCount": 595,
          "title": "Multi-Horizon Forecasting for Limit Order Books: Novel Deep Learning Approaches and Hardware Acceleration using Intelligent Processing Units. (arXiv:2105.10430v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10213",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rohrer_T/0/1/0/all/0/1\">Tobias Rohrer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolberg_J/0/1/0/all/0/1\">Jascha Kolberg</a>",
          "description": "The need for reliable systems to determine fingerprint presentation attacks\ngrows with the rising use of the fingerprint for authentication. This work\npresents a new approach to single-class classification for software-based\nfingerprint presentation attach detection. The described method utilizes a\nWasserstein GAN to apply transfer learning to a deep convolutional autoencoder.\nBy doing so, the autoencoder could be pretrained and finetuned on the\nLivDet2021 Dermalog sensor dataset with only 1122 bona fide training samples.\nWithout making use of any presentation attack samples, the model could archive\nan average classification error rate of 16.79%. The Wasserstein GAN implemented\nto pretrain the autoencoders weights can further be used to generate\nrealistic-looking artificial fingerprint patches. Extensive testing of\ndifferent autoencoder architectures and hyperparameters led to coarse\narchitectural guidelines as well as multiple implementations which can be\nutilized for future work.",
          "link": "http://arxiv.org/abs/2105.10213",
          "publishedOn": "2021-05-24T07:23:04.266Z",
          "wordCount": 566,
          "title": "GAN pretraining for deep convolutional autoencoders applied to Software-based Fingerprint Presentation Attack Detection. (arXiv:2105.10213v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10239",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ambati_A/0/1/0/all/0/1\">Anirudh Ambati</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dubey_S/0/1/0/all/0/1\">Shiv Ram Dubey</a>",
          "description": "Covid-19 global pandemic continues to devastate health care systems across\nthe world. In many countries, the 2nd wave is very severe. Economical and rapid\ntesting, as well as diagnosis, is urgently needed to control the pandemic. At\npresent, the Covid-19 testing is costly and time-consuming. Chest X-Ray (CXR)\ntesting can be the fastest, scalable, and non-invasive method. The existing\nmethods suffer due to the limited CXR samples available from Covid-19. Thus,\ninspired by the limitations of the open-source work in this field, we propose\nattention guided contrastive CNN architecture (AC-CovidNet) for Covid-19\ndetection in CXR images. The proposed method learns the robust and\ndiscriminative features with the help of contrastive loss. Moreover, the\nproposed method gives more importance to the infected regions as guided by the\nattention mechanism. We compute the sensitivity of the proposed method over the\npublicly available Covid-19 dataset. It is observed that the proposed\nAC-CovidNet exhibits very promising performance as compared to the existing\nmethods even with limited training data. It can tackle the bottleneck of CXR\nCovid-19 datasets being faced by the researchers. The code used in this paper\nis released publicly at \\url{https://github.com/shivram1987/AC-CovidNet/}.",
          "link": "http://arxiv.org/abs/2105.10239",
          "publishedOn": "2021-05-24T07:23:04.249Z",
          "wordCount": 687,
          "title": "AC-CovidNet: Attention Guided Contrastive CNN for Recognition of Covid-19 in Chest X-Ray Images. (arXiv:2105.10239v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10013",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Vendramini_M/0/1/0/all/0/1\">Marcos Vendramini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1\">Hugo Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Machado_A/0/1/0/all/0/1\">Alexei Machado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1\">Jefersson A. dos Santos</a>",
          "description": "Image classification methods are usually trained to perform predictions\ntaking into account a predefined group of known classes. Real-world problems,\nhowever, may not allow for a full knowledge of the input and label spaces,\nmaking failures in recognition a hazard to deep visual learning. Open set\nrecognition methods are characterized by the ability to correctly identifying\ninputs of known and unknown classes. In this context, we propose GeMOS: simple\nand plug-and-play open set recognition modules that can be attached to\npretrained Deep Neural Networks for visual recognition. The GeMOS framework\npairs pre-trained Convolutional Neural Networks with generative models for open\nset recognition to extract open set scores for each sample, allowing for\nfailure recognition in object recognition tasks. We conduct a thorough\nevaluation of the proposed method in comparison with state-of-the-art open set\nalgorithms, finding that GeMOS either outperforms or is statistically\nindistinguishable from more complex and costly models.",
          "link": "http://arxiv.org/abs/2105.10013",
          "publishedOn": "2021-05-24T07:23:04.230Z",
          "wordCount": 583,
          "title": "Opening Deep Neural Networks with Generative Models. (arXiv:2105.10013v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10162",
          "author": "<a href=\"http://arxiv.org/find/quant-ph/1/au:+Sen_P/0/1/0/all/0/1\">Pinaki Sen</a>, <a href=\"http://arxiv.org/find/quant-ph/1/au:+Bhatia_A/0/1/0/all/0/1\">Amandeep Singh Bhatia</a>",
          "description": "In quantum computing, the variational quantum algorithms (VQAs) are well\nsuited for finding optimal combinations of things in specific applications\nranging from chemistry all the way to finance. The training of VQAs with\ngradient descent optimization algorithm has shown a good convergence. At an\nearly stage, the simulation of variational quantum circuits on noisy\nintermediate-scale quantum (NISQ) devices suffers from noisy outputs. Just like\nclassical deep learning, it also suffers from vanishing gradient problems. It\nis a realistic goal to study the topology of loss landscape, to visualize the\ncurvature information and trainability of these circuits in the existence of\nvanishing gradients. In this paper, we calculated the Hessian and visualized\nthe loss landscape of variational quantum classifiers at different points in\nparameter space. The curvature information of variational quantum classifiers\n(VQC) is interpreted and the loss function's convergence is shown. It helps us\nbetter understand the behavior of variational quantum circuits to tackle\noptimization problems efficiently. We investigated the variational quantum\nclassifiers via Hessian on quantum computers, started with a simple 4-bit\nparity problem to gain insight into the practical behavior of Hessian, then\nthoroughly analyzed the behavior of Hessian's eigenvalues on training the\nvariational quantum classifier for the Diabetes dataset.",
          "link": "http://arxiv.org/abs/2105.10162",
          "publishedOn": "2021-05-24T07:23:04.207Z",
          "wordCount": 635,
          "title": "Variational Quantum Classifiers Through the Lens of the Hessian. (arXiv:2105.10162v1 [quant-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2102.09342",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaohang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhuiyan_M/0/1/0/all/0/1\">Md Zakirul Alam Bhuiyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lianzhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lifang He</a>",
          "description": "Depression is one of the most common mental illness problems, and the\nsymptoms shown by patients are not consistent, making it difficult to diagnose\nin the process of clinical practice and pathological research. Although\nresearchers hope that artificial intelligence can contribute to the diagnosis\nand treatment of depression, the traditional centralized machine learning needs\nto aggregate patient data, and the data privacy of patients with mental illness\nneeds to be strictly confidential, which hinders mach",
          "link": "http://arxiv.org/abs/2102.09342",
          "publishedOn": "2021-05-22T03:02:52.835Z",
          "wordCount": 672,
          "title": "FedMood: Federated Learning on Mobile Health Data for Mood Detection. (arXiv:2102.09342v6 [cs.CY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04301",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhewei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Linyue Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenwen Yu</a>",
          "description": "Intrusion detection has been a key topic in the field of cyber security, and\nthe common network threats nowadays have the characteristics of varieties and\nvariation. Considering the serious imbalance of intrusion detection datasets\nwill result in low classification performance on attack behaviors of small\nsample size and difficulty to detect network attacks accurately and\nefficiently, using Adaptive Synthetic Sampling (ADASYN) method to balance\ndatasets was proposed in this paper. In addition, Random Forest",
          "link": "http://arxiv.org/abs/2105.04301",
          "publishedOn": "2021-05-22T03:02:52.813Z",
          "wordCount": 615,
          "title": "ADASYN-Random Forest Based Intrusion Detection Model. (arXiv:2105.04301v3 [cs.CR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04350",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Zheng_L/0/1/0/all/0/1\">Liangzhen Zheng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lan_H/0/1/0/all/0/1\">Haidong Lan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Shen_T/0/1/0/all/0/1\">Tao Shen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wu_J/0/1/0/all/0/1\">Jiaxiang Wu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_S/0/1/0/all/0/1\">Sheng Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Huang_J/0/1/0/all/0/1\">Junzhou Huang</a>",
          "description": "Proteins structure prediction has long been a grand challenge over the past\n50 years, owing to its board scientific and application interests. There are\ntwo major types of modelling algorithm, template-free modelling and\ntemplate-based modelling, which is suitable for easy prediction tasks, and is\nwidely adopted in computer aided drug discoveries for drug design and\nscreening. Although it has been several decades since its first edition, the\ncurrent template-based modeling approach suffers from two importan",
          "link": "http://arxiv.org/abs/2105.04350",
          "publishedOn": "2021-05-22T03:02:52.807Z",
          "wordCount": 649,
          "title": "tFold-TR: Combining Deep Learning Enhanced Hybrid Potential Energy for Template-Based Modelling Structure Refinement. (arXiv:2105.04350v2 [physics.bio-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06709",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lv_G/0/1/0/all/0/1\">Guofeng Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiqiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_Y/0/1/0/all/0/1\">Yanguang Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaoting Zhang</a>",
          "description": "The study of multi-type Protein-Protein Interaction (PPI) is fundamental for\nunderstanding biological processes from a systematic perspective and revealing\ndisease mechanisms. Existing methods suffer from significant performance\ndegradation when tested in unseen dataset. In this paper, we investigate the\nproblem and find that it is mainly attributed to the poor performance for\ninter-novel-protein interaction prediction. However, current evaluations\noverlook the inter-novel-protein interactions, and thus fai",
          "link": "http://arxiv.org/abs/2105.06709",
          "publishedOn": "2021-05-22T03:02:52.798Z",
          "wordCount": 631,
          "title": "Learning Unknown from Correlations: Graph Neural Network for Inter-novel-protein Interaction Prediction. (arXiv:2105.06709v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.03842",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leng_Y/0/1/0/all/0/1\">Yichong Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Linchen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Renqian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linquan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang-Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_E/0/1/0/all/0/1\">Ed Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>",
          "description": "Error correction techniques have been used to refine the output sentences\nfrom automatic speech recognition (ASR) models and achieve a lower word error\nrate (WER) than original ASR outputs. Previous works usually use a\nsequence-to-sequence model to correct an ASR output sentence autoregressively,\nwhich causes large latency and cannot be deployed in online ASR services. A\nstraightforward solution to reduce latency, inspired by non-autoregressive\n(NAR) neural machine translation, is to use an NAR sequence gen",
          "link": "http://arxiv.org/abs/2105.03842",
          "publishedOn": "2021-05-22T03:02:52.707Z",
          "wordCount": 751,
          "title": "FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition. (arXiv:2105.03842v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.10777",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Santu_S/0/1/0/all/0/1\">Shubhra Kanti Karmaker Santu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1\">Md. Mahadi Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Micah J. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1\">ChengXiang Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veeramachaneni_K/0/1/0/all/0/1\">Kalyan Veeramachaneni</a>",
          "description": "As big data becomes ubiquitous across domains, and more and more stakeholders\naspire to make the most of their data, demand for machine learning tools has\nspurred researchers to explore the possibilities of automated machine learning\n(AutoML). AutoML tools aim to make machine learning accessible for non-machine\nlearning experts (domain experts), to improve the efficiency of machine\nlearning, and to accelerate machine learning research. But although automation\nand efficiency are among AutoML's main selling p",
          "link": "http://arxiv.org/abs/2010.10777",
          "publishedOn": "2021-05-22T03:02:52.671Z",
          "wordCount": 775,
          "title": "AutoML to Date and Beyond: Challenges and Opportunities. (arXiv:2010.10777v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.06129",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Aaditya Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hingane_S/0/1/0/all/0/1\">Shreeshail Hingane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_X/0/1/0/all/0/1\">Xinyu Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>",
          "description": "Artistic style transfer aims to transfer the style characteristics of one\nimage onto another image while retaining its content. Existing approaches\ncommonly leverage various normalization techniques, although these face\nlimitations in adequately transferring diverse textures to different spatial\nlocations. Self-Attention-based approaches have tackled this issue with partial\nsuccess but suffer from unwanted artifacts. Motivated by these observations,\nthis paper aims to combine the best of both worlds: self-a",
          "link": "http://arxiv.org/abs/2105.06129",
          "publishedOn": "2021-05-22T03:02:52.665Z",
          "wordCount": 616,
          "title": "SAFIN: Arbitrary Style Transfer With Self-Attentive Factorized Instance Normalization. (arXiv:2105.06129v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08147",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ramesh_V/0/1/0/all/0/1\">Vignav Ramesh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rister_B/0/1/0/all/0/1\">Blaine Rister</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1\">Daniel L. Rubin</a>",
          "description": "Chest X-rays of coronavirus disease 2019 (COVID-19) patients are frequently\nobtained to determine the extent of lung disease and are a valuable source of\ndata for creating artificial intelligence models. Most work to date assessing\ndisease severity on chest imaging has focused on segmenting computed tomography\n(CT) images; however, given that CTs are performed much less frequently than\nchest X-rays for COVID-19 patients, automated lung lesion segmentation on chest\nX-rays could be clinically valuable. There ",
          "link": "http://arxiv.org/abs/2105.08147",
          "publishedOn": "2021-05-22T03:02:52.652Z",
          "wordCount": 779,
          "title": "COVID-19 Lung Lesion Segmentation Using a Sparsely Supervised Mask R-CNN on Chest X-rays Automatically Computed from Volumetric CTs. (arXiv:2105.08147v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.01187",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Qi_Z/0/1/0/all/0/1\">Zhengling Qi</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Miao_R/0/1/0/all/0/1\">Rui Miao</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoke Zhang</a>",
          "description": "Data-driven individualized decision making has recently received increasing\nresearch interests. Most existing methods rely on the assumption of no\nunmeasured confounding, which unfortunately cannot be ensured in practice\nespecially in observational studies. Motivated by the recent proposed proximal\ncausal inference, we develop several proximal learning approaches to estimating\noptimal individualized treatment regimes (ITRs) in the presence of unmeasured\nconfounding. In particular, we establish several ident",
          "link": "http://arxiv.org/abs/2105.01187",
          "publishedOn": "2021-05-22T03:02:52.646Z",
          "wordCount": 580,
          "title": "Proximal Learning for Individualized Treatment Regimes Under Unmeasured Confounding. (arXiv:2105.01187v2 [stat.ME] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.04916",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhaofei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1\">Wei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Tiejun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yonghong Tian</a>",
          "description": "Spiking Neural Networks (SNNs) have been attached great importance due to\ntheir biological plausibility and high energy-efficiency on neuromorphic chips.\nAs these chips are usually resource-constrained, the compression of SNNs is\nthus crucial along the road of practical use of SNNs. Most existing methods\ndirectly apply pruning approaches in artificial neural networks (ANNs) to SNNs,\nwhich ignore the difference between ANNs and SNNs, thus limiting the\nperformance of the pruned SNNs. Besides, these methods ar",
          "link": "http://arxiv.org/abs/2105.04916",
          "publishedOn": "2021-05-22T03:02:52.631Z",
          "wordCount": 696,
          "title": "Pruning of Deep Spiking Neural Networks through Gradient Rewiring. (arXiv:2105.04916v2 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09866",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Wang_Z/0/1/0/all/0/1\">Zhe Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Guet_C/0/1/0/all/0/1\">Claude Guet</a>",
          "description": "Solving physics problems for which we know the equations, boundary conditions\nand symmetries can be done by deep learning. The constraints can be either\nimposed as terms in a loss function or used to formulate a neural ansatz. In\nthe present case study, we calculate the induced field inside and outside a\ndielectric cube placed in a uniform electric field, wherein the dielectric\nmismatch at edges and corners of the cube makes accurate calculations\nnumerically challenging. The electric potential is expressed ",
          "link": "http://arxiv.org/abs/2105.09866",
          "publishedOn": "2021-05-22T03:02:52.618Z",
          "wordCount": 707,
          "title": "Deep learning in physics: a study of dielectric quasi-cubic particles in a uniform electric field. (arXiv:2105.09866v1 [physics.class-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2104.10241",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dapeng Zhao</a>",
          "description": "Thesis document of the degree of Master of Science in Robotics of Carnegie\nMellon University School of Computer Science.",
          "link": "http://arxiv.org/abs/2104.10241",
          "publishedOn": "2021-05-22T03:02:52.603Z",
          "wordCount": 465,
          "title": "Predicting Human Trajectories by Learning and Matching Patterns. (arXiv:2104.10241v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.07239",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cramer_B/0/1/0/all/0/1\">Benjamin Cramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Billaudelle_S/0/1/0/all/0/1\">Sebastian Billaudelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanya_S/0/1/0/all/0/1\">Simeon Kanya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leibfried_A/0/1/0/all/0/1\">Aron Leibfried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grubl_A/0/1/0/all/0/1\">Andreas Gr&#xfc;bl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karasenko_V/0/1/0/all/0/1\">Vitali Karasenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pehle_C/0/1/0/all/0/1\">Christian Pehle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schreiber_K/0/1/0/all/0/1\">Korbinian Schreiber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stradmann_Y/0/1/0/all/0/1\">Yannik Stradmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weis_J/0/1/0/all/0/1\">Johannes Weis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schemmel_J/0/1/0/all/0/1\">Johannes Schemmel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zenke_F/0/1/0/all/0/1\">Friedemann Zenke</a>",
          "description": "To rapidly process temporal information at a low metabolic cost, biological\nneurons integrate inputs as an analog sum but communicate with spikes, binary\nevents in time. Analog neuromorphic hardware uses the same principles to\nemulate spiking neural networks with exceptional energy-efficiency. However,\ninstantiating high-performing spiking networks on such hardware remains a\nsignificant challenge due to device mismatch and the lack of efficient training\nalgorithms. Here, we introduce a general in-the-loop l",
          "link": "http://arxiv.org/abs/2006.07239",
          "publishedOn": "2021-05-22T03:02:52.579Z",
          "wordCount": 664,
          "title": "Surrogate gradients for analog neuromorphic computing. (arXiv:2006.07239v3 [cs.NE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.05525",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gou_J/0/1/0/all/0/1\">Jianping Gou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Baosheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maybank_S/0/1/0/all/0/1\">Stephen John Maybank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>",
          "description": "In recent years, deep neural networks have been successful in both industry\nand academia, especially for computer vision tasks. The great success of deep\nlearning is mainly due to its scalability to encode large-scale data and to\nmaneuver billions of model parameters. However, it is a challenge to deploy\nthese cumbersome deep models on devices with limited resources, e.g., mobile\nphones and embedded devices, not only because of the high computational\ncomplexity but also the large storage requirements. To th",
          "link": "http://arxiv.org/abs/2006.05525",
          "publishedOn": "2021-05-22T03:02:52.561Z",
          "wordCount": 677,
          "title": "Knowledge Distillation: A Survey. (arXiv:2006.05525v7 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09899",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Ran Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mingkun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1\">Rujun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Bo Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Zhuoling Xiao</a>",
          "description": "The technology for Visual Odometry (VO) that estimates the position and\norientation of the moving object through analyzing the image sequences captured\nby on-board cameras, has been well investigated with the rising interest in\nautonomous driving. This paper studies monocular VO from the perspective of\nDeep Learning (DL). Unlike most current learning-based methods, our approach,\ncalled DeepAVO, is established on the intuition that features contribute\ndiscriminately to different motion patterns. Specifically",
          "link": "http://arxiv.org/abs/2105.09899",
          "publishedOn": "2021-05-22T03:02:52.521Z",
          "wordCount": 619,
          "title": "DeepAVO: Efficient Pose Refining with Feature Distilling for Deep Visual Odometry. (arXiv:2105.09899v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2008.05600",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xi_D/0/1/0/all/0/1\">Dongbo Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1\">Bowen Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_F/0/1/0/all/0/1\">Fuzhen Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yongchun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qing He</a>",
          "description": "With the explosive growth of e-commerce, online transaction fraud has become\none of the biggest challenges for e-commerce platforms. The historical\nbehaviors of users provide rich information for digging into the users' fraud\nrisk. While considerable efforts have been made in this direction, a\nlong-standing challenge is how to effectively exploit internal user information\nand provide explainable prediction results. In fact, the value variations of\nsame field from different events and the interactions of dif",
          "link": "http://arxiv.org/abs/2008.05600",
          "publishedOn": "2021-05-22T03:02:52.481Z",
          "wordCount": 673,
          "title": "Modeling the Field Value Variations and Field Interactions Simultaneously for Fraud Detection. (arXiv:2008.05600v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2002.08797",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Hayou_S/0/1/0/all/0/1\">Soufiane Hayou</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ton_J/0/1/0/all/0/1\">Jean-Francois Ton</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1\">Arnaud Doucet</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1\">Yee Whye Teh</a>",
          "description": "Overparameterized Neural Networks (NN) display state-of-the-art performance.\nHowever, there is a growing need for smaller, energy-efficient, neural networks\ntobe able to use machine learning applications on devices with limited\ncomputational resources. A popular approach consists of using pruning\ntechniques. While these techniques have traditionally focused on pruning\npre-trained NN (LeCun et al.,1990; Hassibi et al., 1993), recent work by Lee et\nal. (2018) has shown promising results when pruning at initia",
          "link": "http://arxiv.org/abs/2002.08797",
          "publishedOn": "2021-05-22T03:02:52.472Z",
          "wordCount": 619,
          "title": "Robust Pruning at Initialization. (arXiv:2002.08797v5 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.14958",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kefato_Z/0/1/0/all/0/1\">Zekarias T. Kefato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Girdzijauskas_S/0/1/0/all/0/1\">Sarunas Girdzijauskas</a>",
          "description": "Real world data is mostly unlabeled or only few instances are labeled.\nManually labeling data is a very expensive and daunting task. This calls for\nunsupervised learning techniques that are powerful enough to achieve comparable\nresults as semi-supervised/supervised techniques. Contrastive self-supervised\nlearning has emerged as a powerful direction, in some cases outperforming\nsupervised techniques. In this study, we propose, SelfGNN, a novel contrastive\nself-supervised graph neural network (GNN) without re",
          "link": "http://arxiv.org/abs/2103.14958",
          "publishedOn": "2021-05-22T03:02:52.412Z",
          "wordCount": 666,
          "title": "Self-supervised Graph Neural Networks without explicit negative sampling. (arXiv:2103.14958v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09543",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_K/0/1/0/all/0/1\">Keyue Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yuzhuo Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhiyu Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>",
          "description": "Distantly supervised (DS) relation extraction (RE) has attracted much\nattention in the past few years as it can utilize large-scale auto-labeled\ndata. However, its evaluation has long been a problem: previous works either\ntook costly and inconsistent methods to manually examine a small sample of\nmodel predictions, or directly test models on auto-labeled data -- which, by\nour check, produce as much as 53% wrong labels at the entity pair level in the\npopular NYT10 dataset. This problem has not only led to ina",
          "link": "http://arxiv.org/abs/2105.09543",
          "publishedOn": "2021-05-22T03:02:52.394Z",
          "wordCount": 643,
          "title": "Manual Evaluation Matters: Reviewing Test Protocols of Distantly Supervised Relation Extraction. (arXiv:2105.09543v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bountrogiannis_K/0/1/0/all/0/1\">Konstantinos Bountrogiannis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzagkarakis_G/0/1/0/all/0/1\">George Tzagkarakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsakalides_P/0/1/0/all/0/1\">Panagiotis Tsakalides</a>",
          "description": "Due to the importance of the lower bounding distances and the attractiveness\nof symbolic representations, the family of symbolic aggregate approximations\n(SAX) has been used extensively for encoding time series data. However, typical\nSAX-based methods rely on two restrictive assumptions; the Gaussian\ndistribution and equiprobable symbols. This paper proposes two novel\ndata-driven SAX-based symbolic representations, distinguished by their\ndiscretization steps. The first representation, oriented for general d",
          "link": "http://arxiv.org/abs/2105.09592",
          "publishedOn": "2021-05-22T03:02:52.379Z",
          "wordCount": 634,
          "title": "Distribution Agnostic Symbolic Representations for Time Series Dimensionality Reduction and Online Anomaly Detection. (arXiv:2105.09592v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09917",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Beknazaryan_A/0/1/0/all/0/1\">Aleksandr Beknazaryan</a>",
          "description": "An example of an activation function $\\sigma$ is given such that networks\nwith activations $\\{\\sigma, \\lfloor\\cdot\\rfloor\\}$, integer weights and a fixed\narchitecture depending on $d$ approximate continuous functions on $[0,1]^d$.\nThe range of integer weights required for $\\varepsilon$-approximation of\nH\\\"older continuous functions is derived, which leads to a convergence rate of\norder $n^{\\frac{-2\\beta}{2\\beta+d}}\\log_2n$ for neural network regression\nestimation of unknown $\\beta$-H\\\"older continuous funct",
          "link": "http://arxiv.org/abs/2105.09917",
          "publishedOn": "2021-05-22T03:02:52.373Z",
          "wordCount": 489,
          "title": "Neural networks with superexpressive activations and integer weights. (arXiv:2105.09917v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2102.11192",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frerix_T/0/1/0/all/0/1\">Thomas Frerix</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochkov_D/0/1/0/all/0/1\">Dmitrii Kochkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1\">Jamie A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1\">Daniel Cremers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brenner_M/0/1/0/all/0/1\">Michael P. Brenner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoyer_S/0/1/0/all/0/1\">Stephan Hoyer</a>",
          "description": "Variational data assimilation optimizes for an initial state of a dynamical\nsystem such that its evolution fits observational data. The physical model can\nsubsequently be evolved into the future to make predictions. This principle is\na cornerstone of large scale forecasting applications such as numerical weather\nprediction. As such, it is implemented in current operational systems of\nweather forecasting agencies across the globe. However, finding a good initial\nstate poses a difficult optimization problem i",
          "link": "http://arxiv.org/abs/2102.11192",
          "publishedOn": "2021-05-22T03:02:52.368Z",
          "wordCount": 643,
          "title": "Variational Data Assimilation with a Learned Inverse Observation Operator. (arXiv:2102.11192v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09369",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wainakh_A/0/1/0/all/0/1\">Aidmar Wainakh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ventola_F/0/1/0/all/0/1\">Fabrizio Ventola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mussig_T/0/1/0/all/0/1\">Till M&#xfc;&#xdf;ig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keim_J/0/1/0/all/0/1\">Jens Keim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordero_C/0/1/0/all/0/1\">Carlos Garcia Cordero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmer_E/0/1/0/all/0/1\">Ephraim Zimmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grube_T/0/1/0/all/0/1\">Tim Grube</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muhlhauser_M/0/1/0/all/0/1\">Max M&#xfc;hlh&#xe4;user</a>",
          "description": "Federated learning enables multiple users to build a joint model by sharing\ntheir model updates (gradients), while their raw data remains local on their\ndevices. In contrast to the common belief that this provides privacy benefits,\nwe here add to the very recent results on privacy risks when sharing gradients.\nSpecifically, we propose Label Leakage from Gradients (LLG), a novel attack to\nextract the labels of the users' training data from their shared gradients. The\nattack exploits the direction and magnitu",
          "link": "http://arxiv.org/abs/2105.09369",
          "publishedOn": "2021-05-22T03:02:52.284Z",
          "wordCount": 611,
          "title": "User Label Leakage from Gradients in Federated Learning. (arXiv:2105.09369v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.05737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zili Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1\">Marco Valentino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1\">Donal Landers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andre Freitas</a>",
          "description": "This paper describes N-XKT (Neural encoding based on eXplanatory Knowledge\nTransfer), a novel method for the automatic transfer of explanatory knowledge\nthrough neural encoding mechanisms. We demonstrate that N-XKT is able to\nimprove accuracy and generalization on science Question Answering (QA).\nSpecifically, by leveraging facts from background explanatory knowledge\ncorpora, the N-XKT model shows a clear improvement on zero-shot QA.\nFurthermore, we show that N-XKT can be fine-tuned on a target QA dataset,\n",
          "link": "http://arxiv.org/abs/2105.05737",
          "publishedOn": "2021-05-22T03:02:52.275Z",
          "wordCount": 554,
          "title": "Encoding Explanatory Knowledge for Zero-shot Science Question Answering. (arXiv:2105.05737v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.00685",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Marvin_D/0/1/0/all/0/1\">Dario Marvin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Nespoli_L/0/1/0/all/0/1\">Lorenzo Nespoli</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Strepparava_D/0/1/0/all/0/1\">Davide Strepparava</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Medici_V/0/1/0/all/0/1\">Vasco Medici</a>",
          "description": "The ability to forecast the concentration of air pollutants in an urban\nregion is crucial for decision-makers wishing to reduce the impact of pollution\non public health through active measures (e.g. temporary traffic closures). In\nthis study, we present a machine learning approach applied to the forecast of\nthe day-ahead maximum value of the ozone concentration for several geographical\nlocations in southern Switzerland. Due to the low density of measurement\nstations and to the complex orography of the use c",
          "link": "http://arxiv.org/abs/2012.00685",
          "publishedOn": "2021-05-22T03:02:52.258Z",
          "wordCount": 629,
          "title": "A data-driven approach to the forecasting of ground-level ozone concentration. (arXiv:2012.00685v3 [physics.ao-ph] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.05996",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1\">Tharindu Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zampieri_M/0/1/0/all/0/1\">Marcos Zampieri</a>",
          "description": "Offensive content is pervasive in social media and a reason for concern to\ncompanies and government organizations. Several studies have been recently\npublished investigating methods to detect the various forms of such content\n(e.g. hate speech, cyberbullying, and cyberaggression). The clear majority of\nthese studies deal with English partially because most annotated datasets\navailable contain English data. In this paper, we take advantage of available\nEnglish datasets by applying cross-lingual contextual wo",
          "link": "http://arxiv.org/abs/2105.05996",
          "publishedOn": "2021-05-22T03:02:52.222Z",
          "wordCount": 695,
          "title": "Multilingual Offensive Language Identification for Low-resource Languages. (arXiv:2105.05996v3 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09801",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuangshuang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1\">Sihao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karayiannidis_Y/0/1/0/all/0/1\">Yiannis Karayiannidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bjorkman_M/0/1/0/all/0/1\">M&#xe5;rten Bj&#xf6;rkman</a>",
          "description": "Learning generative models and inferring latent trajectories have shown to be\nchallenging for time series due to the intractable marginal likelihoods of\nflexible generative models. It can be addressed by surrogate objectives for\noptimization. We propose Monte Carlo filtering objectives (MCFOs), a family of\nvariational objectives for jointly learning parametric generative models and\namortized adaptive importance proposals of time series. MCFOs extend the\nchoices of likelihood estimators beyond Sequential Mon",
          "link": "http://arxiv.org/abs/2105.09801",
          "publishedOn": "2021-05-22T03:02:52.207Z",
          "wordCount": 595,
          "title": "Monte Carlo Filtering Objectives: A New Family of Variational Objectives to Learn Generative Model and Neural Adaptive Proposal for Time Series. (arXiv:2105.09801v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yanli Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1\">Brenden M. Lake</a>",
          "description": "Humans are highly efficient learners, with the ability to grasp the meaning\nof a new concept from just a few examples. Unlike popular computer vision\nsystems, humans can flexibly leverage the compositional structure of the visual\nworld, understanding new concepts as combinations of existing concepts. In the\ncurrent paper, we study how people learn different types of visual\ncompositions, using abstract visual forms with rich relational structure. We\nfind that people can make meaningful compositional generali",
          "link": "http://arxiv.org/abs/2105.09848",
          "publishedOn": "2021-05-22T03:02:52.200Z",
          "wordCount": 587,
          "title": "Flexible Compositional Learning of Structured Visual Concepts. (arXiv:2105.09848v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2103.00742",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>",
          "description": "Machine learning on graphs has been extensively studied in both academic and\nindustry. However, as the literature on graph learning booms with a vast number\nof emerging methods and techniques, it becomes increasingly difficult to\nmanually design the optimal machine learning algorithm for different\ngraph-related tasks. To solve this critical challenge, automated machine\nlearning (AutoML) on graphs which combines the strength of graph machine\nlearning and AutoML together, is gaining attention from the researc",
          "link": "http://arxiv.org/abs/2103.00742",
          "publishedOn": "2021-05-22T03:02:52.194Z",
          "wordCount": 625,
          "title": "Automated Machine Learning on Graphs: A Survey. (arXiv:2103.00742v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.00359",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1\">Chenjian Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1\">Chen Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hongjin He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1\">Liqun Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yanwei Xu</a>",
          "description": "Tensor completion refers to the task of estimating the missing data from an\nincomplete measurement or observation, which is a core problem frequently\narising from the areas of big data analysis, computer vision, and network\nengineering. Due to the multidimensional nature of high-order tensors, the\nmatrix approaches, e.g., matrix factorization and direct matricization of\ntensors, are often not ideal for tensor completion and recovery. In this paper,\nwe introduce a unified low-rank and sparse enhanced Tucker ",
          "link": "http://arxiv.org/abs/2010.00359",
          "publishedOn": "2021-05-22T03:02:52.188Z",
          "wordCount": 699,
          "title": "Low-Rank and Sparse Enhanced Tucker Decomposition for Tensor Completion. (arXiv:2010.00359v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.08796",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xiaojun Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jianwei Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Abdollahi_A/0/1/0/all/0/1\">Ali Abdollahi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jones_T/0/1/0/all/0/1\">Trevor Jones</a>",
          "description": "For electric vehicles (EV) and energy storage (ES) batteries, thermal runaway\nis a critical issue as it can lead to uncontrollable fires or even explosions.\nThermal anomaly detection can identify problematic battery packs that may\neventually undergo thermal runaway. However, there are common challenges like\ndata unavailability, environment and configuration variations, and battery\naging. We propose a data-driven method to detect battery thermal anomaly based\non comparing shape-similarity between thermal mea",
          "link": "http://arxiv.org/abs/2103.08796",
          "publishedOn": "2021-05-22T03:02:52.182Z",
          "wordCount": 607,
          "title": "Data-driven Thermal Anomaly Detection for Batteries using Unsupervised Shape Clustering. (arXiv:2103.08796v2 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.10683",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Koeppe_A/0/1/0/all/0/1\">Arnd Koeppe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamer_F/0/1/0/all/0/1\">Franz Bamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Selzer_M/0/1/0/all/0/1\">Michael Selzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nestler_B/0/1/0/all/0/1\">Britta Nestler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markert_B/0/1/0/all/0/1\">Bernd Markert</a>",
          "description": "(Artificial) neural networks have become increasingly popular in mechanics as\nmeans to accelerate computations with model order reduction techniques and as\nuniversal models for a wide variety of materials. However, the major\ndisadvantage of neural networks remains: their numerous parameters are\nchallenging to interpret and explain. Thus, neural networks are often labeled\nas black boxes, and their results often elude human interpretation. In\nmechanics, the new and active field of physics-informed neural netw",
          "link": "http://arxiv.org/abs/2104.10683",
          "publishedOn": "2021-05-22T03:02:52.167Z",
          "wordCount": 713,
          "title": "Explainable artificial intelligence for mechanics: physics-informing neural networks for constitutive models. (arXiv:2104.10683v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.02372",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Greenberg_I/0/1/0/all/0/1\">Ido Greenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yannay_N/0/1/0/all/0/1\">Netanel Yannay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1\">Shie Mannor</a>",
          "description": "Determining the noise parameters of a Kalman Filter (KF) has been studied for\ndecades. A huge body of research focuses on the task of estimation of the noise\nunder various conditions, since precise noise estimation is considered\nequivalent to minimization of the filtering errors. However, we show that even\na small violation of the KF assumptions can significantly modify the effective\nnoise, breaking the equivalence between the tasks and making noise estimation\nan inferior strategy. We show that such violati",
          "link": "http://arxiv.org/abs/2104.02372",
          "publishedOn": "2021-05-22T03:02:52.159Z",
          "wordCount": 689,
          "title": "Noise Estimation Is Not Optimal: How to Use Kalman Filter the Right Way. (arXiv:2104.02372v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.10391",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Michalopoulos_G/0/1/0/all/0/1\">George Michalopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuanxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaka_H/0/1/0/all/0/1\">Hussam Kaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Helen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1\">Alexander Wong</a>",
          "description": "Contextual word embedding models, such as BioBERT and Bio_ClinicalBERT, have\nachieved state-of-the-art results in biomedical natural language processing\ntasks by focusing their pre-training process on domain-specific corpora.\nHowever, such models do not take into consideration expert domain knowledge.\n\nIn this work, we introduced UmlsBERT, a contextual embedding model that\nintegrates domain knowledge during the pre-training process via a novel\nknowledge augmentation strategy. More specifically, the augmenta",
          "link": "http://arxiv.org/abs/2010.10391",
          "publishedOn": "2021-05-22T03:02:52.153Z",
          "wordCount": 642,
          "title": "UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus. (arXiv:2010.10391v4 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09900",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Giovanini_L/0/1/0/all/0/1\">Luiz Giovanini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceschin_F/0/1/0/all/0/1\">Fabr&#xed;cio Ceschin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_M/0/1/0/all/0/1\">Mirela Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Aokun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_R/0/1/0/all/0/1\">Ramchandra Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banda_S/0/1/0/all/0/1\">Sanjay Banda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lysaght_M/0/1/0/all/0/1\">Madison Lysaght</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_H/0/1/0/all/0/1\">Heng Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sapountzis_N/0/1/0/all/0/1\">Nikolaos Sapountzis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruimin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthews_B/0/1/0/all/0/1\">Brandon Matthews</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dapeng Oliver Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gregio_A/0/1/0/all/0/1\">Andr&#xe9; Gr&#xe9;gio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_D/0/1/0/all/0/1\">Daniela Oliveira</a>",
          "description": "This paper investigates whether computer usage profiles comprised of\nprocess-, network-, mouse- and keystroke-related events are unique and\ntemporally consistent in a naturalistic setting, discussing challenges and\nopportunities of using such profiles in applications of continuous\nauthentication. We collected ecologically-valid computer usage profiles from 28\nMS Windows 10 computer users over 8 weeks and submitted this data to\ncomprehensive machine learning analysis involving a diverse set of online and\noff",
          "link": "http://arxiv.org/abs/2105.09900",
          "publishedOn": "2021-05-22T03:02:52.146Z",
          "wordCount": 613,
          "title": "Computer Users Have Unique Yet Temporally Inconsistent Computer Usage Profiles. (arXiv:2105.09900v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2104.05089",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cachay_S/0/1/0/all/0/1\">Salva R&#xfc;hling Cachay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erickson_E/0/1/0/all/0/1\">Emma Erickson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bucker_A/0/1/0/all/0/1\">Arthur Fender C. Bucker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pokropek_E/0/1/0/all/0/1\">Ernest Pokropek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potosnak_W/0/1/0/all/0/1\">Willa Potosnak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bire_S/0/1/0/all/0/1\">Suyash Bire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osei_S/0/1/0/all/0/1\">Salomey Osei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1\">Bj&#xf6;rn L&#xfc;tjens</a>",
          "description": "Deep learning-based models have recently outperformed state-of-the-art\nseasonal forecasting models, such as for predicting El Ni\\~no-Southern\nOscillation (ENSO). However, current deep learning models are based on\nconvolutional neural networks which are difficult to interpret and can fail to\nmodel large-scale atmospheric patterns. In comparison, graph neural networks\n(GNNs) are capable of modeling large-scale spatial dependencies and are more\ninterpretable due to the explicit modeling of information flow thr",
          "link": "http://arxiv.org/abs/2104.05089",
          "publishedOn": "2021-05-22T03:02:52.132Z",
          "wordCount": 632,
          "title": "The World as a Graph: Improving El Ni\\~no Forecasts with Graph Neural Networks. (arXiv:2104.05089v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.07686",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ashley_D/0/1/0/all/0/1\">Dylan R. Ashley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1\">Sina Ghiassian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1\">Richard S. Sutton</a>",
          "description": "Catastrophic forgetting remains a severe hindrance to the broad application\nof artificial neural networks (ANNs), however, it continues to be a poorly\nunderstood phenomenon. Despite the extensive amount of work on catastrophic\nforgetting, we argue that it is still unclear how exactly the phenomenon should\nbe quantified, and, moreover, to what degree all of the choices we make when\ndesigning learning systems affect the amount of catastrophic forgetting. We use\nvarious testbeds from the reinforcement learning",
          "link": "http://arxiv.org/abs/2102.07686",
          "publishedOn": "2021-05-22T03:02:52.118Z",
          "wordCount": 752,
          "title": "Does Standard Backpropagation Forget Less Catastrophically Than Adam?. (arXiv:2102.07686v3 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2011.10718",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Rangi_A/0/1/0/all/0/1\">Anshuka Rangi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khojasteh_M/0/1/0/all/0/1\">Mohammad Javad Khojasteh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Franceschetti_M/0/1/0/all/0/1\">Massimo Franceschetti</a>",
          "description": "We study the problem of learning-based attacks in linear systems, where the\ncommunication channel between the controller and the plant can be hijacked by a\nmalicious attacker. We assume the attacker learns the dynamics of the system\nfrom observations, then overrides the controller's actuation signal, while\nmimicking legitimate operation by providing fictitious sensor readings to the\ncontroller. On the other hand, the controller is on a lookout to detect the\npresence of the attacker and tries to enhance the ",
          "link": "http://arxiv.org/abs/2011.10718",
          "publishedOn": "2021-05-22T03:02:52.107Z",
          "wordCount": 720,
          "title": "Learning-based attacks in Cyber-Physical Systems: Exploration, Detection, and Control Cost trade-offs. (arXiv:2011.10718v2 [eess.SY] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.12365",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Siegel_J/0/1/0/all/0/1\">Jonathan W. Siegel</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1\">Jinchao Xu</a>",
          "description": "This article addresses several fundamental issues associated with the\napproximation theory of neural networks, including the characterization of\napproximation spaces, the determination of the metric entropy of these spaces,\nand approximation rates of neural networks. For any activation function\n$\\sigma$, we show that the largest Banach space of functions which can be\nefficiently approximated by the corresponding shallow neural networks is the\nspace whose norm is given by the gauge of the closed convex hull ",
          "link": "http://arxiv.org/abs/2101.12365",
          "publishedOn": "2021-05-22T03:02:52.098Z",
          "wordCount": 762,
          "title": "Optimal Approximation Rates and Metric Entropy of ReLU$^k$ and Cosine Networks. (arXiv:2101.12365v5 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08506",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Ahmed_S/0/1/0/all/0/1\">Sara Atito Ali Ahmed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yavuz_M/0/1/0/all/0/1\">Mehmet Can Yavuz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sen_M/0/1/0/all/0/1\">Mehmet Umut Sen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gulsen_F/0/1/0/all/0/1\">Fatih Gulsen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tutar_O/0/1/0/all/0/1\">Onur Tutar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korkmazer_B/0/1/0/all/0/1\">Bora Korkmazer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Samanci_C/0/1/0/all/0/1\">Cesur Samanci</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sirolu_S/0/1/0/all/0/1\">Sabri Sirolu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hamid_R/0/1/0/all/0/1\">Rauf Hamid</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Eryurekli_A/0/1/0/all/0/1\">Ali Ergun Eryurekli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mammadov_T/0/1/0/all/0/1\">Toghrul Mammadov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yanikoglu_B/0/1/0/all/0/1\">Berrin Yanikoglu</a>",
          "description": "Detecting COVID-19 in computed tomography (CT) or radiography images has been\nproposed as a supplement to the definitive RT-PCR test. We present a deep\nlearning ensemble for detecting COVID-19 infection, combining slice-based (2D)\nand volume-based (3D) approaches. The 2D system detects the infection on each\nCT slice independently, combining them to obtain the patient-level decision via\ndifferent methods (averaging and long-short term memory networks). The 3D\nsystem takes the whole CT volume to arrive to the",
          "link": "http://arxiv.org/abs/2105.08506",
          "publishedOn": "2021-05-22T03:02:52.046Z",
          "wordCount": 693,
          "title": "COVID-19 Detection in Computed Tomography Images with 2D and 3D Approaches. (arXiv:2105.08506v2 [eess.IV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.02694",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Perugachi_Diaz_Y/0/1/0/all/0/1\">Yura Perugachi-Diaz</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tomczak_J/0/1/0/all/0/1\">Jakub M. Tomczak</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bhulai_S/0/1/0/all/0/1\">Sandjai Bhulai</a>",
          "description": "We introduce Invertible Dense Networks (i-DenseNets), a more parameter\nefficient extension of Residual Flows. The method relies on an analysis of the\nLipschitz continuity of the concatenation in DenseNets, where we enforce\ninvertibility of the network by satisfying the Lipschitz constant. Furthermore,\nwe propose a learnable weighted concatenation, which not only improves the\nmodel performance but also indicates the importance of the concatenated\nweighted representation. Additionally, we introduce the Concat",
          "link": "http://arxiv.org/abs/2102.02694",
          "publishedOn": "2021-05-22T03:02:52.031Z",
          "wordCount": 588,
          "title": "Invertible DenseNets with Concatenated LipSwish. (arXiv:2102.02694v2 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.07662",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yuqing Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1\">Olivia Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1\">Deepak Pathak</a>",
          "description": "Policies trained in simulation often fail when transferred to the real world\ndue to the `reality gap' where the simulator is unable to accurately capture\nthe dynamics and visual properties of the real world. Current approaches to\ntackle this problem, such as domain randomization, require prior knowledge and\nengineering to determine how much to randomize system parameters in order to\nlearn a policy that is robust to sim-to-real transfer while also not being too\nconservative. We propose a method for automatic",
          "link": "http://arxiv.org/abs/2104.07662",
          "publishedOn": "2021-05-22T03:02:52.014Z",
          "wordCount": 681,
          "title": "Auto-Tuned Sim-to-Real Transfer. (arXiv:2104.07662v2 [cs.RO] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08869",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianchen Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chaosheng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jingyuan Deng</a>",
          "description": "In this paper, we investigate a new multi-armed bandit (MAB) online learning\nmodel that considers real-world phenomena in many recommender systems: (i) the\nlearning agent cannot pull the arms by itself and thus has to offer rewards to\nusers to incentivize arm-pulling indirectly; and (ii) if users with specific\narm preferences are well rewarded, they induce a \"self-reinforcing\" effect in\nthe sense that they will attract more users of similar arm preferences. Besides\naddressing the tradeoff of exploration and",
          "link": "http://arxiv.org/abs/2105.08869",
          "publishedOn": "2021-05-22T03:02:52.008Z",
          "wordCount": 672,
          "title": "Incentivized Bandit Learning with Self-Reinforcing User Preferences. (arXiv:2105.08869v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08911",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yueyao Yu</a>",
          "description": "What makes an artificial neural network easier to train and more likely to\nproduce desirable solutions than other comparable networks? In this paper, we\nprovide a new angle to study such issues under the setting of a fixed number of\nmodel parameters which in general is the most dominant cost factor. We\nintroduce a notion of variability and show that it correlates positively to the\nactivation ratio and negatively to a phenomenon called {Collapse to Constants}\n(or C2C), which is closely related but not identi",
          "link": "http://arxiv.org/abs/2105.08911",
          "publishedOn": "2021-05-22T03:02:51.959Z",
          "wordCount": 564,
          "title": "Variability of Artificial Neural Networks. (arXiv:2105.08911v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.02331",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ben_Basat_R/0/1/0/all/0/1\">Ran Ben-Basat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitzenmacher_M/0/1/0/all/0/1\">Michael Mitzenmacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargaftik_S/0/1/0/all/0/1\">Shay Vargaftik</a>",
          "description": "We consider the fundamental problem of communicating an estimate of a real\nnumber $x\\in[0,1]$ using a single bit. A sender that knows $x$ chooses a value\n$X\\in\\set{0,1}$ to transmit. In turn, a receiver estimates $x$ based on the\nvalue of $X$. We consider both the biased and unbiased estimation problems and\naim to minimize the cost. For the biased case, the cost is the worst-case (over\nthe choice of $x$) expected squared error, which coincides with the variance if\nthe algorithm is required to be unbiased.\n\n",
          "link": "http://arxiv.org/abs/2010.02331",
          "publishedOn": "2021-05-22T03:02:51.922Z",
          "wordCount": 664,
          "title": "How to send a real number using a single bit (and some shared randomness). (arXiv:2010.02331v4 [cs.DS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07775",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiangmeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guandong Xu</a>",
          "description": "In recommendation systems, the existence of the missing-not-at-random (MNAR)\nproblem results in the selection bias issue, degrading the recommendation\nperformance ultimately. A common practice to address MNAR is to treat missing\nentries from the so-called \"exposure\" perspective, i.e., modeling how an item\nis exposed (provided) to a user. Most of the existing approaches use heuristic\nmodels or re-weighting strategy on observed ratings to mimic the\nmissing-at-random setting. However, little research has been ",
          "link": "http://arxiv.org/abs/2105.07775",
          "publishedOn": "2021-05-22T03:02:51.917Z",
          "wordCount": 632,
          "title": "Be Causal: De-biasing Social Network Confounding in Recommendation. (arXiv:2105.07775v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.07495",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Majdabadi_M/0/1/0/all/0/1\">Mahdiyar Molahasani Majdabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Younhee Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deivalakshmi_S/0/1/0/all/0/1\">S. Deivalakshmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_S/0/1/0/all/0/1\">Seokbum Ko</a>",
          "description": "Prostate cancer is a very common disease among adult men. One in seven\nCanadian men is diagnosed with this cancer in their lifetime. Super-Resolution\n(SR) can facilitate early diagnosis and potentially save many lives. In this\npaper, a robust and accurate model is proposed for prostate MRI SR. The model\nis trained on the Prostate-Diagnosis and PROSTATEx datasets. The proposed model\noutperformed the state-of-the-art prostate SR model in all similarity metrics\nwith notable margins. A new task-specific similar",
          "link": "http://arxiv.org/abs/2105.07495",
          "publishedOn": "2021-05-22T03:02:51.868Z",
          "wordCount": 573,
          "title": "Capsule GAN for Prostate MRI Super-Resolution. (arXiv:2105.07495v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.11156",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Truong_L/0/1/0/all/0/1\">Lan V. Truong</a>",
          "description": "We establish exact asymptotic expressions for the normalized mutual\ninformation and minimum mean-square-error (MMSE) of sparse linear regression in\nthe sub-linear sparsity regime. Our result is achieved by a generalization of\nthe adaptive interpolation method in Bayesian inference for linear regimes to\nsub-linear ones. A modification of the well-known approximate message passing\nalgorithm to approach the MMSE fundamental limit is also proposed, and its\nstate evolution is rigorously analysed. Our results sho",
          "link": "http://arxiv.org/abs/2101.11156",
          "publishedOn": "2021-05-22T03:02:51.824Z",
          "wordCount": 596,
          "title": "Fundamental limits and algorithms for sparse linear regression with sublinear sparsity. (arXiv:2101.11156v3 [cs.IT] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09675",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Gruttemeier_N/0/1/0/all/0/1\">Niels Gr&#xfc;ttemeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komusiewicz_C/0/1/0/all/0/1\">Christian Komusiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morawietz_N/0/1/0/all/0/1\">Nils Morawietz</a>",
          "description": "A Bayesian network is a directed acyclic graph that represents statistical\ndependencies between variables of a joint probability distribution. A\nfundamental task in data science is to learn a Bayesian network from observed\ndata. \\textsc{Polytree Learning} is the problem of learning an optimal Bayesian\nnetwork that fulfills the additional property that its underlying undirected\ngraph is a forest. In this work, we revisit the complexity of \\textsc{Polytree\nLearning}. We show that \\textsc{Polytree Learning} ca",
          "link": "http://arxiv.org/abs/2105.09675",
          "publishedOn": "2021-05-22T03:02:51.793Z",
          "wordCount": 602,
          "title": "On the Parameterized Complexity of Polytree Learning. (arXiv:2105.09675v1 [cs.DS])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09468",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Tang_H/0/1/0/all/0/1\">Hewei Tang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Fu_P/0/1/0/all/0/1\">Pengcheng Fu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sherman_C/0/1/0/all/0/1\">Christopher S. Sherman</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_J/0/1/0/all/0/1\">Jize Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ju_X/0/1/0/all/0/1\">Xin Ju</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Hamon_F/0/1/0/all/0/1\">Fran&#xe7;ois Hamon</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Azzolina_N/0/1/0/all/0/1\">Nicholas A. Azzolina</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Burton_Kelly_M/0/1/0/all/0/1\">Matthew Burton-Kelly</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Morris_J/0/1/0/all/0/1\">Joseph P. Morris</a>",
          "description": "Fast assimilation of monitoring data to update forecasts of pressure buildup\nand carbon dioxide (CO2) plume migration under geologic uncertainties is a\nchallenging problem in geologic carbon storage. The high computational cost of\ndata assimilation with a high-dimensional parameter space impedes fast\ndecision-making for commercial-scale reservoir management. We propose to\nleverage physical understandings of porous medium flow behavior with deep\nlearning techniques to develop a fast history matching-reservoi",
          "link": "http://arxiv.org/abs/2105.09468",
          "publishedOn": "2021-05-22T03:02:51.787Z",
          "wordCount": 658,
          "title": "A Deep Learning-Accelerated Data Assimilation and Forecasting Workflow for Commercial-Scale Geologic Carbon Storage. (arXiv:2105.09468v1 [physics.geo-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2007.05929",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Schwarzer_M/0/1/0/all/0/1\">Max Schwarzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1\">Ankesh Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_R/0/1/0/all/0/1\">Rishab Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hjelm_R/0/1/0/all/0/1\">R Devon Hjelm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1\">Aaron Courville</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachman_P/0/1/0/all/0/1\">Philip Bachman</a>",
          "description": "While deep reinforcement learning excels at solving tasks where large amounts\nof data can be collected through virtually unlimited interaction with the\nenvironment, learning from limited interaction remains a key challenge. We\nposit that an agent can learn more efficiently if we augment reward\nmaximization with self-supervised objectives based on structure in its visual\ninput and sequential interaction with the environment. Our method,\nSelf-Predictive Representations(SPR), trains an agent to predict its own",
          "link": "http://arxiv.org/abs/2007.05929",
          "publishedOn": "2021-05-22T03:02:51.781Z",
          "wordCount": 723,
          "title": "Data-Efficient Reinforcement Learning with Self-Predictive Representations. (arXiv:2007.05929v4 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09685",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Borkar_J/0/1/0/all/0/1\">Jaydeep Borkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>",
          "description": "There has been a rise in the use of Machine Learning as a Service (MLaaS)\nVision APIs as they offer multiple services including pre-built models and\nalgorithms, which otherwise take a huge amount of resources if built from\nscratch. As these APIs get deployed for high-stakes applications, it's very\nimportant that they are robust to different manipulations. Recent works have\nonly focused on typical adversarial attacks when evaluating the robustness of\nvision APIs. We propose two new aspects of adversarial ima",
          "link": "http://arxiv.org/abs/2105.09685",
          "publishedOn": "2021-05-22T03:02:51.736Z",
          "wordCount": 694,
          "title": "Simple Transparent Adversarial Examples. (arXiv:2105.09685v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09394",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glasner_D/0/1/0/all/0/1\">Daniel Glasner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1\">Srikumar Ramalingam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papineni_K/0/1/0/all/0/1\">Kishore Papineni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>",
          "description": "It is generally believed that robust training of extremely large networks is\ncritical to their success in real-world applications. However, when taken to\nthe extreme, methods that promote robustness can hurt the model's sensitivity\nto rare or underrepresented patterns. In this paper, we discuss this trade-off\nbetween sensitivity and robustness to natural (non-adversarial) perturbations\nby introducing two notions: contextual feature utility and contextual feature\nsensitivity. We propose Feature Contrastive L",
          "link": "http://arxiv.org/abs/2105.09394",
          "publishedOn": "2021-05-22T03:02:51.724Z",
          "wordCount": 552,
          "title": "Balancing Robustness and Sensitivity using Feature Contrastive Learning. (arXiv:2105.09394v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/1812.00002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingyuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_S/0/1/0/all/0/1\">Sen Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Congzhou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>",
          "description": "Interactive news recommendation has been launched and attracted much\nattention recently. In this scenario, user's behavior evolves from single click\nbehavior to multiple behaviors including like, comment, share etc. However,\nmost of the existing methods still use single click behavior as the unique\ncriterion of judging user's preferences. Further, although heterogeneous graphs\nhave been applied in different areas, a proper way to construct a heterogeneous\ngraph for interactive news data with an appropriate ",
          "link": "http://arxiv.org/abs/1812.00002",
          "publishedOn": "2021-05-22T03:02:51.717Z",
          "wordCount": 678,
          "title": "The Graph-Based Behavior-Aware Recommendation for Interactive News. (arXiv:1812.00002v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09670",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhu_H/0/1/0/all/0/1\">Huolan Zhu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1\">Yongkai Chen</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Yang_C/0/1/0/all/0/1\">Chenguang Yang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cheng_H/0/1/0/all/0/1\">Huimin Cheng</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1\">Yi Li</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhong_W/0/1/0/all/0/1\">Wenxuan Zhong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wang_F/0/1/0/all/0/1\">Fang Wang</a>",
          "description": "Background: Extensive clinical evidence suggests that a preventive screening\nof coronary heart disease (CHD) at an earlier stage can greatly reduce the\nmortality rate. We use 64 two-dimensional speckle tracking echocardiography\n(2D-STE) features and seven clinical features to predict whether one has CHD.\nMethods: We develop a machine learning approach that integrates a number of\npopular classification methods together by model stacking, and generalize the\ntraditional stacking method to a two-step stacking m",
          "link": "http://arxiv.org/abs/2105.09670",
          "publishedOn": "2021-05-22T03:02:51.684Z",
          "wordCount": 612,
          "title": "Ensemble machine learning approach for screening of coronary heart disease based on echocardiography and risk factors. (arXiv:2105.09670v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2005.13934",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hug_R/0/1/0/all/0/1\">Ronny Hug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1\">Stefan Becker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hubner_W/0/1/0/all/0/1\">Wolfgang H&#xfc;bner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arens_M/0/1/0/all/0/1\">Michael Arens</a>",
          "description": "Methods to quantify the complexity of trajectory datasets are still a missing\npiece in benchmarking human trajectory prediction models. In order to gain a\nbetter understanding of the complexity of trajectory prediction tasks and\nfollowing the intuition, that more complex datasets contain more information,\nan approach for quantifying the amount of information contained in a dataset\nfrom a prototype-based dataset representation is proposed. The dataset\nrepresentation is obtained by first employing a non-trivi",
          "link": "http://arxiv.org/abs/2005.13934",
          "publishedOn": "2021-05-22T03:02:51.655Z",
          "wordCount": 600,
          "title": "Quantifying the Complexity of Standard Benchmarking Datasets for Long-Term Human Trajectory Prediction. (arXiv:2005.13934v4 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08769",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Walton_N/0/1/0/all/0/1\">Neil Walton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kuang Xu</a>",
          "description": "We review the role of information and learning in the stability and\noptimization of queueing systems. In recent years, techniques from supervised\nlearning, bandit learning and reinforcement learning have been applied to\nqueueing systems supported by increasing role of information in decision\nmaking. We present observations and new results that help rationalize the\napplication of these areas to queueing systems.\n\nWe prove that the MaxWeight and BackPressure policies are an application of\nBlackwell's Approach",
          "link": "http://arxiv.org/abs/2105.08769",
          "publishedOn": "2021-05-22T03:02:51.649Z",
          "wordCount": 609,
          "title": "Learning and Information in Stochastic Networks and Queues. (arXiv:2105.08769v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2010.03514",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wang-Zhou Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muggleton_S/0/1/0/all/0/1\">Stephen H. Muggleton</a>",
          "description": "For many reasoning-heavy tasks involving raw inputs, it is challenging to\ndesign an appropriate end-to-end learning pipeline. Neuro-Symbolic Learning,\ndivide the process into sub-symbolic perception and symbolic reasoning, trying\nto utilise data-driven machine learning and knowledge-driven reasoning\nsimultaneously. However, they suffer from the exponential computational\ncomplexity within the interface between these two components, where the\nsub-symbolic learning model lacks direct supervision, and the symbo",
          "link": "http://arxiv.org/abs/2010.03514",
          "publishedOn": "2021-05-22T03:02:51.619Z",
          "wordCount": 639,
          "title": "Abductive Knowledge Induction From Raw Data. (arXiv:2010.03514v2 [cs.AI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2008.09657",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nishad_S/0/1/0/all/0/1\">Sunil Nishad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Shubhangi Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Arnab Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranu_S/0/1/0/all/0/1\">Sayan Ranu</a>",
          "description": "Majority of the existing graph neural networks (GNN) learn node embeddings\nthat encode their local neighborhoods but not their positions. Consequently,\ntwo nodes that are vastly distant but located in similar local neighborhoods\nmap to similar embeddings in those networks. This limitation prevents accurate\nperformance in predictive tasks that rely on position information. In this\npaper,we develop GraphReach, a position-aware inductive GNN that captures the\nglobal positions of nodes through reachability esti",
          "link": "http://arxiv.org/abs/2008.09657",
          "publishedOn": "2021-05-22T03:02:51.608Z",
          "wordCount": 616,
          "title": "GraphReach: Position-Aware Graph Neural Network using Reachability Estimations. (arXiv:2008.09657v3 [cs.SI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.08791",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiaocheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhiwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yansheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Dingyuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1\">Bingchen Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yongxin Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongtu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jieping Ye</a>",
          "description": "Large ride-hailing platforms, such as DiDi, Uber and Lyft, connect tens of\nthousands of vehicles in a city to millions of ride demands throughout the day,\nproviding great promises for improving transportation efficiency through the\ntasks of order dispatching and vehicle repositioning. Existing studies,\nhowever, usually consider the two tasks in simplified settings that hardly\naddress the complex interactions between the two, the real-time fluctuations\nbetween supply and demand, and the necessary coordinatio",
          "link": "http://arxiv.org/abs/2105.08791",
          "publishedOn": "2021-05-22T03:02:51.591Z",
          "wordCount": 705,
          "title": "Value Function is All You Need: A Unified Learning Framework for Ride Hailing Platforms. (arXiv:2105.08791v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2103.00073",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1\">Nan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lutellier_T/0/1/0/all/0/1\">Thibaud Lutellier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1\">Lin Tan</a>",
          "description": "Automatic program repair (APR) is crucial to improve software reliability.\nRecently, neural machine translation (NMT) techniques have been used to fix\nsoftware bugs automatically. While promising, these approaches have two major\nlimitations. Their search space often does not contain the correct fix, and\ntheir search strategy ignores software knowledge such as strict code syntax.\nDue to these limitations, existing NMT-based techniques underperform the best\ntemplate-based approaches.\n\nWe propose CURE, a new N",
          "link": "http://arxiv.org/abs/2103.00073",
          "publishedOn": "2021-05-22T03:02:51.584Z",
          "wordCount": 659,
          "title": "CURE: Code-Aware Neural Machine Translation for Automatic Program Repair. (arXiv:2103.00073v3 [cs.SE] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2012.01059",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Paletta_Q/0/1/0/all/0/1\">Quentin Paletta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lasenby_J/0/1/0/all/0/1\">Joan Lasenby</a>",
          "description": "Improving irradiance forecasting is critical to further increase the share of\nsolar in the energy mix. On a short time scale, fish-eye cameras on the ground\nare used to capture cloud displacements causing the local variability of the\nelectricity production. As most of the solar radiation comes directly from the\nSun, current forecasting approaches use its position in the image as a\nreference to interpret the cloud cover dynamics. However, existing Sun tracking\nmethods rely on external data and a calibration ",
          "link": "http://arxiv.org/abs/2012.01059",
          "publishedOn": "2021-05-22T03:02:51.571Z",
          "wordCount": 634,
          "title": "A Temporally Consistent Image-based Sun Tracking Algorithm for Solar Energy Forecasting Applications. (arXiv:2012.01059v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2006.16362",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cordonnier_J/0/1/0/all/0/1\">Jean-Baptiste Cordonnier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loukas_A/0/1/0/all/0/1\">Andreas Loukas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>",
          "description": "Attention layers are widely used in natural language processing (NLP) and are\nbeginning to influence computer vision architectures. Training very large\ntransformer models allowed significant improvement in both fields, but once\ntrained, these networks show symptoms of over-parameterization. For instance,\nit is known that many attention heads can be pruned without impacting accuracy.\nThis work aims to enhance current understanding on how multiple heads interact.\nMotivated by the observation that attention he",
          "link": "http://arxiv.org/abs/2006.16362",
          "publishedOn": "2021-05-22T03:02:51.565Z",
          "wordCount": 628,
          "title": "Multi-Head Attention: Collaborate Instead of Concatenate. (arXiv:2006.16362v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2101.08413",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1\">Ruimin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiayi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">He Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Baofeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jie Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuting Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chunlei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuyao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1\">Jie Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Hongjiang Wei</a>",
          "description": "Quantitative susceptibility mapping (QSM) has demonstrated great potential in\nquantifying tissue susceptibility in various brain diseases. However, the\nintrinsic ill-posed inverse problem relating the tissue phase to the underlying\nsusceptibility distribution affects the accuracy for quantifying tissue\nsusceptibility. Recently, deep learning has shown promising results to improve\naccuracy by reducing the streaking artifacts. However, there exists a mismatch\nbetween the observed phase and the theoretical for",
          "link": "http://arxiv.org/abs/2101.08413",
          "publishedOn": "2021-05-22T03:02:51.559Z",
          "wordCount": 660,
          "title": "MoDL-QSM: Model-based Deep Learning for Quantitative Susceptibility Mapping. (arXiv:2101.08413v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.05824",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Joseph_J/0/1/0/all/0/1\">Joel Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_A/0/1/0/all/0/1\">Alex Gu</a>",
          "description": "The Continual Learning (CL) problem involves performing well on a sequence of\ntasks under limited compute. Current algorithms in the domain are either slow,\noffline or sensitive to hyper-parameters. La-MAML, an optimization-based\nmeta-learning algorithm claims to be better than other replay-based,\nprior-based and meta-learning based approaches. According to the MER paper [1],\nmetrics to measure performance in the continual learning arena are Retained\nAccuracy (RA) and Backward Transfer-Interference (BTI). L",
          "link": "http://arxiv.org/abs/2102.05824",
          "publishedOn": "2021-05-22T03:02:51.542Z",
          "wordCount": 550,
          "title": "Reproducibility Report: La-MAML: Look-ahead Meta Learning for Continual Learning. (arXiv:2102.05824v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2104.04785",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1\">Bj&#xf6;rn L&#xfc;tjens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leshchinskiy_B/0/1/0/all/0/1\">Brandon Leshchinskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Requena_Mesa_C/0/1/0/all/0/1\">Christian Requena-Mesa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chishtie_F/0/1/0/all/0/1\">Farrukh Chishtie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_Rodriguez_N/0/1/0/all/0/1\">Natalia D&#xed;az-Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boulais_O/0/1/0/all/0/1\">Oc&#xe9;ane Boulais</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankaranarayanan_A/0/1/0/all/0/1\">Aruna Sankaranarayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pina_A/0/1/0/all/0/1\">Aaron Pi&#xf1;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raissi_C/0/1/0/all/0/1\">Chedy Ra&#xef;ssi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavin_A/0/1/0/all/0/1\">Alexander Lavin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Newman_D/0/1/0/all/0/1\">Dava Newman</a>",
          "description": "As climate change increases the intensity of natural disasters, society needs\nbetter tools for adaptation. Floods, for example, are the most frequent natural\ndisaster, and better tools for flood risk communication could increase the\nsupport for flood-resilient infrastructure development. Our work aims to enable\nmore visual communication of large-scale climate impacts via visualizing the\noutput of coastal flood models as satellite imagery. We propose the first deep\nlearning pipeline to ensure physical-consis",
          "link": "http://arxiv.org/abs/2104.04785",
          "publishedOn": "2021-05-22T03:02:51.521Z",
          "wordCount": 685,
          "title": "Physically-Consistent Generative Adversarial Networks for Coastal Flood Visualization. (arXiv:2104.04785v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09837",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_Z/0/1/0/all/0/1\">Zheng Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongchao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yue Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>",
          "description": "The Graph Augmented Multi-layer Perceptron (GA-MLP) model is an attractive\nalternative to Graph Neural Networks (GNNs). This is because it is resistant to\nthe over-smoothing problem, and deeper GA-MLP models yield better performance.\nGA-MLP models are traditionally optimized by the Stochastic Gradient Descent\n(SGD). However, SGD suffers from the layer dependency problem, which prevents\nthe gradients of different layers of GA-MLP models from being calculated in\nparallel. In this paper, we propose a parallel ",
          "link": "http://arxiv.org/abs/2105.09837",
          "publishedOn": "2021-05-22T03:02:51.493Z",
          "wordCount": 638,
          "title": "Towards Quantized Model Parallelism for Graph-Augmented MLPs Based on Gradient-Free ADMM framework. (arXiv:2105.09837v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2007.06284",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yamshchikov_I/0/1/0/all/0/1\">Ivan P. Yamshchikov</a>",
          "description": "This paper addresses the issue of long-scale correlations that is\ncharacteristic for symbolic music and is a challenge for modern generative\nalgorithms. It suggests a very simple workaround for this challenge, namely,\ngeneration of a drum pattern that could be further used as a foundation for\nmelody generation. The paper presents a large dataset of drum patterns\nalongside with corresponding melodies. It explores two possible methods for\ndrum pattern generation. Exploring a latent space of drum patterns one ",
          "link": "http://arxiv.org/abs/2007.06284",
          "publishedOn": "2021-05-22T03:02:51.488Z",
          "wordCount": 604,
          "title": "Artificial Neural Networks Jamming on the Beat. (arXiv:2007.06284v3 [eess.AS] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2102.03814",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Autthasan_P/0/1/0/all/0/1\">Phairot Autthasan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chaisaen_R/0/1/0/all/0/1\">Rattanaphon Chaisaen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sudhawiyangkul_T/0/1/0/all/0/1\">Thapanun Sudhawiyangkul</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rangpong_P/0/1/0/all/0/1\">Phurin Rangpong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kiatthaveephong_S/0/1/0/all/0/1\">Suktipol Kiatthaveephong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dilokthanakul_N/0/1/0/all/0/1\">Nat Dilokthanakul</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bhakdisongkhram_G/0/1/0/all/0/1\">Gun Bhakdisongkhram</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Phan_H/0/1/0/all/0/1\">Huy Phan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guan_C/0/1/0/all/0/1\">Cuntai Guan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wilaiprasitporn_T/0/1/0/all/0/1\">Theerawit Wilaiprasitporn</a>",
          "description": "Advances in the motor imagery (MI)-based brain-computer interfaces (BCIs)\nallow control of several applications by decoding neurophysiological phenomena,\nwhich are usually recorded by electroencephalography (EEG) using a non-invasive\ntechnique. Despite great advances in MI-based BCI, EEG rhythms are specific to\na subject and various changes over time. These issues point to significant\nchallenges to enhance the classification performance, especially in a\nsubject-independent manner. To overcome these challeng",
          "link": "http://arxiv.org/abs/2102.03814",
          "publishedOn": "2021-05-22T03:02:51.474Z",
          "wordCount": 664,
          "title": "MIN2Net: End-to-End Multi-Task Learning for Subject-Independent Motor Imagery EEG Classification. (arXiv:2102.03814v3 [eess.SP] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09872",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Yoon_J/0/1/0/all/0/1\">Jun Ho Yoon</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1\">Seyoung Kim</a>",
          "description": "In many real-world problems, complex dependencies are present both among\nsamples and among features. The Kronecker sum or the Cartesian product of two\ngraphs, each modeling dependencies across features and across samples, has been\nused as an inverse covariance matrix for a matrix-variate Gaussian\ndistribution, as an alternative to a Kronecker-product inverse covariance\nmatrix, due to its more intuitive sparse structure. However, the existing\nmethods for sparse Kronecker-sum inverse covariance estimation are",
          "link": "http://arxiv.org/abs/2105.09872",
          "publishedOn": "2021-05-22T03:02:51.458Z",
          "wordCount": 626,
          "title": "EiGLasso for Scalable Sparse Kronecker-Sum Inverse Covariance Estimation. (arXiv:2105.09872v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2010.01017",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qinbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Bingsheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>",
          "description": "Federated learning enables multiple parties to collaboratively learn a model\nwithout exchanging their data. While most existing federated learning\nalgorithms need many rounds to converge, one-shot federated learning (i.e.,\nfederated learning with a single communication round) is a promising approach\nto make federated learning applicable in cross-silo setting in practice.\nHowever, existing one-shot algorithms only support specific models and do not\nprovide any privacy guarantees, which significantly limit th",
          "link": "http://arxiv.org/abs/2010.01017",
          "publishedOn": "2021-05-22T03:02:51.450Z",
          "wordCount": 581,
          "title": "Practical One-Shot Federated Learning for Cross-Silo Setting. (arXiv:2010.01017v2 [cs.LG] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2007.13693",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pares_F/0/1/0/all/0/1\">Ferran Par&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arias_Duart_A/0/1/0/all/0/1\">Anna Arias-Duart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Gasulla_D/0/1/0/all/0/1\">Dario Garcia-Gasulla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campo_Frances_G/0/1/0/all/0/1\">Gema Campo-Franc&#xe9;s</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viladrich_N/0/1/0/all/0/1\">Nina Viladrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayguade_E/0/1/0/all/0/1\">Eduard Ayguad&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labarta_J/0/1/0/all/0/1\">Jes&#xfa;s Labarta</a>",
          "description": "In the image classification task, the most common approach is to resize all\nimages in a dataset to a unique shape, while reducing their precision to a size\nwhich facilitates experimentation at scale. This practice has benefits from a\ncomputational perspective, but it entails negative side-effects on performance\ndue to loss of information and image deformation. In this work we introduce the\nMAMe dataset, an image classification dataset with remarkable high resolution\nand variable shape properties. The goal o",
          "link": "http://arxiv.org/abs/2007.13693",
          "publishedOn": "2021-05-22T03:02:51.439Z",
          "wordCount": 725,
          "title": "The MAMe Dataset: On the relevance of High Resolution and Variable Shape image properties. (arXiv:2007.13693v3 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/1912.07913",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Grelier_E/0/1/0/all/0/1\">Erwan Grelier</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nouy_A/0/1/0/all/0/1\">Anthony Nouy</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lebrun_R/0/1/0/all/0/1\">R&#xe9;gis Lebrun</a>",
          "description": "We consider the problem of the estimation of a high-dimensional probability\ndistribution from i.i.d. samples of the distribution using model classes of\nfunctions in tree-based tensor formats, a particular case of tensor networks\nassociated with a dimension partition tree. The distribution is assumed to\nadmit a density with respect to a product measure, possibly discrete for\nhandling the case of discrete random variables.\n\nAfter discussing the representation of classical model classes in tree-based\ntensor fo",
          "link": "http://arxiv.org/abs/1912.07913",
          "publishedOn": "2021-05-22T03:02:51.396Z",
          "wordCount": 685,
          "title": "Learning high-dimensional probability distributions using tree tensor networks. (arXiv:1912.07913v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09856",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1\">Patrick Lumban Tobing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>",
          "description": "This paper presents a novel high-fidelity and low-latency universal neural\nvocoder framework based on multiband WaveRNN with data-driven linear prediction\nfor discrete waveform modeling (MWDLP). MWDLP employs a coarse-fine bit WaveRNN\narchitecture for 10-bit mu-law waveform modeling. A sparse gated recurrent unit\nwith a relatively large size of hidden units is utilized, while the multiband\nmodeling is deployed to achieve real-time low-latency usage. A novel technique\nfor data-driven linear prediction (LP) w",
          "link": "http://arxiv.org/abs/2105.09856",
          "publishedOn": "2021-05-22T03:02:51.380Z",
          "wordCount": 635,
          "title": "High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling. (arXiv:2105.09856v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2008.02995",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Zhong_W/0/1/0/all/0/1\">Wenxuan Zhong</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_P/0/1/0/all/0/1\">Ping Ma</a>",
          "description": "Optimal transport has been one of the most exciting subjects in mathematics,\nstarting from the 18th century. As a powerful tool to transport between two\nprobability measures, optimal transport methods have been reinvigorated\nnowadays in a remarkable proliferation of modern data science applications. To\nmeet the big data challenges, various computational tools have been developed\nin the recent decade to accelerate the computation for optimal transport\nmethods. In this review, we present some cutting-edge com",
          "link": "http://arxiv.org/abs/2008.02995",
          "publishedOn": "2021-05-22T03:02:51.375Z",
          "wordCount": 566,
          "title": "A Review on Modern Computational Optimal Transport Methods with Applications in Biomedical Research. (arXiv:2008.02995v3 [stat.ML] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09938",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1\">Dan Hendrycks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1\">Steven Basart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadavath_S/0/1/0/all/0/1\">Saurav Kadavath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mazeika_M/0/1/0/all/0/1\">Mantas Mazeika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1\">Akul Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_E/0/1/0/all/0/1\">Ethan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burns_C/0/1/0/all/0/1\">Collin Burns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puranik_S/0/1/0/all/0/1\">Samir Puranik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Horace He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>",
          "description": "While programming is one of the most broadly applicable skills in modern\nsociety, modern machine learning models still cannot code solutions to basic\nproblems. It can be difficult to accurately assess code generation performance,\nand there has been surprisingly little work on evaluating code generation in a\nway that is both flexible and rigorous. To meet this challenge, we introduce\nAPPS, a benchmark for code generation. Unlike prior work in more restricted\nsettings, our benchmark measures the ability of mo",
          "link": "http://arxiv.org/abs/2105.09938",
          "publishedOn": "2021-05-22T03:02:51.363Z",
          "wordCount": 662,
          "title": "Measuring Coding Challenge Competence With APPS. (arXiv:2105.09938v1 [cs.SE])"
        },
        {
          "id": "http://arxiv.org/abs/2003.01383",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siebert_J/0/1/0/all/0/1\">Jan Paul Siebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiangrong Xu</a>",
          "description": "This paper proposes a novel automatically generating image masks method for\nthe state-of-the-art Mask R-CNN deep learning method. The Mask R-CNN method\nachieves the best results in object detection until now, however, it is very\ntime-consuming and laborious to get the object Masks for training, the proposed\nmethod is composed by a two-stage design, to automatically generating image\nmasks, the first stage implements a fully convolutional networks (FCN) based\nsegmentation network, the second stage network, a ",
          "link": "http://arxiv.org/abs/2003.01383",
          "publishedOn": "2021-05-22T03:02:51.356Z",
          "wordCount": 603,
          "title": "Fully Convolutional Networks for Automatically Generating Image Masks to Train Mask R-CNN. (arXiv:2003.01383v2 [cs.CV] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09908",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wangyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Abraham Noah Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biljecki_F/0/1/0/all/0/1\">Filip Biljecki</a>",
          "description": "There is a prevailing trend to study urban morphology quantitatively thanks\nto the growing accessibility to various forms of spatial big data, increasing\ncomputing power, and use cases benefiting from such information. The methods\ndeveloped up to now measure urban morphology with numerical indices describing\ndensity, proportion, and mixture, but they do not directly represent\nmorphological features from human's visual and intuitive perspective. We take\nthe first step to bridge the gap by proposing a deep le",
          "link": "http://arxiv.org/abs/2105.09908",
          "publishedOn": "2021-05-22T03:02:51.284Z",
          "wordCount": 703,
          "title": "Classification of Urban Morphology with Deep Learning: Application on Urban Vitality. (arXiv:2105.09908v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09930",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Sodhi_S/0/1/0/all/0/1\">Sukhdeep S. Sodhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chio_E/0/1/0/all/0/1\">Ellie Ka-In Chio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jash_A/0/1/0/all/0/1\">Ambarish Jash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1\">Santiago Onta&#xf1;&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apte_A/0/1/0/all/0/1\">Ajit Apte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Ankit Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeje_A/0/1/0/all/0/1\">Ayooluwakunmi Jeje</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuzmin_D/0/1/0/all/0/1\">Dima Kuzmin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_H/0/1/0/all/0/1\">Harry Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Tze Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Effrat_J/0/1/0/all/0/1\">Jon Effrat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bali_T/0/1/0/all/0/1\">Tarush Bali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1\">Nitin Jindal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_P/0/1/0/all/0/1\">Pei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sarvjeet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Senqiang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1\">Tameen Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wankhede_A/0/1/0/all/0/1\">Amol Wankhede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alzantot_M/0/1/0/all/0/1\">Moustafa Alzantot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Allen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra_T/0/1/0/all/0/1\">Tushar Chandra</a>",
          "description": "As more and more online search queries come from voice, automatic speech\nrecognition becomes a key component to deliver relevant search results. Errors\nintroduced by automatic speech recognition (ASR) lead to irrelevant search\nresults returned to the user, thus causing user dissatisfaction. In this paper,\nwe introduce an approach, Mondegreen, to correct voice queries in text space\nwithout depending on audio signals, which may not always be available due to\nsystem constraints or privacy or bandwidth (for exa",
          "link": "http://arxiv.org/abs/2105.09930",
          "publishedOn": "2021-05-22T03:02:51.199Z",
          "wordCount": 678,
          "title": "Mondegreen: A Post-Processing Solution to Speech Recognition Error Correction for Voice Search Queries. (arXiv:2105.09930v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09858",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1\">Patrick Lumban Tobing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>",
          "description": "This paper presents a low-latency real-time (LLRT) non-parallel voice\nconversion (VC) framework based on cyclic variational autoencoder (CycleVAE)\nand multiband WaveRNN with data-driven linear prediction (MWDLP). CycleVAE is a\nrobust non-parallel multispeaker spectral model, which utilizes a\nspeaker-independent latent space and a speaker-dependent code to generate\nreconstructed/converted spectral features given the spectral features of an\ninput speaker. On the other hand, MWDLP is an efficient and a high-qu",
          "link": "http://arxiv.org/abs/2105.09858",
          "publishedOn": "2021-05-22T03:02:51.191Z",
          "wordCount": 646,
          "title": "Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear Prediction. (arXiv:2105.09858v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09737",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Arnavaz_K/0/1/0/all/0/1\">Kasra Arnavaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_O/0/1/0/all/0/1\">Oswin Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krivokapic_J/0/1/0/all/0/1\">Jelena M. Krivokapic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heilmann_S/0/1/0/all/0/1\">Silja Heilmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baerentzen_J/0/1/0/all/0/1\">Jakob Andreas B&#xe6;rentzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nyeng_P/0/1/0/all/0/1\">Pia Nyeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feragen_A/0/1/0/all/0/1\">Aasa Feragen</a>",
          "description": "Motivated by a challenging tubular network segmentation task, this paper\ntackles two commonly encountered problems in biomedical imaging: Topological\nconsistency of the segmentation, and limited annotations. We propose a\ntopological score which measures both topological and geometric consistency\nbetween the predicted and ground truth segmentations, applied for model\nselection and validation. We apply our topological score in three scenarios: i.\na U-net ii. a U-net pretrained on an autoencoder, and iii. a se",
          "link": "http://arxiv.org/abs/2105.09737",
          "publishedOn": "2021-05-22T03:02:51.183Z",
          "wordCount": 590,
          "title": "Semi-supervised, Topology-Aware Segmentation of Tubular Structures from Live Imaging 3D Microscopy. (arXiv:2105.09737v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09903",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Madan_M/0/1/0/all/0/1\">Manav Madan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakob_P/0/1/0/all/0/1\">Peter Jakob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_Schirling_T/0/1/0/all/0/1\">Tobias Schmid-Schirling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valada_A/0/1/0/all/0/1\">Abhinav Valada</a>",
          "description": "Multi-view classification is inspired by the behavior of humans, especially\nwhen fine-grained features or in our case rarely occurring anomalies are to be\ndetected. Current contributions point to the problem of how high-dimensional\ndata can be fused. In this work, we build upon the deep support vector data\ndescription algorithm and address multi-perspective anomaly detection using\nthree different fusion techniques i.e. early fusion, late fusion, and late\nfusion with multiple decoders. We employ different au",
          "link": "http://arxiv.org/abs/2105.09903",
          "publishedOn": "2021-05-22T03:02:51.177Z",
          "wordCount": 633,
          "title": "Multi-Perspective Anomaly Detection. (arXiv:2105.09903v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09580",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dong_N/0/1/0/all/0/1\">Nanqing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kampffmeyer_M/0/1/0/all/0/1\">Michael Kampffmeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voiculescu_I/0/1/0/all/0/1\">Irina Voiculescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>",
          "description": "Entanglement is a physical phenomenon, which has fueled recent successes of\nquantum algorithms. Although quantum neural networks (QNNs) have shown\npromising results in solving simple machine learning tasks recently, for the\ntime being, the effect of entanglement in QNNs and the behavior of QNNs in\nbinary pattern classification are still underexplored. In this work, we provide\nsome theoretical insight into the properties of QNNs by presenting and\nanalyzing a new form of invariance embedded in QNNs for both q",
          "link": "http://arxiv.org/abs/2105.09580",
          "publishedOn": "2021-05-22T03:02:51.172Z",
          "wordCount": 634,
          "title": "Negational Symmetry of Quantum Neural Networks for Binary Pattern Classification. (arXiv:2105.09580v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09506",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Cai_S/0/1/0/all/0/1\">Shengze Cai</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mao_Z/0/1/0/all/0/1\">Zhiping Mao</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wang_Z/0/1/0/all/0/1\">Zhicheng Wang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yin_M/0/1/0/all/0/1\">Minglang Yin</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "Despite the significant progress over the last 50 years in simulating flow\nproblems using numerical discretization of the Navier-Stokes equations (NSE),\nwe still cannot incorporate seamlessly noisy data into existing algorithms,\nmesh-generation is complex, and we cannot tackle high-dimensional problems\ngoverned by parametrized NSE. Moreover, solving inverse flow problems is often\nprohibitively expensive and requires complex and expensive formulations and new\ncomputer codes. Here, we review flow physics-info",
          "link": "http://arxiv.org/abs/2105.09506",
          "publishedOn": "2021-05-22T03:02:51.154Z",
          "wordCount": 535,
          "title": "Physics-informed neural networks (PINNs) for fluid mechanics: A review. (arXiv:2105.09506v1 [physics.flu-dyn])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanxiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "Recommender systems are gaining increasing and critical impacts on human and\nsociety since a growing number of users use them for information seeking and\ndecision making. Therefore, it is crucial to address the potential unfairness\nproblems in recommendations. Just like users have personalized preferences on\nitems, users' demands for fairness are also personalized in many scenarios.\nTherefore, it is important to provide personalized fair recommendations for\nusers to satisfy their personalized fairness deman",
          "link": "http://arxiv.org/abs/2105.09829",
          "publishedOn": "2021-05-22T03:02:51.148Z",
          "wordCount": 630,
          "title": "Towards Personalized Fairness based on Causal Notion. (arXiv:2105.09829v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09788",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Liu_R/0/1/0/all/0/1\">Ruiqi Liu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Xu_G/0/1/0/all/0/1\">Ganggang Xu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Shang_Z/0/1/0/all/0/1\">Zuofeng Shang</a>",
          "description": "When data is of an extraordinarily large size or physically stored in\ndifferent locations, the distributed nearest neighbor (NN) classifier is an\nattractive tool for classification. We propose a novel distributed adaptive NN\nclassifier for which the number of nearest neighbors is a tuning parameter\nstochastically chosen by a data-driven criterion. An early stopping rule is\nproposed when searching for the optimal tuning parameter, which not only speeds\nup the computation but also improves the finite sample p",
          "link": "http://arxiv.org/abs/2105.09788",
          "publishedOn": "2021-05-22T03:02:51.142Z",
          "wordCount": 571,
          "title": "Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory. (arXiv:2105.09788v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09821",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Awad_N/0/1/0/all/0/1\">Noor Awad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallik_N/0/1/0/all/0/1\">Neeratyoy Mallik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1\">Frank Hutter</a>",
          "description": "Modern machine learning algorithms crucially rely on several design decisions\nto achieve strong performance, making the problem of Hyperparameter\nOptimization (HPO) more important than ever. Here, we combine the advantages of\nthe popular bandit-based HPO method Hyperband (HB) and the evolutionary search\napproach of Differential Evolution (DE) to yield a new HPO method which we call\nDEHB. Comprehensive results on a very broad range of HPO problems, as well as a\nwide range of tabular benchmarks from neural ar",
          "link": "http://arxiv.org/abs/2105.09821",
          "publishedOn": "2021-05-22T03:02:51.135Z",
          "wordCount": 571,
          "title": "DEHB: Evolutionary Hyberband for Scalable, Robust and Efficient Hyperparameter Optimization. (arXiv:2105.09821v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09855",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_L/0/1/0/all/0/1\">Lekshmi Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murthy_C/0/1/0/all/0/1\">Chandra R. Murthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_H/0/1/0/all/0/1\">Himanshu Tyagi</a>",
          "description": "In the problem of multiple support recovery, we are given access to linear\nmeasurements of multiple sparse samples in $\\mathbb{R}^{d}$. These samples can\nbe partitioned into $\\ell$ groups, with samples having the same support\nbelonging to the same group. For a given budget of $m$ measurements per sample,\nthe goal is to recover the $\\ell$ underlying supports, in the absence of the\nknowledge of group labels. We study this problem with a focus on the\nmeasurement-constrained regime where $m$ is smaller than the",
          "link": "http://arxiv.org/abs/2105.09855",
          "publishedOn": "2021-05-22T03:02:51.129Z",
          "wordCount": 591,
          "title": "Multiple Support Recovery Using Very Few Measurements Per Sample. (arXiv:2105.09855v1 [cs.IT])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09557",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Mori_T/0/1/0/all/0/1\">Takashi Mori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1\">Liu Ziyin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kangqiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1\">Masahito Ueda</a>",
          "description": "Stochastic gradient descent (SGD) undergoes complicated multiplicative noise\nfor the mean-square loss. We use this property of the SGD noise to derive a\nstochastic differential equation (SDE) with simpler additive noise by\nperforming a non-uniform transformation of the time variable. In the SDE, the\ngradient of the loss is replaced by that of the logarithmized loss.\nConsequently, we show that, near a local or global minimum, the stationary\ndistribution $P_\\mathrm{ss}(\\theta)$ of the network parameters $\\the",
          "link": "http://arxiv.org/abs/2105.09557",
          "publishedOn": "2021-05-22T03:02:51.121Z",
          "wordCount": 604,
          "title": "Logarithmic landscape and power-law escape rate of SGD. (arXiv:2105.09557v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09783",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Thai_B/0/1/0/all/0/1\">Binh Nguyen-Thai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1\">Vuong Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morgan_C/0/1/0/all/0/1\">Catherine Morgan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badawi_N/0/1/0/all/0/1\">Nadia Badawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Truyen Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1\">Svetha Venkatesh</a>",
          "description": "The absence or abnormality of fidgety movements of joints or limbs is\nstrongly indicative of cerebral palsy in infants. Developing computer-based\nmethods for assessing infant movements in videos is pivotal for improved\ncerebral palsy screening. Most existing methods use appearance-based features\nand are thus sensitive to strong but irrelevant signals caused by background\nclutter or a moving camera. Moreover, these features are computed over the\nwhole frame, thus they measure gross whole body movements rathe",
          "link": "http://arxiv.org/abs/2105.09783",
          "publishedOn": "2021-05-22T03:02:51.104Z",
          "wordCount": 657,
          "title": "A Spatio-temporal Attention-based Model for Infant Movement Assessment from Videos. (arXiv:2105.09783v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09679",
          "author": "<a href=\"http://arxiv.org/find/cond-mat/1/au:+Kimura_S/0/1/0/all/0/1\">Shun Kimura</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Ota_K/0/1/0/all/0/1\">Keisuke Ota</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Takeda_K/0/1/0/all/0/1\">Koujin Takeda</a>",
          "description": "Neuronal ensemble inference is a significant problem in the study of\nbiological neural networks. Various methods have been proposed for ensemble\ninference from experimental data of neuronal activity. Among them, Bayesian\ninference approach with generative model was proposed recently. However, this\nmethod requires large computational cost for appropriate inference. In this\nwork, we give an improved Bayesian inference algorithm by modifying update rule\nin Markov chain Monte Carlo method and introducing the id",
          "link": "http://arxiv.org/abs/2105.09679",
          "publishedOn": "2021-05-22T03:02:51.097Z",
          "wordCount": 556,
          "title": "Improved Neuronal Ensemble Inference with Generative Model and MCMC. (arXiv:2105.09679v1 [cond-mat.dis-nn])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09564",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhiqiang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Cong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yunxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_J/0/1/0/all/0/1\">Jingwen Leng</a>",
          "description": "Leveraging sparsity in deep neural network (DNN) models is promising for\naccelerating model inference. Yet existing GPUs can only leverage the sparsity\nfrom weights but not activations, which are dynamic, unpredictable, and hence\nchallenging to exploit. In this work, we propose a novel architecture to\nefficiently harness the dual-side sparsity (i.e., weight and activation\nsparsity). We take a systematic approach to understand the (dis)advantages of\nprevious sparsity-related architectures and propose a novel",
          "link": "http://arxiv.org/abs/2105.09564",
          "publishedOn": "2021-05-22T03:02:51.090Z",
          "wordCount": 586,
          "title": "Dual-side Sparse Tensor Core. (arXiv:2105.09564v1 [cs.AR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09540",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaolin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shuai Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1\">Hao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zejin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongji Wang</a>",
          "description": "The increasing concerns about data privacy and security drives the emergence\nof a new field of studying privacy-preserving machine learning from isolated\ndata sources, i.e., \\textit{federated learning}. Vertical federated learning,\nwhere different parties hold different features for common users, has a great\npotential of driving a more variety of business cooperation among enterprises\nin different fields. Decision tree models especially decision tree ensembles\nare a class of widely applied powerful machine ",
          "link": "http://arxiv.org/abs/2105.09540",
          "publishedOn": "2021-05-22T03:02:51.084Z",
          "wordCount": 684,
          "title": "Fed-EINI: An Efficient and Interpretable Inference Framework for Decision Tree Ensembles in Federated Learning. (arXiv:2105.09540v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09618",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Malem_Shinitski_N/0/1/0/all/0/1\">Noa Malem-Shinitski</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ojeda_C/0/1/0/all/0/1\">Cesar Ojeda</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Opper_M/0/1/0/all/0/1\">Manfred Opper</a>",
          "description": "Traditionally, Hawkes processes are used to model time--continuous point\nprocesses with history dependence. Here we propose an extended model where the\nself--effects are of both excitatory and inhibitory type and follow a Gaussian\nProcess. Whereas previous work either relies on a less flexible\nparameterization of the model, or requires a large amount of data, our\nformulation allows for both a flexible model and learning when data are scarce.\nWe continue the line of work of Bayesian inference for Hawkes proc",
          "link": "http://arxiv.org/abs/2105.09618",
          "publishedOn": "2021-05-22T03:02:51.077Z",
          "wordCount": 584,
          "title": "Nonlinear Hawkes Process with Gaussian Process Self Effects. (arXiv:2105.09618v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09720",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Mudiyanselage_T/0/1/0/all/0/1\">Thosini Bamunu Mudiyanselage</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Senanayake_N/0/1/0/all/0/1\">Nipuna Senanayake</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ji_C/0/1/0/all/0/1\">Chunyan Ji</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pan_Y/0/1/0/all/0/1\">Yi Pan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanqing Zhang</a>",
          "description": "The novel corona virus (Covid-19) has introduced significant challenges due\nto its rapid spreading nature through respiratory transmission. As a result,\nthere is a huge demand for Artificial Intelligence (AI) based quick disease\ndiagnosis methods as an alternative to high demand tests such as Polymerase\nChain Reaction (PCR). Chest X-ray (CXR) Image analysis is such cost-effective\nradiography technique due to resource availability and quick screening. But, a\nsufficient and systematic data collection that is ",
          "link": "http://arxiv.org/abs/2105.09720",
          "publishedOn": "2021-05-22T03:02:51.060Z",
          "wordCount": 747,
          "title": "Covid-19 Detection from Chest X-ray and Patient Metadata using Graph Convolutional Neural Networks. (arXiv:2105.09720v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09787",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Devleena Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishimura_Y/0/1/0/all/0/1\">Yasutaka Nishimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vivek_R/0/1/0/all/0/1\">Rajan P. Vivek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_N/0/1/0/all/0/1\">Naoto Takeda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fish_S/0/1/0/all/0/1\">Sean T. Fish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ploetz_T/0/1/0/all/0/1\">Thomas Ploetz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chernova_S/0/1/0/all/0/1\">Sonia Chernova</a>",
          "description": "Smart home environments are designed to provide services that help improve\nthe quality of life for the occupant via a variety of sensors and actuators\ninstalled throughout the space. Many automated actions taken by a smart home\nare governed by the output of an underlying activity recognition system.\nHowever, activity recognition systems may not be perfectly accurate and\ntherefore inconsistencies in smart home operations can lead a user to wonder\n\"why did the smart home do that?\" In this work, we build on in",
          "link": "http://arxiv.org/abs/2105.09787",
          "publishedOn": "2021-05-22T03:02:51.054Z",
          "wordCount": 704,
          "title": "Explainable Activity Recognition for Smart Home Systems. (arXiv:2105.09787v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09513",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jagtap_A/0/1/0/all/0/1\">Ameya D. Jagtap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1\">Yeonjong Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>",
          "description": "We propose a new type of neural networks, Kronecker neural networks (KNNs),\nthat form a general framework for neural networks with adaptive activation\nfunctions. KNNs employ the Kronecker product, which provides an efficient way\nof constructing a very wide network while keeping the number of parameters low.\nOur theoretical analysis reveals that under suitable conditions, KNNs induce a\nfaster decay of the loss than that by the feed-forward networks. This is also\nempirically verified through a set of computat",
          "link": "http://arxiv.org/abs/2105.09513",
          "publishedOn": "2021-05-22T03:02:51.048Z",
          "wordCount": 632,
          "title": "Deep Kronecker neural networks: A general framework for neural networks with adaptive activation functions. (arXiv:2105.09513v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09601",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Atri_Y/0/1/0/all/0/1\">Yash Kumar Atri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pramanick_S/0/1/0/all/0/1\">Shraman Pramanick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_V/0/1/0/all/0/1\">Vikram Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>",
          "description": "In recent years, abstractive text summarization with multimodal inputs has\nstarted drawing attention due to its ability to accumulate information from\ndifferent source modalities and generate a fluent textual summary. However,\nexisting methods use short videos as the visual modality and short summary as\nthe ground-truth, therefore, perform poorly on lengthy videos and long\nground-truth summary. Additionally, there exists no benchmark dataset to\ngeneralize this task on videos of varying lengths. In this pape",
          "link": "http://arxiv.org/abs/2105.09601",
          "publishedOn": "2021-05-22T03:02:51.042Z",
          "wordCount": 667,
          "title": "See, Hear, Read: Leveraging Multimodality with Guided Attention for Abstractive Text Summarization. (arXiv:2105.09601v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09494",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Berahmand_K/0/1/0/all/0/1\">Kamal Berahmand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasiri_E/0/1/0/all/0/1\">Elahe Nasiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forouzandeh_S/0/1/0/all/0/1\">Saman Forouzandeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuefeng Li</a>",
          "description": "Predicting links in complex networks has been one of the essential topics\nwithin the realm of data mining and science discovery over the past few years.\nThis problem remains an attempt to identify future, deleted, and redundant\nlinks using the existing links in a graph. Local random walk is considered to\nbe one of the most well-known algorithms in the category of quasi-local\nmethods. It traverses the network using the traditional random walk with a\nlimited number of steps, randomly selecting one adjacent no",
          "link": "http://arxiv.org/abs/2105.09494",
          "publishedOn": "2021-05-22T03:02:51.037Z",
          "wordCount": 671,
          "title": "A Preference Random Walk Algorithm for Link Prediction through Mutual Influence Nodes in Complex Networks. (arXiv:2105.09494v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09536",
          "author": "<a href=\"http://arxiv.org/find/stat/1/au:+Fried_S/0/1/0/all/0/1\">Sela Fried</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wolfer_G/0/1/0/all/0/1\">Geoffrey Wolfer</a>",
          "description": "We formulate extendibility of the minimax one-trajectory length of several\nstatistical Markov chains inference problems and give sufficient conditions for\nboth the possibility and impossibility of such extensions. We follow up and\napply this framework to recently published results on learning and identity\ntesting of ergodic Markov chains. In particular, we show that for some of the\naforementioned results, we can omit the aperiodicity requirement by simulating\nan $\\alpha$-lazy version of the original process",
          "link": "http://arxiv.org/abs/2105.09536",
          "publishedOn": "2021-05-22T03:02:51.031Z",
          "wordCount": 516,
          "title": "On the $\\alpha$-lazy version of Markov chains in estimation and testing problems. (arXiv:2105.09536v1 [stat.ML])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09716",
          "author": "<a href=\"http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1\">Yongfeng Li</a>, <a href=\"http://arxiv.org/find/math/1/au:+Zhao_M/0/1/0/all/0/1\">Mingming Zhao</a>, <a href=\"http://arxiv.org/find/math/1/au:+Chen_W/0/1/0/all/0/1\">Weijie Chen</a>, <a href=\"http://arxiv.org/find/math/1/au:+Wen_Z/0/1/0/all/0/1\">Zaiwen Wen</a>",
          "description": "In this paper, we consider the linear programming (LP) formulation for deep\nreinforcement learning. The number of the constraints depends on the size of\nstate and action spaces, which makes the problem intractable in large or\ncontinuous environments. The general augmented Lagrangian method suffers the\ndouble-sampling obstacle in solving the LP. Namely, the conditional\nexpectations originated from the constraint functions and the quadratic\npenalties in the augmented Lagrangian function impose difficulties in",
          "link": "http://arxiv.org/abs/2105.09716",
          "publishedOn": "2021-05-22T03:02:51.011Z",
          "wordCount": 642,
          "title": "A Stochastic Composite Augmented Lagrangian Method For Reinforcement Learning. (arXiv:2105.09716v1 [math.OC])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09673",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Daniely_A/0/1/0/all/0/1\">Amit Daniely</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granot_E/0/1/0/all/0/1\">Elad Granot</a>",
          "description": "As machine learning increasingly becomes more prevalent in our everyday life,\nmany organizations offer neural-networks based services as a black-box. The\nreasons for hiding a learning model may vary: e.g., preventing copying of its\nbehavior or keeping back an adversarial from reverse-engineering its mechanism\nand revealing sensitive information about its training data.\n\nHowever, even as a black-box, some information can still be discovered by\nspecific queries. In this work, we show a polynomial-time algorit",
          "link": "http://arxiv.org/abs/2105.09673",
          "publishedOn": "2021-05-22T03:02:51.005Z",
          "wordCount": 521,
          "title": "An Exact Poly-Time Membership-Queries Algorithm for Extraction a three-Layer ReLU Network. (arXiv:2105.09673v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09681",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhuangwei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weihua Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yanbu Guo</a>",
          "description": "Chinese word segmentation (CWS) is the basic of Chinese natural language\nprocessing (NLP). The quality of word segmentation will directly affect the\nrest of NLP tasks. Recently, with the artificial intelligence tide rising\nagain, Long Short-Term Memory (LSTM) neural network, as one of easily modeling\nin sequence, has been widely utilized in various kinds of NLP tasks, and\nfunctions well. Attention mechanism is an ingenious method to solve the memory\ncompression problem on LSTM. Furthermore, inspired by the ",
          "link": "http://arxiv.org/abs/2105.09681",
          "publishedOn": "2021-05-22T03:02:50.999Z",
          "wordCount": 546,
          "title": "Bidirectional LSTM-CRF Attention-based Model for Chinese Word Segmentation. (arXiv:2105.09681v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09632",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1\">Danilo Dessi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1\">Rim Helaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vivek Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1\">Diego Reforgiato Recupero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1\">Daniele Riboni</a>",
          "description": "Today, we are seeing an ever-increasing number of clinical notes that contain\nclinical results, images, and textual descriptions of patient's health state.\nAll these data can be analyzed and employed to cater novel services that can\nhelp people and domain experts with their common healthcare tasks. However,\nmany technologies such as Deep Learning and tools like Word Embeddings have\nstarted to be investigated only recently, and many challenges remain open when\nit comes to healthcare domain applications. To a",
          "link": "http://arxiv.org/abs/2105.09632",
          "publishedOn": "2021-05-22T03:02:50.993Z",
          "wordCount": 680,
          "title": "TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09474",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lazic_S/0/1/0/all/0/1\">Stanley E. Lazic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_D/0/1/0/all/0/1\">Dominic P. Williams</a>",
          "description": "Knowing the uncertainty in a prediction is critical when making expensive\ninvestment decisions and when patient safety is paramount, but machine learning\n(ML) models in drug discovery typically provide only a single best estimate and\nignore all sources of uncertainty. Predictions from these models may therefore\nbe over-confident, which can put patients at risk and waste resources when\ncompounds that are destined to fail are further developed. Probabilistic\npredictive models (PPMs) can incorporate uncertaint",
          "link": "http://arxiv.org/abs/2105.09474",
          "publishedOn": "2021-05-22T03:02:50.987Z",
          "wordCount": 649,
          "title": "Quantifying sources of uncertainty in drug discovery predictions with probabilistic models. (arXiv:2105.09474v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09501",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>",
          "description": "Existing multilingual machine translation approaches mainly focus on\nEnglish-centric directions, while the non-English directions still lag behind.\nIn this work, we aim to build a many-to-many translation system with an\nemphasis on the quality of non-English language directions. Our intuition is\nbased on the hypothesis that a universal cross-language representation leads to\nbetter multilingual translation performance. To this end, we propose \\method, a\ntraining method to obtain a single unified multilingual",
          "link": "http://arxiv.org/abs/2105.09501",
          "publishedOn": "2021-05-22T03:02:50.970Z",
          "wordCount": 576,
          "title": "Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09481",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Pryor_W/0/1/0/all/0/1\">Will Pryor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnoy_Y/0/1/0/all/0/1\">Yotam Barnoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raval_S/0/1/0/all/0/1\">Suraj Raval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaolong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mair_L/0/1/0/all/0/1\">Lamar Mair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerner_D/0/1/0/all/0/1\">Daniel Lerner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erin_O/0/1/0/all/0/1\">Onder Erin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hager_G/0/1/0/all/0/1\">Gregory D. Hager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_Mercado_Y/0/1/0/all/0/1\">Yancy Diaz-Mercado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krieger_A/0/1/0/all/0/1\">Axel Krieger</a>",
          "description": "Real-time visual localization of needles is necessary for various surgical\napplications, including surgical automation and visual feedback. In this study\nwe investigate localization and autonomous robotic control of needles in the\ncontext of our magneto-suturing system. Our system holds the potential for\nsurgical manipulation with the benefit of minimal invasiveness and reduced\npatient side effects. However, the non-linear magnetic fields produce\nunintuitive forces and demand delicate position-based control",
          "link": "http://arxiv.org/abs/2105.09481",
          "publishedOn": "2021-05-22T03:02:50.963Z",
          "wordCount": 664,
          "title": "Localization and Control of Magnetic Suture Needles in Cluttered Surgical Site with Blood and Tissue. (arXiv:2105.09481v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09579",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Takamichi Toda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moriwaki_D/0/1/0/all/0/1\">Daisuke Moriwaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ota_K/0/1/0/all/0/1\">Kazuhiro Ota</a>",
          "description": "Large and acute economic shocks such as the 2007-2009 financial crisis and\nthe current COVID-19 infections rapidly change the economic environment. In\nsuch a situation, the importance of real-time economic analysis using\nalternative datais emerging. Alternative data such as search query and location\ndata are closer to real-time and richer than official statistics that are\ntypically released once a month in an aggregated form. We take advantage of\nspatio-temporal granularity of alternative data and propose a",
          "link": "http://arxiv.org/abs/2105.09579",
          "publishedOn": "2021-05-22T03:02:50.936Z",
          "wordCount": 613,
          "title": "Aggregate Learning for Mixed Frequency Data. (arXiv:2105.09579v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09477",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Haghighat_E/0/1/0/all/0/1\">Ehsan Haghighat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bekar_A/0/1/0/all/0/1\">Ali Can Bekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madenci_E/0/1/0/all/0/1\">Erdogan Madenci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Juanes_R/0/1/0/all/0/1\">Ruben Juanes</a>",
          "description": "Deep learning has been the most popular machine learning method in the last\nfew years. In this chapter, we present the application of deep learning and\nphysics-informed neural networks concerning structural mechanics and vibration\nproblems. Demonstration problems involve de-noising data, solution to\ntime-dependent ordinary and partial differential equations, and characterizing\nthe system's response for a given data.",
          "link": "http://arxiv.org/abs/2105.09477",
          "publishedOn": "2021-05-22T03:02:50.869Z",
          "wordCount": 491,
          "title": "Deep learning for solution and inversion of structural mechanics and vibrations. (arXiv:2105.09477v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09492",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Rundi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Changxi Zheng</a>",
          "description": "Deep generative models of 3D shapes have received a great deal of research\ninterest. Yet, almost all of them generate discrete shape representations, such\nas voxels, point clouds, and polygon meshes. We present the first 3D generative\nmodel for a drastically different shape representation -- describing a shape as\na sequence of computer-aided design (CAD) operations. Unlike meshes and point\nclouds, CAD models encode the user creation process of 3D shapes, widely used\nin numerous industrial and engineering de",
          "link": "http://arxiv.org/abs/2105.09492",
          "publishedOn": "2021-05-22T03:02:50.760Z",
          "wordCount": 608,
          "title": "DeepCAD: A Deep Generative Network for Computer-Aided Design Models. (arXiv:2105.09492v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09471",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Leblebici_A/0/1/0/all/0/1\">Asim Leblebici</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gesoglu_O/0/1/0/all/0/1\">Omer Gesoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basbinar_Y/0/1/0/all/0/1\">Yasemin Basbinar</a>",
          "description": "Until the beginning of 2021, lung cancer is known to be the most common\ncancer in the world. The disease is common due to factors such as occupational\nexposure, smoking and environmental pollution. The early diagnosis and\ntreatment of the disease is of great importance as well as the prevention of\nthe causes that cause the disease. The study was planned to create a web\ninterface that works with machine learning algorithms to predict prognosis\nusing lung cancer clinical and gene expression in the GDC data po",
          "link": "http://arxiv.org/abs/2105.09471",
          "publishedOn": "2021-05-22T03:02:50.744Z",
          "wordCount": 515,
          "title": "AI-Decision Support System Interface Using Cancer Related Data for Lung Cancer Prognosis. (arXiv:2105.09471v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09637",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Devlin_S/0/1/0/all/0/1\">Sam Devlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgescu_R/0/1/0/all/0/1\">Raluca Georgescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Momennejad_I/0/1/0/all/0/1\">Ida Momennejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rzepecki_J/0/1/0/all/0/1\">Jaroslaw Rzepecki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuniga_E/0/1/0/all/0/1\">Evelyn Zuniga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costello_G/0/1/0/all/0/1\">Gavin Costello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leroy_G/0/1/0/all/0/1\">Guy Leroy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaw_A/0/1/0/all/0/1\">Ali Shaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1\">Katja Hofmann</a>",
          "description": "A key challenge on the path to developing agents that learn complex\nhuman-like behavior is the need to quickly and accurately quantify\nhuman-likeness. While human assessments of such behavior can be highly\naccurate, speed and scalability are limited. We address these limitations\nthrough a novel automated Navigation Turing Test (ANTT) that learns to predict\nhuman judgments of human-likeness. We demonstrate the effectiveness of our\nautomated NTT on a navigation task in a complex 3D environment. We investigate",
          "link": "http://arxiv.org/abs/2105.09637",
          "publishedOn": "2021-05-22T03:02:50.736Z",
          "wordCount": 589,
          "title": "Navigation Turing Test (NTT): Learning to Evaluate Human-Like Navigation. (arXiv:2105.09637v1 [cs.AI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09461",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Al_Kababji_A/0/1/0/all/0/1\">Ayman Al-Kababji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amira_A/0/1/0/all/0/1\">Abbes Amira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bensaali_F/0/1/0/all/0/1\">Faycal Bensaali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarouf_A/0/1/0/all/0/1\">Abdulah Jarouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shidqi_L/0/1/0/all/0/1\">Lisan Shidqi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Djelouat_H/0/1/0/all/0/1\">Hamza Djelouat</a>",
          "description": "Fall detection is a serious healthcare issue that needs to be solved. Falling\nwithout quick medical intervention would lower the chances of survival for the\nelderly, especially if living alone. Hence, the need is there for developing\nfall detection algorithms with high accuracy. This paper presents a novel\nIoT-based system for fall detection that includes a sensing device transmitting\ndata to a mobile application through a cloud-connected gateway device. Then,\nthe focus is shifted to the algorithmic aspect ",
          "link": "http://arxiv.org/abs/2105.09461",
          "publishedOn": "2021-05-22T03:02:50.727Z",
          "wordCount": 658,
          "title": "An IoT-Based Framework for Remote Fall Monitoring. (arXiv:2105.09461v1 [cs.NI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09384",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1\">Hanghang Tong</a>",
          "description": "The past decades have witnessed the prosperity of graph mining, with a\nmultitude of sophisticated models and algorithms designed for various mining\ntasks, such as ranking, classification, clustering and anomaly detection.\nGenerally speaking, the vast majority of the existing works aim to answer the\nfollowing question, that is, given a graph, what is the best way to mine it? In\nthis paper, we introduce the graph sanitation problem, to answer an orthogonal\nquestion. That is, given a mining task and an initial",
          "link": "http://arxiv.org/abs/2105.09384",
          "publishedOn": "2021-05-22T03:02:50.709Z",
          "wordCount": 631,
          "title": "Graph Sanitation with Application to Node Classification. (arXiv:2105.09384v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09406",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Javaheri_B/0/1/0/all/0/1\">Behzad Javaheri</a>",
          "description": "Herein, we have compared the performance of SVM and MLP in emotion\nrecognition using speech and song channels of the RAVDESS dataset. We have\nundertaken a journey to extract various audio features, identify optimal\nscaling strategy and hyperparameter for our models. To increase sample size, we\nhave performed audio data augmentation and addressed data imbalance using\nSMOTE. Our data indicate that optimised SVM outperforms MLP with an accuracy of\n82 compared to 75%. Following data augmentation, the performanc",
          "link": "http://arxiv.org/abs/2105.09406",
          "publishedOn": "2021-05-22T03:02:50.702Z",
          "wordCount": 576,
          "title": "Speech & Song Emotion Recognition Using Multilayer Perceptron and Standard Vector Machine. (arXiv:2105.09406v1 [cs.SD])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09452",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Alegre_L/0/1/0/all/0/1\">Lucas N. Alegre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bazzan_A/0/1/0/all/0/1\">Ana L. C. Bazzan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_B/0/1/0/all/0/1\">Bruno C. da Silva</a>",
          "description": "Non-stationary environments are challenging for reinforcement learning\nalgorithms. If the state transition and/or reward functions change based on\nlatent factors, the agent is effectively tasked with optimizing a behavior that\nmaximizes performance over a possibly infinite random sequence of Markov\nDecision Processes (MDPs), each of which drawn from some unknown distribution.\nWe call each such MDP a context. Most related works make strong assumptions\nsuch as knowledge about the distribution over contexts, t",
          "link": "http://arxiv.org/abs/2105.09452",
          "publishedOn": "2021-05-22T03:02:50.687Z",
          "wordCount": 713,
          "title": "Minimum-Delay Adaptation in Non-Stationary Reinforcement Learning via Online High-Confidence Change-Point Detection. (arXiv:2105.09452v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09356",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_S/0/1/0/all/0/1\">Seyed Saeed Changiz Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1\">Fred X. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1\">Di Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salameh_M/0/1/0/all/0/1\">Mohammad Salameh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mills_K/0/1/0/all/0/1\">Keith Mills</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_S/0/1/0/all/0/1\">Shuo Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jui_S/0/1/0/all/0/1\">Shangling Jui</a>",
          "description": "Despite the empirical success of neural architecture search (NAS) in deep\nlearning applications, the optimality, reproducibility and cost of NAS schemes\nremain hard to assess. In this paper, we propose Generative Adversarial NAS\n(GA-NAS) with theoretically provable convergence guarantees, promoting\nstability and reproducibility in neural architecture search. Inspired by\nimportance sampling, GA-NAS iteratively fits a generator to previously\ndiscovered top architectures, thus increasingly focusing on importan",
          "link": "http://arxiv.org/abs/2105.09356",
          "publishedOn": "2021-05-22T03:02:50.676Z",
          "wordCount": 621,
          "title": "Generative Adversarial Neural Architecture Search. (arXiv:2105.09356v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09379",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Adler_A/0/1/0/all/0/1\">Avraham Adler</a>",
          "description": "This paper reviews a wide selection of machine learning models built to\npredict both the presence of diabetes and the presence of undiagnosed diabetes\nusing eight years of National Health and Nutrition Examination Survey (NHANES)\ndata. Models are tuned and compared via their Brier Scores. The most relevant\nvariables of the best performing models are then compared. A Support Vector\nMachine with a linear kernel performed best for predicting diabetes, returning\na Brier score of 0.0654 and an AUROC of 0.9235 on",
          "link": "http://arxiv.org/abs/2105.09379",
          "publishedOn": "2021-05-22T03:02:50.587Z",
          "wordCount": 588,
          "title": "Using Machine Learning Techniques to Identify Key Risk Factors for Diabetes and Undiagnosed Diabetes. (arXiv:2105.09379v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09469",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Frostig_R/0/1/0/all/0/1\">Roy Frostig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Matthew J. Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maclaurin_D/0/1/0/all/0/1\">Dougal Maclaurin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paszke_A/0/1/0/all/0/1\">Adam Paszke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radul_A/0/1/0/all/0/1\">Alexey Radul</a>",
          "description": "We decompose reverse-mode automatic differentiation into (forward-mode)\nlinearization followed by transposition. Doing so isolates the essential\ndifference between forward- and reverse-mode AD, and simplifies their joint\nimplementation. In particular, once forward-mode AD rules are defined for every\nprimitive operation in a source language, only linear primitives require an\nadditional transposition rule in order to arrive at a complete reverse-mode AD\nimplementation. This is how reverse-mode AD is written i",
          "link": "http://arxiv.org/abs/2105.09469",
          "publishedOn": "2021-05-22T03:02:50.581Z",
          "wordCount": 507,
          "title": "Decomposing reverse-mode automatic differentiation. (arXiv:2105.09469v1 [cs.PL])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09371",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Karnan_H/0/1/0/all/0/1\">Haresh Karnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warnell_G/0/1/0/all/0/1\">Garrett Warnell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xuesu Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1\">Peter Stone</a>",
          "description": "While imitation learning for vision based autonomous mobile robot navigation\nhas recently received a great deal of attention in the research community,\nexisting approaches typically require state action demonstrations that were\ngathered using the deployment platform. However, what if one cannot easily\noutfit their platform to record these demonstration signals or worse yet the\ndemonstrator does not have access to the platform at all? Is imitation learning\nfor vision based autonomous navigation even possible",
          "link": "http://arxiv.org/abs/2105.09371",
          "publishedOn": "2021-05-22T03:02:50.562Z",
          "wordCount": 671,
          "title": "VOILA: Visual-Observation-Only Imitation Learning for Autonomous Navigation. (arXiv:2105.09371v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09421",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Ming-Chang Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jia-Chun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gran_E/0/1/0/all/0/1\">Ernst Gunnar Gran</a>",
          "description": "Over the past decade, many approaches have been introduced for traffic speed\nprediction. However, providing fine-grained, accurate, time-efficient, and\nadaptive traffic speed prediction for a growing transportation network where\nthe size of the network keeps increasing and new traffic detectors are\nconstantly deployed has not been well studied. To address this issue, this\npaper presents DistTune based on Long Short-Term Memory (LSTM) and the\nNelder-Mead method. Whenever encountering an unprocessed detector,",
          "link": "http://arxiv.org/abs/2105.09421",
          "publishedOn": "2021-05-22T03:02:50.551Z",
          "wordCount": 658,
          "title": "DistTune: Distributed Fine-Grained Adaptive Traffic Speed Prediction for Growing Transportation Networks. (arXiv:2105.09421v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09401",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lecheng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yada Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jingrui He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jinjun Xiong</a>",
          "description": "With the advent of big data across multiple high-impact applications, we are\noften facing the challenge of complex heterogeneity. The newly collected data\nusually consist of multiple modalities and characterized with multiple labels,\nthus exhibiting the co-existence of multiple types of heterogeneity. Although\nstate-of-the-art techniques are good at modeling the complex heterogeneity with\nsufficient label information, such label information can be quite expensive to\nobtain in real applications, leading to s",
          "link": "http://arxiv.org/abs/2105.09401",
          "publishedOn": "2021-05-22T03:02:50.540Z",
          "wordCount": 613,
          "title": "Heterogeneous Contrastive Learning. (arXiv:2105.09401v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09467",
          "author": "<a href=\"http://arxiv.org/find/physics/1/au:+Yan_B/0/1/0/all/0/1\">Bicheng Yan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Harp_D/0/1/0/all/0/1\">Dylan Robert Harp</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Chen_B/0/1/0/all/0/1\">Bailian Chen</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Pawar_R/0/1/0/all/0/1\">Rajesh Pawar</a>",
          "description": "In this work, an efficient physics-constrained deep learning model is\ndeveloped for solving multiphase flow in 3D heterogeneous porous media. The\nmodel fully leverages the spatial topology predictive capability of\nconvolutional neural networks, and is coupled with an efficient\ncontinuity-based smoother to predict flow responses that need spatial\ncontinuity. Furthermore, the transient regions are penalized to steer the\ntraining process such that the model can accurately capture flow in these\nregions. The mod",
          "link": "http://arxiv.org/abs/2105.09467",
          "publishedOn": "2021-05-22T03:02:50.534Z",
          "wordCount": 727,
          "title": "A Physics-Constrained Deep Learning Model for Simulating Multiphase Flow in 3D Heterogeneous Porous Media. (arXiv:2105.09467v1 [physics.geo-ph])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09446",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lowe_E/0/1/0/all/0/1\">Evan Lowe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guvenc_L/0/1/0/all/0/1\">Levent Guven&#xe7;</a>",
          "description": "As passenger vehicle technologies have advanced, so have their capabilities\nto avoid obstacles, especially with developments in tires, suspensions,\nsteering, as well as safety technologies like ABS, ESC, and more recently, ADAS\nsystems. However, environments around passenger vehicles have also become more\ncomplex, and dangerous. There have previously been studies that outline driver\ntendencies and performance capabilities when attempting to avoid obstacles\nwhile driving passenger vehicles. Now that autonomo",
          "link": "http://arxiv.org/abs/2105.09446",
          "publishedOn": "2021-05-22T03:02:50.527Z",
          "wordCount": 619,
          "title": "A Review of Autonomous Road Vehicle Integrated Approaches to an Emergency Obstacle Avoidance Maneuver. (arXiv:2105.09446v1 [cs.RO])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09428",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lahlou_C/0/1/0/all/0/1\">Chuhong Lahlou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crayton_A/0/1/0/all/0/1\">Ancil Crayton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trier_C/0/1/0/all/0/1\">Caroline Trier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willett_E/0/1/0/all/0/1\">Evan Willett</a>",
          "description": "In 2019, The Centers for Medicare and Medicaid Services (CMS) launched an\nArtificial Intelligence (AI) Health Outcomes Challenge seeking solutions to\npredict risk in value-based care for incorporation into CMS Innovation Center\npayment and service delivery models. Recently, modern language models have\nplayed key roles in a number of health related tasks. This paper presents, to\nthe best of our knowledge, the first application of these models to patient\nreadmission prediction. To facilitate this, we create a",
          "link": "http://arxiv.org/abs/2105.09428",
          "publishedOn": "2021-05-22T03:02:50.509Z",
          "wordCount": 592,
          "title": "Explainable Health Risk Predictor with Transformer-based Medicare Claim Encoder. (arXiv:2105.09428v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09433",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Parulekar_A/0/1/0/all/0/1\">Aditya Parulekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parulekar_A/0/1/0/all/0/1\">Advait Parulekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Price_E/0/1/0/all/0/1\">Eric Price</a>",
          "description": "We consider the problem of finding an approximate solution to $\\ell_1$\nregression while only observing a small number of labels. Given an $n \\times d$\nunlabeled data matrix $X$, we must choose a small set of $m \\ll n$ rows to\nobserve the labels of, then output an estimate $\\widehat{\\beta}$ whose error on\nthe original problem is within a $1 + \\varepsilon$ factor of optimal. We show\nthat sampling from $X$ according to its Lewis weights and outputting the\nempirical minimizer succeeds with probability $1-\\delta",
          "link": "http://arxiv.org/abs/2105.09433",
          "publishedOn": "2021-05-22T03:02:50.491Z",
          "wordCount": 552,
          "title": "L1 Regression with Lewis Weights Subsampling. (arXiv:2105.09433v1 [cs.LG])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09365",
          "author": "<a href=\"http://arxiv.org/find/eess/1/au:+Uysal_E/0/1/0/all/0/1\">Enes Sadi Uysal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bilici_M/0/1/0/all/0/1\">M.&#x15e;afak Bilici</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zaza_B/0/1/0/all/0/1\">B. Selin Zaza</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ozgenc_M/0/1/0/all/0/1\">M. Yi&#x11f;it &#xd6;zgen&#xe7;</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boyar_O/0/1/0/all/0/1\">Onur Boyar</a>",
          "description": "Retinal Vessel Segmentation is important for diagnosis of various diseases.\nThe research on retinal vessel segmentation focuses mainly on improvement of\nthe segmentation model which is usually based on U-Net architecture. In our\nstudy we use the U-Net architecture and we rely on heavy data augmentation in\norder to achieve better performance. The success of the data augmentation\nrelies on successfully addressing the problem of input images. By analyzing\ninput images and performing the augmentation accordingl",
          "link": "http://arxiv.org/abs/2105.09365",
          "publishedOn": "2021-05-22T03:02:50.484Z",
          "wordCount": 564,
          "title": "Exploring The Limits Of Data Augmentation For Retinal Vessel Segmentation. (arXiv:2105.09365v1 [eess.IV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09400",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pau-Chen Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eykholt_K/0/1/0/all/0/1\">Kevin Eykholt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1\">Zhongshu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamjoom_H/0/1/0/all/0/1\">Hani Jamjoom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayaram_K/0/1/0/all/0/1\">K. R. Jayaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valdez_E/0/1/0/all/0/1\">Enriquillo Valdez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1\">Ashish Verma</a>",
          "description": "Federated Learning (FL) enables collaborative training among mutually\ndistrusting parties. Model updates, rather than training data, are concentrated\nand fused in a central aggregation server. A key security challenge in FL is\nthat an untrustworthy or compromised aggregation process might lead to\nunforeseeable information leakage. This challenge is especially acute due to\nrecently demonstrated attacks that have reconstructed large fractions of\ntraining data from ostensibly \"sanitized\" model updates.\n\nIn thi",
          "link": "http://arxiv.org/abs/2105.09400",
          "publishedOn": "2021-05-22T03:02:50.422Z",
          "wordCount": 604,
          "title": "Separation of Powers in Federated Learning. (arXiv:2105.09400v1 [cs.CR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09448",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Chhablani_G/0/1/0/all/0/1\">Gunjan Chhablani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abheesht Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_H/0/1/0/all/0/1\">Harshit Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dash_T/0/1/0/all/0/1\">Tirtharaj Dash</a>",
          "description": "Superpixels are higher-order perceptual groups of pixels in an image, often\ncarrying much more information than raw pixels. There is an inherent relational\nstructure to the relationship among different superpixels of an image. This\nrelational information can convey some form of domain information about the\nimage, e.g. relationship between superpixels representing two eyes in a cat\nimage. Our interest in this paper is to construct computer vision models,\nspecifically those based on Deep Neural Networks (DNNs",
          "link": "http://arxiv.org/abs/2105.09448",
          "publishedOn": "2021-05-22T03:02:50.400Z",
          "wordCount": 693,
          "title": "Superpixel-based Domain-Knowledge Infusion in Computer Vision. (arXiv:2105.09448v1 [cs.CV])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09352",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1\">Dawn Drain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clement_C/0/1/0/all/0/1\">Colin B. Clement</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serrato_G/0/1/0/all/0/1\">Guillermo Serrato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1\">Neel Sundaresan</a>",
          "description": "The joint task of bug localization and program repair is an integral part of\nthe software development process. In this work we present DeepDebug, an\napproach to automated debugging using large, pretrained transformers. We begin\nby training a bug-creation model on reversed commit data for the purpose of\ngenerating synthetic bugs. We apply these synthetic bugs toward two ends.\nFirst, we directly train a backtranslation model on all functions from 200K\nrepositories. Next, we focus on 10K repositories for which",
          "link": "http://arxiv.org/abs/2105.09352",
          "publishedOn": "2021-05-22T03:02:50.362Z",
          "wordCount": 678,
          "title": "DeepDebug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons. (arXiv:2105.09352v1 [cs.SE])"
        }
      ]
    },
    {
      "title": "cs.IR updates on arXiv.org",
      "feedUrl": "http://arxiv.org/rss/cs.IR",
      "siteUrl": "http://arxiv.org/",
      "articles": [
        {
          "id": "http://arxiv.org/abs/2105.10484",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Ze Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinnian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yumeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiancheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1\">Tanchao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lifeng Sun</a>",
          "description": "Modeling powerful interactions is a critical challenge in Click-through rate\n(CTR) prediction, which is one of the most typical machine learning tasks in\npersonalized advertising and recommender systems. Although developing\nhand-crafted interactions is effective for a small number of datasets, it\ngenerally requires laborious and tedious architecture engineering for extensive\nscenarios. In recent years, several neural architecture search (NAS) methods\nhave been proposed for designing interactions automatically. However, existing\nmethods only explore limited types and connections of operators for interaction\ngeneration, leading to low generalization ability. To address these problems,\nwe propose a more general automated method for building powerful interactions\nnamed AutoPI. The main contributions of this paper are as follows: AutoPI\nadopts a more general search space in which the computational graph is\ngeneralized from existing network connections, and the interactive operators in\nthe edges of the graph are extracted from representative hand-crafted works. It\nallows searching for various powerful feature interactions to produce higher\nAUC and lower Logloss in a wide variety of applications. Besides, AutoPI\nutilizes a gradient-based search strategy for exploration with a significantly\nlow computational cost. Experimentally, we evaluate AutoPI on a diverse suite\nof benchmark datasets, demonstrating the generalizability and efficiency of\nAutoPI over hand-crafted architectures and state-of-the-art NAS algorithms.",
          "link": "http://arxiv.org/abs/2105.10484",
          "publishedOn": "2021-05-24T07:23:02.468Z",
          "wordCount": 653,
          "title": "A General Method For Automatic Discovery of Powerful Interactions In Click-Through Rate Prediction. (arXiv:2105.10484v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10152",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kohli_H/0/1/0/all/0/1\">Harsh Kohli</a>",
          "description": "Related or ideal follow-up suggestions to a web query in search engines are\noften optimized based on several different parameters -- relevance to the\noriginal query, diversity, click probability etc. One or many rankers may be\ntrained to score each suggestion from a candidate pool based on these factors.\nThese scorers are usually pairwise classification tasks where each training\nexample consists of a user query and a single suggestion from the list of\ncandidates. We propose an architecture that takes all candidate suggestions\nassociated with a given query and outputs a suggestion block. We discuss the\nbenefits of such an architecture over traditional approaches and experiment\nwith further enforcing each individual metric through mixed-objective training.",
          "link": "http://arxiv.org/abs/2105.10152",
          "publishedOn": "2021-05-24T07:23:02.421Z",
          "wordCount": 558,
          "title": "Training Mixed-Objective Pointing Decoders for Block-Level Optimization in Search Recommendation. (arXiv:2105.10152v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2104.06312",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1\">Keke Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_L/0/1/0/all/0/1\">Linjian Mo</a>",
          "description": "Click-Through Rate (CTR) prediction plays an important role in many\nindustrial applications, and recently a lot of attention is paid to the deep\ninterest models which use attention mechanism to capture user interests from\nhistorical behaviors. However, most current models are based on sequential\nmodels which truncate the behavior sequences by a fixed length, thus have\ndifficulties in handling very long behavior sequences. Another big problem is\nthat sequences with the same length can be quite different in terms of time,\ncarrying completely different meanings. In this paper, we propose a\nnon-sequential approach to tackle the above problems. Specifically, we first\nrepresent the behavior data in a sparse key-vector format, where the vector\ncontains rich behavior info such as time, count and category. Next, we enhance\nthe Deep Interest Network to take such rich information into account by a novel\nattention network. The sparse representation makes it practical to handle large\nscale long behavior sequences. Finally, we introduce a multidimensional\npartition framework to mine behavior interactions. The framework can partition\ndata into custom designed time buckets to capture the interactions among\ninformation aggregated in different time buckets. Similarly, it can also\npartition the data into different categories and capture the interactions among\nthem. Experiments are conducted on two public datasets: one is an advertising\ndataset and the other is a production recommender dataset. Our models\noutperform other state-of-the-art models on both datasets.",
          "link": "http://arxiv.org/abs/2104.06312",
          "publishedOn": "2021-05-24T07:23:02.390Z",
          "wordCount": 689,
          "title": "A Non-sequential Approach to Deep User Interest Model for CTR Prediction. (arXiv:2104.06312v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10072",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianghong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zahiri_S/0/1/0/all/0/1\">Sayyed M. Zahiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hughes_S/0/1/0/all/0/1\">Simon Hughes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jadda_K/0/1/0/all/0/1\">Khalifeh Al Jadda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kallumadi_S/0/1/0/all/0/1\">Surya Kallumadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agichtein_E/0/1/0/all/0/1\">Eugene Agichtein</a>",
          "description": "Users' clicks on Web search results are one of the key signals for evaluating\nand improving web search quality and have been widely used as part of current\nstate-of-the-art Learning-To-Rank(LTR) models. With a large volume of search\nlogs available for major search engines, effective models of searcher click\nbehavior have emerged to evaluate and train LTR models. However, when modeling\nthe users' click behavior, considering the bias of the behavior is imperative.\nIn particular, when a search result is not clicked, it is not necessarily\nchosen as not relevant by the user, but instead could have been simply missed,\nespecially for lower-ranked results. These kinds of biases in the click log\ndata can be incorporated into the click models, propagating the errors to the\nresulting LTR ranking models or evaluation metrics. In this paper, we propose\nthe De-biased Reinforcement Learning Click model (DRLC). The DRLC model relaxes\npreviously made assumptions about the users' examination behavior and resulting\nlatent states. To implement the DRLC model, convolutional neural networks are\nused as the value networks for reinforcement learning, trained to learn a\npolicy to reduce bias in the click logs. To demonstrate the effectiveness of\nthe DRLC model, we first compare performance with the previous state-of-art\napproaches using established click prediction metrics, including log-likelihood\nand perplexity. We further show that DRLC also leads to improvements in ranking\nperformance. Our experiments demonstrate the effectiveness of the DRLC model in\nlearning to reduce bias in click logs, leading to improved modeling performance\nand showing the potential for using DRLC for improving Web search quality.",
          "link": "http://arxiv.org/abs/2105.10072",
          "publishedOn": "2021-05-24T07:23:02.371Z",
          "wordCount": 698,
          "title": "De-Biased Modelling of Search Click Behavior with Reinforcement Learning. (arXiv:2105.10072v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10019",
          "author": "<a href=\"http://arxiv.org/find/q-fin/1/au:+Poh_D/0/1/0/all/0/1\">Daniel Poh</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Lim_B/0/1/0/all/0/1\">Bryan Lim</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Zohren_S/0/1/0/all/0/1\">Stefan Zohren</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Roberts_S/0/1/0/all/0/1\">Stephen Roberts</a>",
          "description": "The performance of a cross-sectional currency strategy depends crucially on\naccurately ranking instruments prior to portfolio construction. While this\nranking step is traditionally performed using heuristics, or by sorting outputs\nproduced by pointwise regression or classification models, Learning to Rank\nalgorithms have recently presented themselves as competitive and viable\nalternatives. Despite improving ranking accuracy on average however, these\ntechniques do not account for the possibility that assets positioned at the\nextreme ends of the ranked list -- which are ultimately used to construct the\nlong/short portfolios -- can assume different distributions in the input space,\nand thus lead to sub-optimal strategy performance. Drawing from research in\nInformation Retrieval that demonstrates the utility of contextual information\nembedded within top-ranked documents to learn the query's characteristics to\nimprove ranking, we propose an analogous approach: exploiting the features of\nboth out- and under-performing instruments to learn a model for refining the\noriginal ranked list. Under a re-ranking framework, we adapt the Transformer\narchitecture to encode the features of extreme assets for refining our\nselection of long/short instruments obtained with an initial retrieval.\nBacktesting on a set of 31 currencies, our proposed methodology significantly\nboosts Sharpe ratios -- by approximately 20% over the original LTR algorithms\nand double that of traditional baselines.",
          "link": "http://arxiv.org/abs/2105.10019",
          "publishedOn": "2021-05-24T07:23:02.322Z",
          "wordCount": 655,
          "title": "Enhancing Cross-Sectional Currency Strategies by Ranking Refinement with Transformer-based Architectures. (arXiv:2105.10019v1 [q-fin.PM])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10165",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bennett_A/0/1/0/all/0/1\">Andrew Bennett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1\">Dipendra Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Than_N/0/1/0/all/0/1\">Nga Than</a>",
          "description": "Topic models are widely used in studying social phenomena. We conduct a\ncomparative study examining state-of-the-art neural versus non-neural topic\nmodels, performing a rigorous quantitative and qualitative assessment on a\ndataset of tweets about the COVID-19 pandemic. Our results show that not only\ndo neural topic models outperform their classical counterparts on standard\nevaluation metrics, but they also produce more coherent topics, which are of\ngreat benefit when studying complex social problems. We also propose a novel\nregularization term for neural topic models, which is designed to address the\nwell-documented problem of mode collapse, and demonstrate its effectiveness.",
          "link": "http://arxiv.org/abs/2105.10165",
          "publishedOn": "2021-05-24T07:23:02.312Z",
          "wordCount": 605,
          "title": "Have you tried Neural Topic Models? Comparative Analysis of Neural and Non-Neural Topic Models with Application to COVID-19 Twitter Data. (arXiv:2105.10165v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2101.01910",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaopeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyusong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tiancheng Zhao</a>",
          "description": "Although open-domain question answering (QA) draws great attention in recent\nyears, it requires large amounts of resources for building the full system and\nis often difficult to reproduce previous results due to complex configurations.\nIn this paper, we introduce SF-QA: simple and fair evaluation framework for\nopen-domain QA. SF-QA framework modularizes the pipeline open-domain QA system,\nwhich makes the task itself easily accessible and reproducible to research\ngroups without enough computing resources. The proposed evaluation framework is\npublicly available and anyone can contribute to the code and evaluations.",
          "link": "http://arxiv.org/abs/2101.01910",
          "publishedOn": "2021-05-24T07:23:02.292Z",
          "wordCount": 555,
          "title": "SF-QA: Simple and Fair Evaluation Library for Open-domain Question Answering. (arXiv:2101.01910v2 [cs.CL] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.10124",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianghong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agichtein_E/0/1/0/all/0/1\">Eugene Agichtein</a>",
          "description": "To support complex search tasks, where the initial information requirements\nare complex or may change during the search, a search engine must adapt the\ninformation delivery as the user's information requirements evolve. To support\nthis dynamic ranking paradigm effectively, search result ranking must\nincorporate both the user feedback received, and the information displayed so\nfar. To address this problem, we introduce a novel reinforcement learning-based\napproach, RLIrank. We first build an adapted reinforcement learning framework\nto integrate the key components of the dynamic search. Then, we implement a new\nLearning to Rank (LTR) model for each iteration of the dynamic search, using a\nrecurrent Long Short Term Memory neural network (LSTM), which estimates the\ngain for each next result, learning from each previously ranked document. To\nincorporate the user's feedback, we develop a word-embedding variation of the\nclassic Rocchio Algorithm, to help guide the ranking towards the high-value\ndocuments. Those innovations enable RLIrank to outperform the previously\nreported methods from the TREC Dynamic Domain Tracks 2017 and exceed all the\nmethods in 2016 TREC Dynamic Domain after multiple search iterations, advancing\nthe state of the art for dynamic search.",
          "link": "http://arxiv.org/abs/2105.10124",
          "publishedOn": "2021-05-24T07:23:02.266Z",
          "wordCount": 642,
          "title": "RLIRank: Learning to Rank with Reinforcement Learning for Dynamic Search. (arXiv:2105.10124v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10216",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wolbitsch_M/0/1/0/all/0/1\">Matthias W&#xf6;lbitsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasler_T/0/1/0/all/0/1\">Thomas Hasler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasper_P/0/1/0/all/0/1\">Patrick Kasper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helic_D/0/1/0/all/0/1\">Denis Helic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walk_S/0/1/0/all/0/1\">Simon Walk</a>",
          "description": "In recent years, Radio Frequency Identification (RFID) technology has been\napplied to improve numerous processes, such as inventory management in retail\nstores. However, automatic localization of RFID-tagged goods in stores is still\na challenging problem. To address this issue, we equip fixtures (e.g., shelves)\nwith reference tags and use data we collect during RFID-based stocktakes to map\narticles to fixtures. Knowing the location of goods enables the implementation\nof several practical applications, such as automated Money Mapping (i.e., a\nheat map of sales across fixtures). Specifically, we conduct controlled lab\nexperiments and a case-study in two fashion retail stores to evaluate our\narticle-to-fixture prediction approaches. The approaches are based on\ncalculating distances between read event time series using DTW, and clustering\nof read events using DBSCAN. We find that, read events collected during\nRFID-based stocktakes can be used to assign articles to fixtures with an\naccuracy of more than 90%. Additionally, we conduct a pilot to investigate the\nchallenges related to the integration of such a localization system in the\nday-to-day business of retail stores. Hence, in this paper we present an\nexploratory venture into novel and practical RFID-based applications in fashion\nretails stores, beyond the scope of stock management.",
          "link": "http://arxiv.org/abs/2105.10216",
          "publishedOn": "2021-05-24T07:23:02.253Z",
          "wordCount": 632,
          "title": "RFID-based Article-to-Fixture Predictions in Real-World Fashion Stores. (arXiv:2105.10216v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10256",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Colladon_A/0/1/0/all/0/1\">A. Fronzetti Colladon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gloor_P/0/1/0/all/0/1\">P. A. Gloor</a>",
          "description": "This paper investigates the research question if senders of large amounts of\nirrelevant or unsolicited information - commonly called \"spammers\" - distort\nthe network structure of social networks. Two large social networks are\nanalyzed, the first extracted from the Twitter discourse about a big\ntelecommunication company, and the second obtained from three years of email\ncommunication of 200 managers working for a large multinational company. This\nwork compares network robustness and the stability of centrality and\ninteraction metrics, as well as the use of language, after removing spammers\nand the most and least connected nodes. The results show that spammers do not\nsignificantly alter the structure of the information-carrying network, for most\nof the social indicators. The authors additionally investigate the correlation\nbetween e-mail subject line and content by tracking language sentiment,\nemotionality, and complexity, addressing the cases where collecting email\nbodies is not permitted for privacy reasons. The findings extend the research\nabout robustness and stability of social networks metrics, after the\napplication of graph simplification strategies. The results have practical\nimplication for network analysts and for those company managers who rely on\nnetwork analytics (applied to company emails and social media data) to support\ntheir decision-making processes.",
          "link": "http://arxiv.org/abs/2105.10256",
          "publishedOn": "2021-05-24T07:23:02.237Z",
          "wordCount": 656,
          "title": "Measuring the impact of spammers on e-mail and Twitter networks. (arXiv:2105.10256v1 [cs.SI])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09981",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Afsar_M/0/1/0/all/0/1\">Mehdi Afsar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crump_T/0/1/0/all/0/1\">Trafford Crump</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Far_B/0/1/0/all/0/1\">Behrouz Far</a>",
          "description": "Recommender systems (RSs) are software tools and algorithms developed to\nalleviate the problem of information overload, which makes it difficult for a\nuser to make right decisions. Two main paradigms toward the recommendation\nproblem are collaborative filtering and content-based filtering, which try to\nrecommend the best items using ratings and content available. These methods\ntypically face infamous problems including cold-start, diversity, scalability,\nand great computational expense. We argue that the uptake of deep learning and\nreinforcement learning methods is also questionable due to their computational\ncomplexities and uninterpretability. In this paper, we approach the\nrecommendation problem from a new prospective. We borrow ideas from cluster\nhead selection algorithms in wireless sensor networks and adapt them to the\nrecommendation problem. In particular, we propose Load Balanced Recommender\nSystem (LBRS), which uses a probabilistic scheme for item recommendation.\nFurthermore, we factor in the importance of items in the recommendation\nprocess, which significantly improves the recommendation accuracy. We also\nintroduce a method that considers a heterogeneity among items, in order to\nbalance the similarity and diversity trade-off. Finally, we propose a new\nmetric for diversity, which emphasizes the importance of diversity not only\nfrom an intra-list perspective, but also from a between-list point of view.\nWith experiments in a simulation study performed on RecSim, we show that LBRS\nis effective and can outperform baseline methods.",
          "link": "http://arxiv.org/abs/2105.09981",
          "publishedOn": "2021-05-24T07:23:02.225Z",
          "wordCount": 639,
          "title": "A Load Balanced Recommendation Approach. (arXiv:2105.09981v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10075",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jianghong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agichtein_E/0/1/0/all/0/1\">Eugene Agichtein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kallumadi_S/0/1/0/all/0/1\">Surya Kallumadi</a>",
          "description": "In search and recommendation, diversifying the multi-aspect search results\ncould help with reducing redundancy, and promoting results that might not be\nshown otherwise. Many previous methods have been proposed for this task.\nHowever, previous methods do not explicitly consider the uniformity of the\nnumber of the items' classes, or evenness, which could degrade the search and\nrecommendation quality. To address this problem, we introduce a novel method by\nadapting the Simpson's Diversity Index from biology, which enables a more\neffective and efficient quadratic search result diversification algorithm. We\nalso extend the method to balance the diversity between multiple aspects\nthrough weighted factors and further improve computational complexity by\ndeveloping a fast approximation algorithm. We demonstrate the feasibility of\nthe proposed method using the openly available Kaggle shoes competition\ndataset. Our experimental results show that our approach outperforms previous\nstate of the art diversification methods, while reducing computational\ncomplexity.",
          "link": "http://arxiv.org/abs/2105.10075",
          "publishedOn": "2021-05-24T07:23:02.186Z",
          "wordCount": 612,
          "title": "Diversifying Multi-aspect Search Results Using Simpson's Diversity Index. (arXiv:2105.10075v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.10117",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Kawintiranon_K/0/1/0/all/0/1\">Kornraphop Kawintiranon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yaguang Liu</a>",
          "description": "General Data Protection Regulation (GDPR) becomes a standard law for data\nprotection in many countries. Currently, twelve countries adopt the regulation\nand establish their GDPR-like regulation. However, to evaluate the differences\nand similarities of these GDPR-like regulations is time-consuming and needs a\nlot of manual effort from legal experts. Moreover, GDPR-like regulations from\ndifferent countries are written in their languages leading to a more difficult\ntask since legal experts who know both languages are essential. In this paper,\nwe investigate a simple natural language processing (NLP) approach to tackle\nthe problem. We first extract chunks of information from GDPR-like documents\nand form structured data from natural language. Next, we use NLP methods to\ncompare documents to measure their similarity. Finally, we manually label a\nsmall set of data to evaluate our approach. The empirical result shows that the\nBERT model with cosine similarity outperforms other baselines. Our data and\ncode are publicly available.",
          "link": "http://arxiv.org/abs/2105.10117",
          "publishedOn": "2021-05-24T07:23:02.154Z",
          "wordCount": 600,
          "title": "Towards Automatic Comparison of Data Privacy Documents: A Preliminary Experiment on GDPR-like Laws. (arXiv:2105.10117v1 [cs.CL])"
        },
        {
          "id": "http://arxiv.org/abs/2102.03848",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hamada_M/0/1/0/all/0/1\">Mohamed A. Hamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdallah_A/0/1/0/all/0/1\">Abdelrahman Abdallah</a>",
          "description": "Many computer systems for calculating the proper organization of memory are\namong the most critical issues. Using a tier cache memory (along with branching\nprediction) is an effective means of increasing modern multi-core processors'\nperformance. Designing high-performance processors is a complex task and\nrequires preliminary verification and analysis of the model level, usually used\nin analytical and simulation modeling. The refinement of extreme programming is\nan unfortunate challenge. Few experts disagre",
          "link": "http://arxiv.org/abs/2102.03848",
          "publishedOn": "2021-05-22T03:02:49.060Z",
          "wordCount": 650,
          "title": "Estimate The Efficiency Of Multiprocessor's Cash Memory Work Algorithms. (arXiv:2102.03848v2 [cs.NI] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09829",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanxiong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>",
          "description": "Recommender systems are gaining increasing and critical impacts on human and\nsociety since a growing number of users use them for information seeking and\ndecision making. Therefore, it is crucial to address the potential unfairness\nproblems in recommendations. Just like users have personalized preferences on\nitems, users' demands for fairness are also personalized in many scenarios.\nTherefore, it is important to provide personalized fair recommendations for\nusers to satisfy their personalized fairness deman",
          "link": "http://arxiv.org/abs/2105.09829",
          "publishedOn": "2021-05-22T03:02:48.745Z",
          "wordCount": 630,
          "title": "Towards Personalized Fairness based on Causal Notion. (arXiv:2105.09829v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/1812.00002",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingyuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_S/0/1/0/all/0/1\">Sen Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Congzhou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>",
          "description": "Interactive news recommendation has been launched and attracted much\nattention recently. In this scenario, user's behavior evolves from single click\nbehavior to multiple behaviors including like, comment, share etc. However,\nmost of the existing methods still use single click behavior as the unique\ncriterion of judging user's preferences. Further, although heterogeneous graphs\nhave been applied in different areas, a proper way to construct a heterogeneous\ngraph for interactive news data with an appropriate ",
          "link": "http://arxiv.org/abs/1812.00002",
          "publishedOn": "2021-05-22T03:02:48.725Z",
          "wordCount": 678,
          "title": "The Graph-Based Behavior-Aware Recommendation for Interactive News. (arXiv:1812.00002v2 [cs.IR] UPDATED)"
        },
        {
          "id": "http://arxiv.org/abs/2105.09605",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1\">Xin Xin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zaiqiao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jose_J/0/1/0/all/0/1\">Joemon Jose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>",
          "description": "Learning from implicit feedback is one of the most common cases in the\napplication of recommender systems. Generally speaking, interacted examples are\nconsidered as positive while negative examples are sampled from uninteracted\nones. However, noisy examples are prevalent in real-world implicit feedback. A\nnoisy positive example could be interacted but it actually leads to negative\nuser preference. A noisy negative example which is uninteracted because of\nunawareness of the user could also denote potential p",
          "link": "http://arxiv.org/abs/2105.09605",
          "publishedOn": "2021-05-22T03:02:48.682Z",
          "wordCount": 678,
          "title": "Probabilistic and Variational Recommendation Denoising. (arXiv:2105.09605v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09816",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1\">Sebastian Hofst&#xe4;tter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_B/0/1/0/all/0/1\">Bhaskar Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1\">Hamed Zamani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Craswell_N/0/1/0/all/0/1\">Nick Craswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1\">Allan Hanbury</a>",
          "description": "An emerging recipe for achieving state-of-the-art effectiveness in neural\ndocument re-ranking involves utilizing large pre-trained language models -\ne.g., BERT - to evaluate all individual passages in the document and then\naggregating the outputs by pooling or additional Transformer layers. A major\ndrawback of this approach is high query latency due to the cost of evaluating\nevery passage in the document with BERT. To make matters worse, this high\ninference cost and latency varies based on the length of the",
          "link": "http://arxiv.org/abs/2105.09816",
          "publishedOn": "2021-05-22T03:02:48.653Z",
          "wordCount": 659,
          "title": "Intra-Document Cascading: Learning to Select Passages for Neural Document Ranking. (arXiv:2105.09816v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09710",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Fei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bolin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>",
          "description": "Conversational recommender systems (CRS) enable the traditional recommender\nsystems to explicitly acquire user preferences towards items and attributes\nthrough interactive conversations. Reinforcement learning (RL) is widely\nadopted to learn conversational recommendation policies to decide what\nattributes to ask, which items to recommend, and when to ask or recommend, at\neach conversation turn. However, existing methods mainly target at solving one\nor two of these three decision-making problems in CRS with ",
          "link": "http://arxiv.org/abs/2105.09710",
          "publishedOn": "2021-05-22T03:02:48.630Z",
          "wordCount": 642,
          "title": "Unified Conversational Recommendation Policy Learning via Graph-based Reinforcement Learning. (arXiv:2105.09710v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09562",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Proper_H/0/1/0/all/0/1\">H. A. Proper</a>",
          "description": "Effective information disclosure in the context of databases with a large\nconceptual schema is known to be a non-trivial problem. In particular the\nformulation of ad-hoc queries is a major problem in such contexts. Existing\napproaches for tackling this problem include graphical query interfaces, query\nby navigation, query by construction, and point to point queries. In this\nreport we propose an adoption of the query by navigation mechanism that is\nespecially geared towards the InfoAssistant product. Query b",
          "link": "http://arxiv.org/abs/2105.09562",
          "publishedOn": "2021-05-22T03:02:48.607Z",
          "wordCount": 609,
          "title": "Interactive Query Formulation using Query By Navigation. (arXiv:2105.09562v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09613",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Aditi Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanya_S/0/1/0/all/0/1\">Suhas Jayaram Subramanya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnaswamy_R/0/1/0/all/0/1\">Ravishankar Krishnaswamy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simhadri_H/0/1/0/all/0/1\">Harsha Vardhan Simhadri</a>",
          "description": "Approximate nearest neighbor search (ANNS) is a fundamental building block in\ninformation retrieval with graph-based indices being the current\nstate-of-the-art and widely used in the industry. Recent advances in\ngraph-based indices have made it possible to index and search billion-point\ndatasets with high recall and millisecond-level latency on a single commodity\nmachine with an SSD.\n\nHowever, existing graph algorithms for ANNS support only static indices that\ncannot reflect real-time changes to the corpus ",
          "link": "http://arxiv.org/abs/2105.09613",
          "publishedOn": "2021-05-22T03:02:48.584Z",
          "wordCount": 643,
          "title": "FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming Similarity Search. (arXiv:2105.09613v1 [cs.IR])"
        },
        {
          "id": "http://arxiv.org/abs/2105.09592",
          "author": "<a href=\"http://arxiv.org/find/cs/1/au:+Bountrogiannis_K/0/1/0/all/0/1\">Konstantinos Bountrogiannis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzagkarakis_G/0/1/0/all/0/1\">George Tzagkarakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsakalides_P/0/1/0/all/0/1\">Panagiotis Tsakalides</a>",
          "description": "Due to the importance of the lower bounding distances and the attractiveness\nof symbolic representations, the family of symbolic aggregate approximations\n(SAX) has been used extensively for encoding time series data. However, typical\nSAX-based methods rely on two restrictive assumptions; the Gaussian\ndistribution and equiprobable symbols. This paper proposes two novel\ndata-driven SAX-based symbolic representations, distinguished by their\ndiscretization steps. The first representation, oriented for general d",
          "link": "http://arxiv.org/abs/2105.09592",
          "publishedOn": "2021-05-22T03:02:48.534Z",
          "wordCount": 634,
          "title": "Distribution Agnostic Symbolic Representations for Time Series Dimensionality Reduction and Online Anomaly Detection. (arXiv:2105.09592v1 [cs.IR])"
        }
      ]
    }
  ],
  "cliVersion": "1.8.1"
}