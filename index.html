<!DOCTYPE html>
<html lang="en">

<head>
  <title>osmos::feed</title>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="robots" content="noindex, nofollow" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
  <link rel="alternate" type="application/rss+xml" title="osmos::feed" href="feed.atom" />
  <link href="index.css" rel="stylesheet" />
  <style>
  :root {
    /**
     * Solarized Light
     * Ethan Schoonover (modified by aramisgithub)
     */
    --base00: #fdf6e3;
    --base01: #eee8d5;
    --base02: #93a1a1;
    --base03: #839496;
    --base04: #657b83;
    --base05: #586e75;
    --base06: #073642;
    --base07: #002b36;
    --base08: #dc322f;
    --base09: #cb4b16;
    --base0A: #b58900;
    --base0B: #859900;
    --base0C: #2aa198;
    --base0D: #268bd2;
    --base0E: #6c71c4;
    --base0F: #d33682;

    /**
    * Typograph
    */
    --font-size-m: 1.6rem;
    --font-size-s: 1.4rem;

    /**
    * Components
    */
    --body-color: var(--base07);
    --body-bg: var(--base01);

    --source-name-color: var(--base0D);
    --source-name-hover-color: var(--base0D);

    --article-title-color: var(--base05);
    --article-title-hover-color: var(--base0E);
    --article-summary-hover-color: var(--base0D);

    --accordion-content-rail-color: var(--base01);
    --accordion-content-hover-rail-color: var(--base0D);
    --accordion-title-marker-color: var(--base01);
    --accordion-title-hover-marker-color: var(--base0E);

    --card-bg: var(--base00);
    --card-shadow: none;
    --card-radius: 0;
    --footer-link-hover-color: var(--base0D);
  }

  .daily-heading {
    padding-left: 0;
  }

  .card {
    border: 1px solid var(--base02);
  }
</style>

</head>

<body>
<!-- %after-body-begin.html% -->
  <section class="daily-content">
    <h2 class="daily-heading"><time datatime="2021-05-22">2021-05-22</time></h2>
    <ul class="sources card">
      <li class="source">
        <section>
          <h3 class="source-name"><a class="source-name__link" href="http://arxiv.org/">cs.CL updates on arXiv.org</a></h3>
          <section class="articles-per-source">
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Encoding Explanatory Knowledge for Zero-shot Science Question Answering. (arXiv:2105.05737v2 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05737">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>This paper describes N-XKT (Neural encoding based on eXplanatory Knowledge
Transfer), a novel method for the automatic transfer of explanatory knowledge
through neural encoding mechanisms. We demonstrate that N-XKT is able to
improve accuracy and generalization on science Question Answering (QA).
Specifically, by leveraging facts from background explanatory knowledge
corpora, the N-XKT model shows a clear improvement on zero-shot QA.
Furthermore, we show that N-XKT can be fine-tuned on a target QA dataset,
…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Counterfactual Interventions Reveal the Causal Effect of Relative Clause Representations on Agreement Prediction. (arXiv:2105.06965v2 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06965">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>When language models process syntactically complex sentences, do they use
abstract syntactic information present in these sentences in a manner that is
consistent with the grammar of English, or do they rely solely on a set of
heuristics? We propose a method to tackle this question, AlterRep. For any
linguistic feature in the sentence, AlterRep allows us to generate
counterfactual representations by altering how this feature is encoded, while
leaving all other aspects of the original representation intact. …</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">FastCorrect: Fast Error Correction with Edit Alignment for Automatic Speech Recognition. (arXiv:2105.03842v2 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03842">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(3 min)</span>
                    <span>Error correction techniques have been used to refine the output sentences
from automatic speech recognition (ASR) models and achieve a lower word error
rate (WER) than original ASR outputs. Previous works usually use a
sequence-to-sequence model to correct an ASR output sentence autoregressively,
which causes large latency and cannot be deployed in online ASR services. A
straightforward solution to reduce latency, inspired by non-autoregressive
(NAR) neural machine translation, is to use an NAR sequence gen…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Infinite use of finite means: Zero-Shot Generalization using Compositional Emergent Protocols. (arXiv:2012.05011v3 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05011">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Human language has been described as a system that makes \textit{use of
finite means to express an unlimited array of thoughts}. Of particular interest
is the aspect of compositionality, whereby, the meaning of a compound language
expression can be deduced from the meaning of its constituent parts. If
artificial agents can develop compositional communication protocols akin to
human language, they can be made to seamlessly generalize to unseen
combinations. However, the real question is, how do we induce com…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Multilingual Offensive Language Identification for Low-resource Languages. (arXiv:2105.05996v3 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05996">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Offensive content is pervasive in social media and a reason for concern to
companies and government organizations. Several studies have been recently
published investigating methods to detect the various forms of such content
(e.g. hate speech, cyberbullying, and cyberaggression). The clear majority of
these studies deal with English partially because most annotated datasets
available contain English data. In this paper, we take advantage of available
English datasets by applying cross-lingual contextual wo…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Unsupervised Cross-Domain Prerequisite Chain Learning using Variational Graph Autoencoders. (arXiv:2105.03505v2 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03505">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Learning prerequisite chains is an essential task for efficiently acquiring
knowledge in both known and unknown domains. For example, one may be an expert
in the natural language processing (NLP) domain but want to determine the best
order to learn new concepts in an unfamiliar Computer Vision domain (CV). Both
domains share some common concepts, such as machine learning basics and deep
learning models. In this paper, we propose unsupervised cross-domain concept
prerequisite chain learning using an optimize…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter. (arXiv:2105.07148v2 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07148">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Lexicon information and pre-trained models, such as BERT, have been combined
to explore Chinese sequence labelling tasks due to their respective strengths.
However, existing methods solely fuse lexicon features via a shallow and random
initialized sequence layer and do not integrate them into the bottom layers of
BERT. In this paper, we propose Lexicon Enhanced BERT (LEBERT) for Chinese
sequence labelling, which integrates external lexicon knowledge into BERT
layers directly by a Lexicon Adapter layer. Comp…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">&quot;Subverting the Jewtocracy&quot;: Online Antisemitism Detection Using Multimodal Deep Learning. (arXiv:2104.05947v2 [cs.MM] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05947">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>The exponential rise of online social media has enabled the creation,
distribution, and consumption of information at an unprecedented rate. However,
it has also led to the burgeoning of various forms of online abuse. Increasing
cases of online antisemitism have become one of the major concerns because of
its socio-political consequences. Unlike other major forms of online abuse like
racism, sexism, etc., online antisemitism has not been studied much from a
machine learning perspective. To the best of our k…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">KLUE: Korean Language Understanding Evaluation. (arXiv:2105.09680v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09680">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE
is a collection of 8 Korean natural language understanding (NLU) tasks,
including Topic Classification, Semantic Textual Similarity, Natural Language
Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing,
Machine Reading Comprehension, and Dialogue State Tracking. We build all of the
tasks from scratch from diverse source corpora while respecting copyrights, to
ensure accessibility for anyone without any rest…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Towards Target-dependent Sentiment Classification in News Articles. (arXiv:2105.09660v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09660">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Extensive research on target-dependent sentiment classification (TSC) has led
to strong classification performances in domains where authors tend to
explicitly express sentiment about specific entities or topics, such as in
reviews or on social media. We investigate TSC in news articles, a much less
researched domain, despite the importance of news as an essential information
source in individual and societal decision making. This article introduces
NewsTSC, a manually annotated dataset to explore TSC on ne…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Exploiting News Article Structure for Automatic Corpus Generation. (arXiv:2010.11574v2 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11574">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Transformers represent the state-of-the-art in Natural Language Processing
(NLP) in recent years, proving effective even in tasks done in low-resource
languages. While pretrained transformers for these languages can be made, it is
challenging to measure their true performance and capacity due to the lack of
hard benchmark datasets, as well as the difficulty and cost of producing them.
In this paper, we present three contributions: First, we propose a methodology
for automatically producing Natural Language …</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Mondegreen: A Post-Processing Solution to Speech Recognition Error Correction for Voice Search Queries. (arXiv:2105.09930v1 [cs.SD])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09930">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>As more and more online search queries come from voice, automatic speech
recognition becomes a key component to deliver relevant search results. Errors
introduced by automatic speech recognition (ASR) lead to irrelevant search
results returned to the user, thus causing user dissatisfaction. In this paper,
we introduce an approach, Mondegreen, to correct voice queries in text space
without depending on audio signals, which may not always be available due to
system constraints or privacy or bandwidth (for exa…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Multi-Head Attention: Collaborate Instead of Concatenate. (arXiv:2006.16362v2 [cs.LG] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.16362">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Attention layers are widely used in natural language processing (NLP) and are
beginning to influence computer vision architectures. Training very large
transformer models allowed significant improvement in both fields, but once
trained, these networks show symptoms of over-parameterization. For instance,
it is known that many attention heads can be pruned without impacting accuracy.
This work aims to enhance current understanding on how multiple heads interact.
Motivated by the observation that attention he…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Measuring Coding Challenge Competence With APPS. (arXiv:2105.09938v1 [cs.SE])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09938">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>While programming is one of the most broadly applicable skills in modern
society, modern machine learning models still cannot code solutions to basic
problems. It can be difficult to accurately assess code generation performance,
and there has been surprisingly little work on evaluating code generation in a
way that is both flexible and rigorous. To meet this challenge, we introduce
APPS, a benchmark for code generation. Unlike prior work in more restricted
settings, our benchmark measures the ability of mo…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Head-driven Phrase Structure Parsing in O($n^3$) Time Complexity. (arXiv:2105.09835v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09835">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Constituent and dependency parsing, the two classic forms of syntactic
parsing, have been found to benefit from joint training and decoding under a
uniform formalism, Head-driven Phrase Structure Grammar (HPSG). However,
decoding this unified grammar has a higher time complexity ($O(n^5)$) than
decoding either form individually ($O(n^3)$) since more factors have to be
considered during decoding. We thus propose an improved head scorer that helps
achieve a novel performance-preserved parser in $O$($n^3$) tim…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering. (arXiv:2012.00955v2 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00955">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Recent works have shown that language models (LM) capture different types of
knowledge regarding facts or common sense. However, because no model is
perfect, they still fail to provide appropriate answers in many cases. In this
paper, we ask the question &quot;how can we know when language models know, with
confidence, the answer to a particular query?&quot; We examine this question from
the point of view of calibration, the property of a probabilistic model&#x27;s
predicted probabilities actually being well correlated wi…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning. (arXiv:2012.15409v3 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15409">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Existed pre-training methods either focus on single-modal tasks or
multi-modal tasks, and cannot effectively adapt to each other. They can only
utilize single-modal data (i.e. text or image) or limited multi-modal data
(i.e. image-text pairs). In this work, we propose a unified-modal pre-training
architecture, namely UNIMO, which can effectively adapt to both single-modal
and multi-modal understanding and generation tasks. Large scale of free text
corpus and image collections can be utilized to improve the …</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">A practical introduction to the Rational Speech Act modeling framework. (arXiv:2105.09867v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09867">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Recent advances in computational cognitive science (i.e., simulation-based
probabilistic programs) have paved the way for significant progress in formal,
implementable models of pragmatics. Rather than describing a pragmatic
reasoning process in prose, these models formalize and implement one, deriving
both qualitative and quantitative predictions of human behavior -- predictions
that consistently prove correct, demonstrating the viability and value of the
framework. The current paper provides a practical i…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">On Cross-Dataset Generalization in Automatic Detection of Online Abuse. (arXiv:2010.07414v3 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07414">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>NLP research has attained high performances in abusive language detection as
a supervised classification task. While in research settings, training and test
datasets are usually obtained from similar data samples, in practice systems
are often applied on data that are different from the training set in topic and
class distributions. Also, the ambiguity in class definitions inherited in this
task aggravates the discrepancies between source and target datasets. We
explore the topic bias and the task formulati…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">A comprehensive comparative evaluation and analysis of Distributional Semantic Models. (arXiv:2105.09825v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09825">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Distributional semantics has deeply changed in the last decades. First,
predict models stole the thunder from traditional count ones, and more recently
both of them were replaced in many NLP applications by contextualized vectors
produced by Transformer neural language models. Although an extensive body of
research has been devoted to Distributional Semantic Model (DSM) evaluation, we
still lack a thorough comparison with respect to tested models, semantic tasks,
and benchmark datasets. Moreover, previous w…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Robustness of end-to-end Automatic Speech Recognition Models -- A Case Study using Mozilla DeepSpeech. (arXiv:2105.09742v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09742">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>When evaluating the performance of automatic speech recognition models,
usually word error rate within a certain dataset is used. Special care must be
taken in understanding the dataset in order to report realistic performance
numbers. We argue that many performance numbers reported probably underestimate
the expected error rate. We conduct experiments controlling for selection bias,
gender as well as overlap (between training and test data) in content, voices,
and recording conditions. We find that content…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling. (arXiv:2105.09856v1 [cs.SD])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09856">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>This paper presents a novel high-fidelity and low-latency universal neural
vocoder framework based on multiband WaveRNN with data-driven linear prediction
for discrete waveform modeling (MWDLP). MWDLP employs a coarse-fine bit WaveRNN
architecture for 10-bit mu-law waveform modeling. A sparse gated recurrent unit
with a relatively large size of hidden units is utilized, while the multiband
modeling is deployed to achieve real-time low-latency usage. A novel technique
for data-driven linear prediction (LP) w…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Simplifying Paragraph-level Question Generation via Transformer Language Models. (arXiv:2005.01107v3 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01107">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Question generation (QG) is a natural language generation task where a model
is trained to ask questions corresponding to some input text. Most recent
approaches frame QG as a sequence-to-sequence problem and rely on additional
features and mechanisms to increase performance; however, these often increase
model complexity, and can rely on auxiliary data unavailable in practical use.
A single Transformer-based unidirectional language model leveraging transfer
learning can be used to produce high quality ques…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear Prediction. (arXiv:2105.09858v1 [cs.SD])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09858">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>This paper presents a low-latency real-time (LLRT) non-parallel voice
conversion (VC) framework based on cyclic variational autoencoder (CycleVAE)
and multiband WaveRNN with data-driven linear prediction (MWDLP). CycleVAE is a
robust non-parallel multispeaker spectral model, which utilizes a
speaker-independent latent space and a speaker-dependent code to generate
reconstructed/converted spectral features given the spectral features of an
input speaker. On the other hand, MWDLP is an efficient and a high-qu…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus. (arXiv:2010.10391v4 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10391">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Contextual word embedding models, such as BioBERT and Bio_ClinicalBERT, have
achieved state-of-the-art results in biomedical natural language processing
tasks by focusing their pre-training process on domain-specific corpora.
However, such models do not take into consideration expert domain knowledge.

In this work, we introduced UmlsBERT, a contextual embedding model that
integrates domain knowledge during the pre-training process via a novel
knowledge augmentation strategy. More specifically, the augmenta…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">BRUMS at SemEval-2020 Task 3: Contextualised Embeddings for Predicting the (Graded) Effect of Context in Word Similarity. (arXiv:2010.06269v2 [cs.CL] UPDATED)</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06269">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>This paper presents the team BRUMS submission to SemEval-2020 Task 3: Graded
Word Similarity in Context. The system utilises state-of-the-art contextualised
word embeddings, which have some task-specific adaptations, including stacked
embeddings and average embeddings. Overall, the approach achieves good
evaluation scores across all the languages, while maintaining simplicity.
Following the final rankings, our approach is ranked within the top 5 solutions
of each language while preserving the 1st position o…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Towards Detecting Need for Empathetic Response in Motivational Interviewing. (arXiv:2105.09649v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09649">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Empathetic response from the therapist is key to the success of clinical
psychotherapy, especially motivational interviewing. Previous work on
computational modelling of empathy in motivational interviewing has focused on
offline, session-level assessment of therapist empathy, where empathy captures
all efforts that the therapist makes to understand the client&#x27;s perspective and
convey that understanding to the client. In this position paper, we propose a
novel task of turn-level detection of client need for…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09632">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Today, we are seeing an ever-increasing number of clinical notes that contain
clinical results, images, and textual descriptions of patient&#x27;s health state.
All these data can be analyzed and employed to cater novel services that can
help people and domain experts with their common healthcare tasks. However,
many technologies such as Deep Learning and tools like Word Embeddings have
started to be investigated only recently, and many challenges remain open when
it comes to healthcare domain applications. To a…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">A Case Study on Pros and Cons of Regular Expression Detection and Dependency Parsing for Negation Extraction from German Medical Documents. Technical Report. (arXiv:2105.09702v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09702">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>We describe our work on information extraction in medical documents written
in German, especially detecting negations using an architecture based on the
UIMA pipeline. Based on our previous work on software modules to cover medical
concepts like diagnoses, examinations, etc. we employ a version of the NegEx
regular expression algorithm with a large set of triggers as a baseline. We
show how a significantly smaller trigger set is sufficient to achieve similar
results, in order to reduce adaptation times to n…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Intra-Document Cascading: Learning to Select Passages for Neural Document Ranking. (arXiv:2105.09816v1 [cs.IR])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09816">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>An emerging recipe for achieving state-of-the-art effectiveness in neural
document re-ranking involves utilizing large pre-trained language models -
e.g., BERT - to evaluate all individual passages in the document and then
aggregating the outputs by pooling or additional Transformer layers. A major
drawback of this approach is high query latency due to the cost of evaluating
every passage in the document with BERT. To make matters worse, this high
inference cost and latency varies based on the length of the…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">See, Hear, Read: Leveraging Multimodality with Guided Attention for Abstractive Text Summarization. (arXiv:2105.09601v1 [cs.LG])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09601">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>In recent years, abstractive text summarization with multimodal inputs has
started drawing attention due to its ability to accumulate information from
different source modalities and generate a fluent textual summary. However,
existing methods use short videos as the visual modality and short summary as
the ground-truth, therefore, perform poorly on lengthy videos and long
ground-truth summary. Additionally, there exists no benchmark dataset to
generalize this task on videos of varying lengths. In this pape…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">MLBiNet: A Cross-Sentence Collective Event Detection Network. (arXiv:2105.09458v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09458">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>We consider the problem of collectively detecting multiple events,
particularly in cross-sentence settings. The key to dealing with the problem is
to encode semantic information and model event inter-dependency at a
document-level. In this paper, we reformulate it as a Seq2Seq task and propose
a Multi-Layer Bidirectional Network (MLBiNet) to capture the document-level
association of events and semantic information simultaneously. Specifically, a
bidirectional decoder is firstly devised to model event inter-…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Dependency Parsing with Bottom-up Hierarchical Pointer Networks. (arXiv:2105.09611v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09611">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Dependency parsing is a crucial step towards deep language understanding and,
therefore, widely demanded by numerous Natural Language Processing
applications. In particular, left-to-right and top-down transition-based
algorithms that rely on Pointer Networks are among the most accurate approaches
for performing dependency parsing. Additionally, it has been observed for the
top-down algorithm that Pointer Networks&#x27; sequential decoding can be improved
by implementing a hierarchical variant, more adequate to m…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Computational Morphology with Neural Network Approaches. (arXiv:2105.09404v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09404">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Neural network approaches have been applied to computational morphology with
great success, improving the performance of most tasks by a large margin and
providing new perspectives for modeling. This paper starts with a brief
introduction to computational morphology, followed by a review of recent work
on computational morphology with neural network approaches, to provide an
overview of the area. In the end, we will analyze the advantages and problems
of neural network approaches to computational morphology…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">The impact of virtual mirroring on customer satisfaction. (arXiv:2105.09571v1 [cs.SI])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09571">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>We investigate the impact of a novel method called &quot;virtual mirroring&quot; to
promote employee self-reflection and impact customer satisfaction. The method
is based on measuring communication patterns, through social network and
semantic analysis, and mirroring them back to the individual. Our goal is to
demonstrate that self-reflection can trigger a change in communication
behaviors, which lead to increased customer satisfaction. We illustrate and
test our approach analyzing e-mails of a large global services …</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09501">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Existing multilingual machine translation approaches mainly focus on
English-centric directions, while the non-English directions still lag behind.
In this work, we aim to build a many-to-many translation system with an
emphasis on the quality of non-English language directions. Our intuition is
based on the hypothesis that a universal cross-language representation leads to
better multilingual translation performance. To this end, we propose \method, a
training method to obtain a single unified multilingual…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Manual Evaluation Matters: Reviewing Test Protocols of Distantly Supervised Relation Extraction. (arXiv:2105.09543v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09543">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Distantly supervised (DS) relation extraction (RE) has attracted much
attention in the past few years as it can utilize large-scale auto-labeled
data. However, its evaluation has long been a problem: previous works either
took costly and inconsistent methods to manually examine a small sample of
model predictions, or directly test models on auto-labeled data -- which, by
our check, produce as much as 53% wrong labels at the entity pair level in the
popular NYT10 dataset. This problem has not only led to ina…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Geographic Question Answering: Challenges, Uniqueness, Classification, and Future Directions. (arXiv:2105.09392v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09392">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>As an important part of Artificial Intelligence (AI), Question Answering (QA)
aims at generating answers to questions phrased in natural language. While
there has been substantial progress in open-domain question answering, QA
systems are still struggling to answer questions which involve geographic
entities or concepts and that require spatial operations. In this paper, we
discuss the problem of geographic question answering (GeoQA). We first
investigate the reasons why geographic questions are difficult t…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Explainable Health Risk Predictor with Transformer-based Medicare Claim Encoder. (arXiv:2105.09428v1 [cs.LG])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09428">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>In 2019, The Centers for Medicare and Medicaid Services (CMS) launched an
Artificial Intelligence (AI) Health Outcomes Challenge seeking solutions to
predict risk in value-based care for incorporation into CMS Innovation Center
payment and service delivery models. Recently, modern language models have
played key roles in a number of health related tasks. This paper presents, to
the best of our knowledge, the first application of these models to patient
readmission prediction. To facilitate this, we create a…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">LAST at SemEval-2021 Task 1: Improving Multi-Word Complexity Prediction Using Bigram Association Measures. (arXiv:2105.09653v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09653">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>This paper describes the system developed by the Laboratoire d&#x27;analyse
statistique des textes (LAST) for the Lexical Complexity Prediction shared task
at SemEval-2021. The proposed system is made up of a LightGBM model fed with
features obtained from many word frequency lists, published lexical norms and
psychometric data. For tackling the specificity of the multi-word task, it uses
bigram association measures. Despite that the only contextual feature used was
sentence length, the system achieved an honorab…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Adaptive Knowledge-Enhanced Bayesian Meta-Learning for Few-shot Event Detection. (arXiv:2105.09509v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09509">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Event detection (ED) aims at detecting event trigger words in sentences and
classifying them into specific event types. In real-world applications, ED
typically does not have sufficient labelled data, thus can be formulated as a
few-shot learning problem. To tackle the issue of low sample diversity in
few-shot ED, we propose a novel knowledge-based few-shot event detection method
which uses a definition-based encoder to introduce external event knowledge as
the knowledge prior of event types. Furthermore, a…</span>
                  </div>
                </a>
              </details>
            </article>
            <article>
              <details class="article-expander">
                <summary class="article-expander__title">Unified Dual-view Cognitive Model for Interpretable Claim Verification. (arXiv:2105.09567v1 [cs.CL])</summary>
                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09567">
                  <div class="article-summary-box-inner">
                    <span class="article-reading-time">(2 min)</span>
                    <span>Recent studies constructing direct interactions between the claim and each
single user response (a comment or a relevant article) to capture evidence have
shown remarkable success in interpretable claim verification. Owing to
different single responses convey different cognition of individual users
(i.e., audiences), the captured evidence belongs to the perspective of
individual cognition. However, individuals&#x27; cognition of social things is not
always able to truly reflect the objective. There may be one-si…</span>
                  </div>
                </a>
              </details>
            </article>
        </section>
      </li>
    </ul>
  </section>

  <footer>
    <time id="build-timestamp" datetime="2021-05-22T02:50:51.109Z">2021-05-22T02:50:51.109Z</time>
    <span><a class="footer-link" href="https://github.com/osmoscraft/osmosfeed">osmosfeed 1.7.2</a></span>
  </footer>
  <script src="index.js"></script>
  <!-- %before-body-end.html% -->
</body>

</html>